[{"content":"\n","date":"2024-10-12T00:00:00Z","image":"https://gkxgithub.github.io/p/%E7%BE%8E/8e071cae5ea4815582903fccfc46a39_hu5531098368616869691.jpg","permalink":"https://gkxgithub.github.io/p/%E7%BE%8E/","title":"美"},{"content":"1.快速入门 1.1yum wget docker 1.1.1yum YUM 它是一个命令行软件包管理工具，主要用于基于 RPM 的 Linux 发行版（如 CentOS、Red Hat Enterprise Linux、Fedora 等）。YUM 是 “Yellowdog Updater, Modified” 的缩写。它的主要功能包括：\n1、自动解决依赖关系：YUM 能够自动解决安装软件包时遇到的依赖问题。\n2、简化软件管理：用户可以轻松地安装、更新和删除软件包。\n3、支持多个仓库：YUM 支持从多个软件仓库（repositories）下载和安装软件包。\n4、易于更新系统：通过简单的命令，用户可以轻松地更新系统中的所有软件包。\n常见的YUM命令包括：\nyum list | grep \u0026lt;软件包名\u0026gt;：查找软件包。\nyum install \u0026lt;软件包名\u0026gt;：安装软件包。\nyum remove \u0026lt;软件包名\u0026gt;：删除软件包。\nyum update \u0026lt;软件包名\u0026gt;：更新软件包。\nyum search \u0026lt;关键词\u0026gt;：搜索软件包。\nyum info \u0026lt;软件包名\u0026gt;：显示软件包的详细信息。\n使用之前要安装好相关的配置以及yum源。\n1.1.2wget wget命令是一个在Linux和类Unix操作系统中经常使用的网络命令，用途是从指定的URL下载文件。它支持HTTP、HTTPS和FTP协议，支持断点续传，可以下载整个网站。 原文链接：https://blog.csdn.net/jks212454/article/details/132345108\n1.1.3docker Docker ：是一个开源的容器化平台，它允许开发者将应用程序及其依赖打包进轻量级、可移植的容器中，实现快速、一致和高效的开发、测试和部署 同时提供了环境隔离，使得每个容器都拥有独立的文件系统和网络配置，互不影响；镜像管理功能让应用及其运行环境可以轻松地进行版本控制和分发；\nDocker 通过容器化技术，为项目开发、部署和运维提供了一套高效、灵活的解决方案，帮助项目团队解决了环境一致性、依赖管理、开发效率、持续集成/持续部署、微服务架构、资源隔离、弹性伸缩、快速部署、多租户环境、调试能力、资源利用率、跨平台支持和本地开发远程部署等一系列问题；\ndocker的安装和配置详情\n原文链接：https://blog.csdn.net/qq_66851231/article/details/138728913\n1.1.4关系 Docker直接拉取镜像进行使用与yum安装软件在某些方面相似，都提供了简洁的安装方式，但它们在实现机制和应用场景上存在明显差异。\n简洁性：\nDocker拉取镜像：用户可以通过简单的docker pull [镜像名称]命令从Docker Hub或其他镜像仓库拉取所需的镜像，这些镜像包含了完整的应用程序及其依赖环境，使得部署变得快速且一致。 yum安装软件：yum同样提供了简洁的安装命令yum install [软件包名称]，能够自动处理依赖关系并安装软件包，但它是针对Linux系统中的单个软件包或应用程序进行安装。\n实现机制：\nDocker：通过容器化技术，将应用程序及其运行环境打包成一个独立的容器，实现了应用程序与宿主机的解耦，确保了应用程序在不同环境中的一致性和可移植性。 yum：基于RPM包管理，通过访问指定的软件仓库，下载并安装软件包及其依赖项，主要用于Linux系统的软件包管理。\n应用场景：\nDocker：更适用于需要快速部署、扩展和管理复杂应用程序的场景，如微服务架构、持续集成/持续部署（CI/CD）等。 yum：主要用于Linux系统的日常软件包管理，包括系统更新、安全补丁安装以及用户自定义软件包的安装等。\n综上所述，虽然Docker拉取镜像进行使用与yum安装软件在简洁性方面有所相似，但它们在实现机制和应用场景上存在显著差异。Docker提供了一种更高级别的应用程序部署和管理方式，而yum则更侧重于Linux系统的软件包管理。\nwget和yum是Linux系统中常用的两个工具，它们各自有不同的功能和用途：\nwget：\n功能：wget是一个命令行下载工具，用于从互联网上下载文件。它支持HTTP、HTTPS和FTP协议，能够下载网页、软件包、文档等各种类型的文件。 特点：wget提供了丰富的选项和参数，如断点续传、限速下载、后台下载等，使得下载过程更加灵活和可控。 用途：wget广泛用于下载文件、镜像网站等场景，是Linux用户不可或缺的工具之一。\nyum：\n功能：yum是一个基于RPM包管理的软件包管理器，主要用于Red Hat系列的Linux系统中（如CentOS、Fedora等）。它能够自动从指定的软件仓库中下载、安装、更新和删除软件包，并自动处理软件包之间的依赖关系。 特点：yum简化了软件包管理的过程，用户无需手动下载和安装每个依赖的软件包，只需一条命令即可完成安装或更新操作。 用途：yum是Linux系统管理员进行系统维护和软件管理的得力助手，极大地提高了工作效率。\n综上所述，wget和yum在Linux系统中各自扮演着重要的角色。wget专注于文件下载，而yum则侧重于软件包的管理。两者相互配合，使得Linux系统的文件和软件管理变得更加高效和便捷。\n1.2部署MySQL，引入docker 首先，我们利用Docker来安装一个MySQL软件，大家可以对比一下之前传统的安装方式，看看哪个效率更高一些。\n如果是利用传统方式部署MySQL，大概的步骤有：\n搜索并下载MySQL安装包 上传至Linux环境 编译和配置环境 安装 而使用Docker安装，仅仅需要一步即可，在命令行输入下面的命令（建议采用CV大法）：\n1 2 3 4 5 6 docker run -d \\ --name mysql \\ -p 3306:3306 \\ -e TZ=Asia/Shanghai \\ -e MYSQL_ROOT_PASSWORD=123 \\ mysql 运行效果如图：\nMySQL安装完毕！通过任意客户端工具即可连接到MySQL.\n大家可以发现，当我们执行命令后，Docker做的第一件事情，是去自动搜索并下载了MySQL，然后会自动运行MySQL，我们完全不用插手，是不是非常方便。\n而且，这种安装方式你完全不用考虑运行的操作系统环境，它不仅仅在CentOS系统是这样，在Ubuntu系统、macOS系统、甚至是装了WSL的Windows下，都可以使用这条命令来安装MySQL。\n要知道，不同操作系统下其安装包、运行环境是都不相同的！如果是手动安装，必须手动解决安装包不同、环境不同的、配置不同的问题！\n而使用Docker，这些完全不用考虑。就是因为Docker会自动搜索并下载MySQL。注意：这里下载的不是安装包，而是镜像。镜像中不仅包含了MySQL本身，还包含了其运行所需要的环境、配置、系统级函数库。因此它在运行时就有自己独立的环境，就可以跨系统运行，也不需要手动再次配置环境了。这套独立运行的隔离环境我们称为容器。\n说明：\n镜像：英文是image 容器：英文是container 因此，Docker安装软件的过程，就是自动搜索下载镜像，然后创建并运行容器的过程。\nDocker会根据命令中的镜像名称自动搜索并下载镜像，那么问题来了，它是去哪里搜索和下载镜像的呢？这些镜像又是谁制作的呢？\nDocker官方提供了一个专门管理、存储镜像的网站，并对外开放了镜像上传、下载的权利。Docker官方提供了一些基础镜像，然后各大软件公司又在基础镜像基础上，制作了自家软件的镜像，全部都存放在这个网站。这个网站就成了Docker镜像交流的社区：\nhttps://hub.docker.com/\n基本上我们常用的各种软件都能在这个网站上找到，我们甚至可以自己制作镜像上传上去。\n像这种提供存储、管理Docker镜像的服务器，被称为DockerRegistry，可以翻译为镜像仓库。DockerHub网站是官方仓库，阿里云、华为云会提供一些第三方仓库，我们也可以自己搭建私有的镜像仓库。\n官方仓库在国外，下载速度较慢，一般我们都会使用第三方仓库提供的镜像加速功能，提高下载速度。而企业内部的机密项目，往往会采用私有镜像仓库。\n总之，镜像的来源有两种：\n基于官方基础镜像自己制作 直接去DockerRegistry下载 总结一下：\nDocker本身包含一个后台服务，我们可以利用Docker命令告诉Docker服务，帮助我们快速部署指定的应用。Docker服务部署应用时，首先要去搜索并下载应用对应的镜像，然后根据镜像创建并允许容器，应用就部署完成了。\n1.3命令解读 利用Docker快速的安装了MySQL，非常的方便，不过我们执行的命令到底是什么意思呢？\n1 2 3 4 5 6 docker run -d \\ --name mysql \\ -p 3306:3306 \\ -e TZ=Asia/Shanghai \\ -e MYSQL_ROOT_PASSWORD=123 \\ mysql 解读：\ndocker run -d ：创建并运行一个容器，-d则是让容器以后台进程运行 --name mysql : 给容器起个名字叫mysql，你可以叫别的 -p 3306:3306 : 设置端口映射。 容器是隔离环境，外界不可访问。但是可以将宿主机端口****映射容器内到端口，当访问宿主机指定端口时，就是在访问容器内的端口了。 容器内端口往往是由容器内的进程决定，例如MySQL进程默认端口是3306，因此容器内端口一定是3306；而宿主机端口则可以任意指定，一般与容器内保持一致。 格式： -p 宿主机端口:容器内端口，示例中就是将宿主机的3306映射到容器内的3306端口 -e TZ=Asia/Shanghai : 配置容器内进程运行时的一些参数 格式：-e KEY=VALUE，KEY和VALUE都由容器内进程决定 案例中，TZ=Asia/Shanghai是设置时区；MYSQL_ROOT_PASSWORD=123是设置MySQL默认密码 mysql : 设置镜像名称，Docker会根据这个名字搜索并下载镜像 格式：REPOSITORY:TAG，例如mysql:8.0，其中REPOSITORY可以理解为镜像名，TAG是版本号 在未指定TAG的情况下，默认是最新版本，也就是mysql:latest 镜像的名称不是随意的，而是要到DockerRegistry中寻找，镜像运行时的配置也不是随意的，要参考镜像的帮助文档，这些在DockerHub网站或者软件的官方网站中都能找到。\n如果我们要安装其它软件，也可以到DockerRegistry中寻找对应的镜像名称和版本，阅读相关配置即可。\n2.docker基础 接下来，我们一起来学习Docker使用的一些基础知识，为将来部署项目打下基础。具体用法可以参考Docker官方文档：\nhttps://docs.docker.com/\n2.1常见命令 首先我们来学习Docker中的常见命令，可以参考官方文档：\nhttps://docs.docker.com/engine/reference/commandline/cli/\n当你使用 docker run 命令启动一个容器时，Docker 会首先检查本地是否已经有指定的镜像。如果本地没有这个镜像，Docker 客户端会向 Docker Hub（或者其他配置的仓库）发送请求，自动执行 docker pull 操作来拉取缺失的镜像，然后再使用该镜像启动容器。\n这个过程大致如下：\n检查本地镜像：\nDocker 守护进程会在本地镜像存储中查找指定的镜像和标签（tag）。 拉取镜像：\n如果本地没有找到对应的镜像，Docker 会尝试从配置的镜像仓库（默认是 Docker Hub）拉取镜像。 启动容器：\n一旦镜像被成功拉取到本地，Docker 就会使用这个镜像启动一个新的容器。 例如，如果你执行以下命令：\n1 docker run -d -p 80:80 --name my-nginx nginx Docker 会首先检查本地是否有 nginx 镜像的最新版本。如果没有，它会从 Docker Hub 上的 nginx 仓库拉取镜像，然后使用这个镜像启动一个名为 my-nginx 的容器，并将容器的 80 端口映射到宿主机的 80 端口。\n这个流程是 Docker 的一个重要特性，它确保了容器的快速启动，并且使得镜像的管理和分发变得非常高效。这也意味着用户不需要手动拉取镜像，Docker 会在需要时自动处理。不过，如果你想要确保镜像在运行容器之前已经准备好，或者想要避免在容器启动过程中的网络延迟，你可以先手动执行 docker pull 命令来拉取镜像。\n2.1.1.命令介绍 其中，比较常见的命令有：\n命令 说明 文档地址 docker pull 拉取镜像 docker pull docker push 推送镜像到DockerRegistry docker push docker images 查看本地镜像 docker images docker rmi 删除本地镜像 docker rmi docker run 创建并运行容器（不能重复创建） docker run docker stop 停止指定容器 docker stop docker start 启动指定容器 docker start docker restart 重新启动容器 docker restart docker rm 删除指定容器 docs.docker.com docker ps 查看容器 docker ps docker logs 查看容器运行日志 docker logs docker exec 进入容器 docker exec docker save 保存镜像到本地压缩文件 docker save docker load 加载本地压缩文件到镜像 docker load docker inspect 查看容器详细信息 docker inspect docker exec 命令允许你在运行中的容器内执行命令。这个命令有许多选项，可以帮助你控制如何在容器中执行命令。以下是一些常用的 docker exec 选项及其使用案例：\n-i, --interactive：\n保持容器的标准输入（STDIN）打开，即使不附加到容器终端。 1 docker exec -i container_name /bin/bash -t, --tty：\n分配一个伪终端。通常与 -i 一起使用。 1 docker exec -it container_name /bin/bash -d, --detach：\n在后台运行命令。默认情况下，docker exec 会附加到容器的标准输出。 1 docker exec -d container_name /my_service.sh --detach-keys：\n指定从容器中分离的键。默认情况下是 ctrl-p,ctrl-q。 1 docker exec --detach-keys \u0026#34;ctrl-a,ctrl-q\u0026#34; -d container_name /my_service.sh --env, -e：\n设置环境变量。可以设置单个变量或从文件中读取多个变量。 1 docker exec -e \u0026#34;MY_VAR=value\u0026#34; container_name /bin/bash --env-file：\n从文件中读取环境变量。 1 docker exec --env-file ./env.list container_name /bin/bash --workdir, -w：\n设置容器内命令的工作目录。 1 docker exec -w /path/to/workdir container_name ls -l --user, -u：\n指定执行命令的用户。 1 docker exec -u root container_name /bin/bash --privileged：\n给予容器内的进程访问宿主机所有设备的能力。 1 docker exec --privileged container_name /sbin/service --volume, -v：\n将宿主机的文件系统挂载到容器内。 1 docker exec -v /host/path:/container/path container_name /bin/bash --link：\n将一个运行中的容器链接到另一个容器，以实现容器间的通信。 1 docker exec --link other_container_name:alias container_name /bin/bash --name：\n为执行的命令分配一个名称，使其可以在 docker ps 中显示。 1 docker exec --name my_command container_name /bin/bash --replace：\n如果容器内已经有一个同名的进程在运行，则替换它。 1 docker exec --name my_command --replace container_name /bin/bash --signal, -s：\n向容器内的进程发送一个信号。 1 docker exec -s SIGTERM container_name /bin/bash --entrypoint：\n覆盖容器的入口点。 1 docker exec --entrypoint /custom_entrypoint.sh container_name --network：\n指定容器的网络设置。 1 docker exec --network container_network container_name /bin/bash --detach-keys：\n自定义从容器中分离的键。 1 docker exec --detach-keys \u0026#34;ctrl-a,ctrl-b\u0026#34; container_name /bin/bash 请注意，docker exec 的某些选项可能不适用于所有场景，具体取决于你的 Docker 版本和配置。在使用这些选项时，建议查阅 Docker 的官方文档，以获取最新的信息和更详细的说明。\ndocker inspect 是一个非常强大的 Docker 命令，它用于获取 Docker 对象（如容器、镜像、网络或卷）的详细信息。这个命令可以输出大量的数据，包括配置、状态、统计信息等。\n以下是 docker inspect 的一些常用选项及其使用案例：\n--format, -f：\n自定义输出格式，只显示你感兴趣的部分信息。 1 docker inspect --format=\u0026#39;{{.Config.Image}}\u0026#39; container_name --type：\n指定要检查的对象类型，如 container、image、network 或 volume。 1 docker inspect --type=image my_image --all, -a：\n列出所有容器的详细信息（默认只列出最近的一个容器）。 1 docker inspect --all --latest：\n仅列出最后一个创建的容器的详细信息。 1 docker inspect --latest --size, -s：\n显示容器的磁盘使用情况。 1 docker inspect --size container_name --context：\n指定要检查的上下文环境。 1 docker inspect --context my_context container_name --mode：\n指定输出模式，如 json 或 template。 1 docker inspect --mode=json container_name --timeout, -t：\n设置命令的超时时间。 1 docker inspect --timeout=10s container_name --privileged：\n显示容器是否以特权模式运行。 1 docker inspect --privileged container_name --restart-policy：\n显示容器的重启策略。 1 docker inspect --restart-policy container_name --network：\n显示容器的网络设置。 1 docker inspect --network container_name --volume：\n显示容器的卷挂载信息。 1 docker inspect --volume container_name --link：\n显示容器的链接信息。 1 docker inspect --link container_name --env：\n显示容器的环境变量。 1 docker inspect --env container_name --label：\n显示容器的标签。 1 docker inspect --label container_name --file：\n显示容器的 Dockerfile 文件内容。 1 docker inspect --file my_image --config：\n显示容器的配置文件内容。 1 docker inspect --config container_name --events：\n显示容器的事件日志。 1 docker inspect --events container_name --stat：\n显示容器的统计信息。 1 docker inspect --stat container_name --top：\n显示容器的进程列表。 1 docker inspect --top container_name 请注意，docker inspect 命令的输出通常是一个 JSON 对象，其中包含了大量信息。使用 --format 选项可以方便地提取特定的信息。此外，docker inspect 命令的选项可能会随着 Docker 版本的更新而变化，因此建议查阅 Docker 的官方文档以获取最新的信息和更详细的说明。\n用一副图来表示这些命令的关系：\n对其进行解读为：\n首先，如果想利用docker部署项目，需要先获取项目相关的镜像，安装到本地的镜像如果没有删除可以多次使用。利用已经存在的镜像，用docker run命令，可以生成一个容器，从而运行每一个独立的镜像。\n镜像可以由三个途径进行获取：\n​\t1.通过docker pull从镜像仓库中拉取并下载仓库中已经存在的镜像，利用docker push可以向其中推送。\n​\t2.通过docker load可以安装本地已经存在的镜像包，就不用从镜像仓库里进行下载了，可以通过docker save对镜像进行打包。\n​\t3.通过docker build可以利用DOCKERFILE将本地的文件封装成需要使用的镜像。\n镜像操作：\n​\t1.通过docker images可以查看本地已经有的镜像。\n​\t2.通过docker rmi可以将镜像删除，如果没有删除镜像则可以长期使用。\n容器操作：\n​\t1.利用docker run命令可以创建并且启动容器，相当于已经执行了docker start。\n​\t2.利用docker start可以启动已经关闭的容器。\n​\t3.利用docker stop可以关闭已经开启的容器。\n​\t4.利用docker ps可以查看已经开启的容器。\n​\t6.利用docker rm可以删除已经存在的容器。\n​\t7.利用docker logs可以查看容器运行的日志。\n​\t8.利用docker exec可以对运行的容器进行一些操作和处理。\n​\t9.利用docker inspect查看容器的详细信息。\n补充：\n默认情况下，每次重启虚拟机我们都需要手动启动Docker和Docker中的容器。通过命令可以实现开机自启：\n1 2 3 4 5 # Docker开机自启 systemctl enable docker # Docker容器开机自启 docker update --restart=always [容器名/容器id] 2.1.2.演示 教学环节说明：我们以Nginx为例给大家演示上述命令。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 # 第1步，去DockerHub查看nginx镜像仓库及相关信息 # 第2步，拉取Nginx镜像 docker pull nginx # 第3步，查看镜像 docker images # 结果如下： REPOSITORY TAG IMAGE ID CREATED SIZE nginx latest 605c77e624dd 16 months ago 141MB mysql latest 3218b38490ce 17 months ago 516MB # 第4步，创建并允许Nginx容器 docker run -d --name nginx -p 80:80 nginx # 第5步，查看运行中容器 docker ps # 也可以加格式化方式访问，格式会更加清爽 docker ps --format \u0026#34;table {{.ID}}\\t{{.Image}}\\t{{.Ports}}\\t{{.Status}}\\t{{.Names}}\u0026#34; # 第6步，访问网页，地址：http://虚拟机地址 # 第7步，停止容器 docker stop nginx # 第8步，查看所有容器 docker ps -a --format \u0026#34;table {{.ID}}\\t{{.Image}}\\t{{.Ports}}\\t{{.Status}}\\t{{.Names}}\u0026#34; # 第9步，再次启动nginx容器 docker start nginx # 第10步，再次查看容器 docker ps --format \u0026#34;table {{.ID}}\\t{{.Image}}\\t{{.Ports}}\\t{{.Status}}\\t{{.Names}}\u0026#34; # 第11步，查看容器详细信息 docker inspect nginx # 第12步，进入容器,查看容器内目录 docker exec -it nginx bash # 或者，可以进入MySQL docker exec -it mysql mysql -uroot -p # 第13步，删除容器 docker rm nginx # 发现无法删除，因为容器运行中，强制删除容器 docker rm -f nginx 2.1.3.命令别名 给常用Docker命令起别名，方便我们访问：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # 修改/root/.bashrc文件 vi /root/.bashrc 内容如下： # .bashrc # User specific aliases and functions alias rm=\u0026#39;rm -i\u0026#39; alias cp=\u0026#39;cp -i\u0026#39; alias mv=\u0026#39;mv -i\u0026#39; alias dps=\u0026#39;docker ps --format \u0026#34;table {{.ID}}\\t{{.Image}}\\t{{.Ports}}\\t{{.Status}}\\t{{.Names}}\u0026#34;\u0026#39; alias dis=\u0026#39;docker images\u0026#39; # Source global definitions if [ -f /etc/bashrc ]; then . /etc/bashrc fi 然后，执行命令使别名生效，\n它所执行的是shell脚本。\n1 source /root/.bashrc 接下来，试试看新的命令吧。\n2.2.数据卷 容器是隔离环境，容器内程序的文件、配置、运行时产生的容器都在容器内部，我们要读写容器内的文件非常不方便。大家思考几个问题：\n如果要升级MySQL版本，需要销毁旧容器，那么数据岂不是跟着被销毁了？ MySQL、Nginx容器运行后，如果我要修改其中的某些配置该怎么办？ 我想要让Nginx代理我的静态资源怎么办？ 因此，容器提供程序的运行环境，但是程序运行产生的数据、程序运行依赖的配置都应该与容器解耦。\n2.2.1.什么是数据卷 数据卷（volume）是一个虚拟目录，是容器内目录与宿主机目录之间映射的桥梁。\n以Nginx为例，我们知道Nginx中有两个关键的目录：\nhtml：放置一些静态资源 conf：放置配置文件 如果我们要让Nginx代理我们的静态资源，最好是放到html目录；如果我们要修改Nginx的配置，最好是找到conf下的nginx.conf文件。\n但遗憾的是，容器运行的Nginx所有的文件都在容器内部。所以我们必须利用数据卷将两个目录与宿主机目录关联，方便我们操作。如图：\n在上图中：\n我们创建了两个数据卷：conf、html Nginx容器内部的conf目录和html目录分别与两个数据卷关联。 而数据卷conf和html分别指向了宿主机的/var/lib/docker/volumes/conf/_data目录和/var/lib/docker/volumes/html/_data目录 这样以来，容器内的conf和html目录就 与宿主机的conf和html目录关联起来，我们称为挂载。此时，我们操作宿主机的/var/lib/docker/volumes/html/_data就是在操作容器内的/usr/share/nginx/html/_data目录。只要我们将静态资源放入宿主机对应目录，就可以被Nginx代理了。\n小提示：\n/var/lib/docker/volumes这个目录就是默认的存放所有容器数据卷的目录，其下再根据数据卷名称创建新目录，格式为/数据卷名/_data。\n为什么不让容器目录直接指向宿主机目录呢？\n因为直接指向宿主机目录就与宿主机强耦合了，如果切换了环境，宿主机目录就可能发生改变了。由于容器一旦创建，目录挂载就无法修改，这样容器就无法正常工作了。 但是容器指向数据卷，一个逻辑名称，而数据卷再指向宿主机目录，就不存在强耦合。如果宿主机目录发生改变，只要改变数据卷与宿主机目录之间的映射关系即可。 不过，我们通过由于数据卷目录比较深，不好寻找，通常我们也允许让容器直接与宿主机目录挂载而不使用数据卷，具体参考2.2.3小节。\n那么我想知道既然linux的/home目录为此用户独有的信息储存和管理的区域对吗，它们每个用户无法访问其他人的家目录对吗，那么其它的目录像/var和/lib等就是所有用户共有的吗\n在Linux系统中，/home 目录通常用于存放用户的家目录（home directories），每个用户都有一个以用户名命名的子目录。默认情况下，每个用户的家目录只有该用户和 root 用户（超级用户）有权限访问。这是出于隐私和安全性的考虑。以下是一些关于用户目录和系统目录的说明：\n/home 目录：\n存放用户家目录的地方。 每个用户对自己的家目录拥有读、写、执行权限，而其他用户默认没有访问权限。 root 用户可以访问所有用户的家目录。 用户访问其他用户的家目录：\n普通用户无法访问其他用户的家目录，除非他们具有相应的权限或使用了 sudo 命令。 系统管理员可以使用 sudo 或切换到目标用户来访问其家目录。 /var 目录：\n用于存放经常变动的文件，如日志文件、数据库文件、某些服务的运行时数据等。 这个目录下的内容通常由系统进程和系统管理员管理，普通用户不一定有权限访问或修改这些文件。 /lib 目录：\n存放系统库文件，包括动态链接库（如 .so 文件）和静态库文件。 这些文件是系统和应用程序运行所必需的，通常由系统管理员管理。 系统目录的共享性：\n像 /var、/lib、/usr、/opt 等目录是系统级的目录，它们被所有用户共享。 普通用户通常没有权限修改这些目录下的文件，但可以读取某些特定文件或执行某些程序。 权限管理：\nLinux 使用权限管理系统来控制用户对文件和目录的访问。文件和目录的权限可以由 root 用户或具有适当权限的用户更改。 系统管理员可以通过修改文件权限（使用 chmod 命令）或所有权（使用 chown 命令）来控制谁可以访问或修改文件。 安全性和隐私：\n为了保护用户隐私和系统安全，Linux 提供了一套详细的权限管理机制，确保用户只能访问他们被授权访问的资源。 总的来说，/home 目录是为每个用户提供的私有存储区域，而 /var、/lib 和其他一些系统目录是所有用户共享的资源。Linux 的权限管理系统确保了用户只能访问他们有权访问的文件和目录，从而保护了系统的安全性和用户的隐私。\n那么主目录的/root目录呢\n在 Linux 系统中，/root 是系统管理员（通常称为 root 用户）的主目录。这个目录与普通用户的家目录类似，但它属于 root 用户，并且通常具有不同的权限和用途。\n/root 目录的特点：\n所有权：\n/root 目录属于 root 用户，即系统的超级用户。它的所有者是 root，组通常是 root 或 wheel（取决于具体的 Linux 发行版）。 权限：\n/root 目录的权限通常设置为 700（drwx\u0026mdash;\u0026mdash;），这意味着只有 root 用户可以读取、写入和执行目录中的文件。 内容：\n/root 目录包含 root 用户的个人文件，如配置文件、文档和其他个人数据。它也可能包含系统管理相关的文件和脚本。 安全性：\n由于 root 用户拥有对整个系统的完全控制权，/root 目录通常受到严格的保护，以防止未授权访问。 访问控制：\n普通用户默认情况下无法访问 /root 目录，除非他们使用 sudo 命令或以 root 用户身份登录。 使用 /root 目录的案例：\n系统管理：系统管理员可能会在 /root 目录中存放系统管理脚本或敏感配置文件。 备份和恢复：在系统备份和恢复过程中，/root 目录中的数据可能需要特别处理。 安全审计：在进行安全审计时，可能需要检查 /root 目录中的文件以确保没有安全隐患。 注意事项：\n谨慎操作：由于 root 用户的权限非常高，任何在 /root 目录中执行的操作都可能影响整个系统的稳定性和安全性。因此，建议谨慎操作，并确保了解每个命令的影响。 权限管理：虽然 /root 目录默认对普通用户不可见，但系统管理员仍应定期检查和维护文件权限，以确保系统的安全性。 数据保护：由于 /root 目录中可能包含敏感数据，建议定期备份这些数据，并采取适当的加密和保护措施。 总的来说，/root 目录是 Linux 系统中一个特殊的目录，它为系统管理员提供了一个存放个人文件和系统管理文件的地方。由于其敏感性，建议只有经验丰富的系统管理员才操作这个目录中的文件。\n2.2.2.数据卷命令 数据卷的相关命令有：\n命令 说明 文档地址 docker volume create 创建数据卷 docker volume create docker volume ls 查看所有数据卷 docs.docker.com docker volume rm 删除指定数据卷 docs.docker.com docker volume inspect 查看某个数据卷的详情 docs.docker.com docker volume prune 清除数据卷 docker volume prune 注意：容器与数据卷的挂载要在创建容器时配置，对于创建好的容器，是不能设置数据卷的。而且创建容器的过程中，数据卷会自动创建。\n教学演示环节：演示一下nginx的html目录挂载\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 # 1.首先创建容器并指定数据卷，注意通过 -v 参数来指定数据卷 docker run -d --name nginx -p 80:80 -v html:/usr/share/nginx/html nginx # 2.然后查看数据卷 docker volume ls # 结果 DRIVER VOLUME NAME local 29524ff09715d3688eae3f99803a2796558dbd00ca584a25a4bbc193ca82459f local html # 3.查看数据卷详情 docker volume inspect html # 结果 [ { \u0026#34;CreatedAt\u0026#34;: \u0026#34;2024-05-17T19:57:08+08:00\u0026#34;, \u0026#34;Driver\u0026#34;: \u0026#34;local\u0026#34;, \u0026#34;Labels\u0026#34;: null, \u0026#34;Mountpoint\u0026#34;: \u0026#34;/var/lib/docker/volumes/html/_data\u0026#34;, \u0026#34;Name\u0026#34;: \u0026#34;html\u0026#34;, \u0026#34;Options\u0026#34;: null, \u0026#34;Scope\u0026#34;: \u0026#34;local\u0026#34; } ] # 4.查看/var/lib/docker/volumes/html/_data目录 ll /var/lib/docker/volumes/html/_data # 可以看到与nginx的html目录内容一样，结果如下： 总用量 8 -rw-r--r--. 1 root root 497 12月 28 2021 50x.html -rw-r--r--. 1 root root 615 12月 28 2021 index.html # 5.进入该目录，并随意修改index.html内容 cd /var/lib/docker/volumes/html/_data vi index.html # 6.打开页面，查看效果 # 7.进入容器内部，查看/usr/share/nginx/html目录内的文件是否变化 docker exec -it nginx bash 具体的执行过程\n当你执行 docker run 命令并使用 -v 选项来指定一个数据卷时，Docker 会进行一系列操作来设置和挂载数据卷。下面是你提供的命令的具体过程：\n1 2 3 4 5 docker run -d \\ --name nginx \\ -p 80:80 \\ -v html:/usr/share/nginx/html \\ nginx 解析命令：\nDocker 客户端解析命令行参数，识别出要创建一个名为 nginx 的新容器，将宿主机的 80 端口映射到容器的 80 端口，并挂载一个名为 html 的数据卷到容器的 /usr/share/nginx/html 目录。 检查数据卷：\nDocker 检查本地是否存在名为 html 的数据卷。如果不存在，Docker 会在 /var/lib/docker/volumes 目录下创建一个新的数据卷。 创建数据卷：\n如果数据卷不存在，Docker 会在 /var/lib/docker/volumes/html/_data 下创建必要的目录结构。_data 是 Docker 用来标识数据卷内容的默认后缀。 设置权限：\nDocker 设置数据卷的权限，确保容器内的用户（在这个例子中是 Nginx）有权访问和修改数据卷中的文件。 启动容器：\nDocker 拉取（如果本地没有）并启动 Nginx 镜像，创建一个新的容器实例。 挂载数据卷：\nDocker 将名为 html 的数据卷挂载到容器的 /usr/share/nginx/html 目录。这意味着容器内的 /usr/share/nginx/html 目录实际上是指向宿主机上的 /var/lib/docker/volumes/html/_data 目录。 容器操作：\n在容器内部，任何对 /usr/share/nginx/html 目录的读写操作都会反映在宿主机的 /var/lib/docker/volumes/html/_data 目录。 数据持久性：\n由于数据卷独立于容器的生命周期，即使容器被删除，数据卷中的数据也不会丢失。 这个过程展示了 Docker 数据卷的灵活性和便利性，它允许你轻松地在容器之间共享数据，同时保持数据的持久性和独立性。通过使用数据卷，你可以在不同的容器实例之间迁移数据，或者在容器被删除后保留数据。\n教学演示环节：演示一下MySQL的匿名数据卷\n1 2 3 # 1.查看MySQL容器详细信息 docker inspect mysql # 关注其中.Config.Volumes部分和.Mounts部分 我们关注两部分内容，第一是.Config.Volumes部分：\n1 2 3 4 5 6 7 8 9 { \u0026#34;Config\u0026#34;: { // ... 略 \u0026#34;Volumes\u0026#34;: { \u0026#34;/var/lib/mysql\u0026#34;: {} } // ... 略 } } 可以发现这个容器声明了一个本地目录，需要挂载数据卷，但是数据卷未定义。这就是匿名卷。\n然后，我们再看结果中的.Mounts部分：\n1 2 3 4 5 6 7 8 9 10 11 { \u0026#34;Mounts\u0026#34;: [ { \u0026#34;Type\u0026#34;: \u0026#34;volume\u0026#34;, \u0026#34;Name\u0026#34;: \u0026#34;29524ff09715d3688eae3f99803a2796558dbd00ca584a25a4bbc193ca82459f\u0026#34;, \u0026#34;Source\u0026#34;: \u0026#34;/var/lib/docker/volumes/29524ff09715d3688eae3f99803a2796558dbd00ca584a25a4bbc193ca82459f/_data\u0026#34;, \u0026#34;Destination\u0026#34;: \u0026#34;/var/lib/mysql\u0026#34;, \u0026#34;Driver\u0026#34;: \u0026#34;local\u0026#34;, } ] } 可以发现，其中有几个关键属性：\nName：数据卷名称。由于定义容器未设置容器名，这里的就是匿名卷自动生成的名字，一串hash值。 Source：宿主机目录 Destination : 容器内的目录 上述配置是将容器内的/var/lib/mysql这个目录，与数据卷29524ff09715d3688eae3f99803a2796558dbd00ca584a25a4bbc193ca82459f挂载。于是在宿主机中就有了/var/lib/docker/volumes/29524ff09715d3688eae3f99803a2796558dbd00ca584a25a4bbc193ca82459f/_data这个目录。这就是匿名数据卷对应的目录，其使用方式与普通数据卷没有差别。\n接下来，可以查看该目录下的MySQL的data文件：\n1 ls -l /var/lib/docker/volumes/29524ff09715d3688eae3f99803a2796558dbd00ca584a25a4bbc193ca82459f/_data 注意：每一个不同的镜像，将来创建容器后内部有哪些目录可以挂载，可以参考DockerHub对应的页面\n2.2.3.挂载本地目录或文件 可以发现，数据卷的目录结构较深，如果我们去操作数据卷目录会不太方便。在很多情况下，我们会直接将容器目录与宿主机指定目录挂载。挂载语法与数据卷类似：\n1 2 3 4 # 挂载本地目录 -v 本地目录:容器内目录 # 挂载本地文件 -v 本地文件:容器内文件 注意：本地目录或文件必须以 / 或 ./开头，如果直接以名字开头，会被识别为数据卷名而非本地目录名。\n例如：\n1 2 -v mysql:/var/lib/mysql # 会被识别为一个数据卷叫mysql，运行时会自动创建这个数据卷 -v ./mysql:/var/lib/mysql # 会被识别为当前目录下的mysql目录，运行时如果不存在会创建目录 教学演示，删除并重新创建mysql容器，并完成本地目录挂载：\n挂载/root/mysql/data到容器内的/var/lib/mysql目录 挂载/root/mysql/init到容器内的/docker-entrypoint-initdb.d目录（初始化的SQL脚本目录） 挂载/root/mysql/conf到容器内的/etc/mysql/conf.d目录（这个是MySQL配置文件目录） Docker 中，确定要挂载到容器的具体目录通常取决于你使用的 Docker 镜像的设计和需求。不同的镜像可能会有不同的默认目录用于存放数据、配置文件和初始化脚本。以下是一些常见的方法来确定这些目录：\n查看 Docker 镜像文档：\n许多官方和社区维护的 Docker 镜像在其文档中会详细说明数据卷应该挂载到哪些目录。例如，MySQL 官方镜像的文档会说明数据卷应该挂载到 /var/lib/mysql。 检查 Docker 镜像的 Dockerfile：\nDockerfile 是构建 Docker 镜像的脚本。通过查看 Dockerfile，你可以了解镜像中的目录结构和配置。例如，MySQL 镜像的 Dockerfile 可能会有指令将数据和配置文件放在特定的目录。 查看 Docker 容器的层：\n你可以使用 docker history 命令来查看 Docker 容器的层，这有助于你了解容器内部的文件系统结构。 运行交互式容器：\n你可以运行一个交互式的容器实例，然后使用 docker exec 命令进入容器内部，手动检查目录结构和配置文件的位置。 查看 Docker 镜像的配置文件：\n对于一些镜像，配置文件可能已经包含在镜像中。你可以通过查看这些配置文件来了解它们期望的数据卷挂载点。 使用 Docker 镜像的标签：\n一些 Docker 镜像提供了不同的标签（tags），每个标签可能对应不同的配置。查看这些标签的文档可以帮助你了解正确的挂载点。 社区和论坛：\n如果你无法通过上述方法找到信息，你可以在社区论坛、GitHub 仓库或 Stack Overflow 等平台上搜索或提问。 对于 MySQL 容器，以下是挂载数据卷的一般步骤：\n1 2 3 4 5 6 docker run -d \\ --name mysql \\ -v /root/mysql/data:/var/lib/mysql \\ -v /root/mysql/init:/docker-entrypoint-initdb.d \\ -v /root/mysql/conf:/etc/mysql/conf.d \\ mysql:tag 在这个命令中：\n/var/lib/mysql 是 MySQL 容器内用于存储数据库文件的默认目录。 /docker-entrypoint-initdb.d 是 MySQL 容器内用于初始化数据库时执行 SQL 脚本的默认目录。 /etc/mysql/conf.d 是 MySQL 容器内用于存放配置文件的默认目录。 请注意，tag 应该被替换为具体的 MySQL 镜像标签，例如 5.7 或 latest。确保你使用的镜像标签与你的需求相匹配，并且挂载的宿主机目录对你的应用程序是可访问的。\n在课前资料中已经准备好了mysql的init目录和conf目录：\n以及对应的初始化SQL脚本和配置文件：\n其中，hm.cnf主要是配置了MySQL的默认编码，改为utf8mb4；而hmall.sql则是后面我们要用到的黑马商城项目的初始化SQL脚本。\n我们直接将整个mysql目录上传至虚拟机的/root目录下：\n接下来，我们演示本地目录挂载：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 # 1.删除原来的MySQL容器 docker rm -f mysql # 2.进入root目录 cd ~ # 3.创建并运行新mysql容器，挂载本地目录 docker run -d \\ --name mysql \\ -p 3306:3306 \\ -e TZ=Asia/Shanghai \\ -e MYSQL_ROOT_PASSWORD=123 \\ -v ./mysql/data:/var/lib/mysql \\ -v ./mysql/conf:/etc/mysql/conf.d \\ -v ./mysql/init:/docker-entrypoint-initdb.d \\ mysql # 4.查看root目录，可以发现~/mysql/data目录已经自动创建好了 ls -l mysql # 结果： 总用量 4 drwxr-xr-x. 2 root root 20 5月 19 15:11 conf drwxr-xr-x. 7 polkitd root 4096 5月 19 15:11 data drwxr-xr-x. 2 root root 23 5月 19 15:11 init # 查看data目录，会发现里面有大量数据库数据，说明数据库完成了初始化 ls -l data # 5.查看MySQL容器内数据 # 5.1.进入MySQL docker exec -it mysql mysql -uroot -p123 # 5.2.查看编码表 show variables like \u0026#34;%char%\u0026#34;; # 5.3.结果，发现编码是utf8mb4没有问题 +--------------------------+--------------------------------+ | Variable_name | Value | +--------------------------+--------------------------------+ | character_set_client | utf8mb4 | | character_set_connection | utf8mb4 | | character_set_database | utf8mb4 | | character_set_filesystem | binary | | character_set_results | utf8mb4 | | character_set_server | utf8mb4 | | character_set_system | utf8mb3 | | character_sets_dir | /usr/share/mysql-8.0/charsets/ | +--------------------------+--------------------------------+ # 6.查看数据 # 6.1.查看数据库 show databases; # 结果，hmall是黑马商城数据库 +--------------------+ | Database | +--------------------+ | hmall | | information_schema | | mysql | | performance_schema | | sys | +--------------------+ 5 rows in set (0.00 sec) # 6.2.切换到hmall数据库 use hmall; # 6.3.查看表 show tables; # 结果： +-----------------+ | Tables_in_hmall | +-----------------+ | address | | cart | | item | | order | | order_detail | | order_logistics | | pay_order | | user | +-----------------+ # 6.4.查看address表数据 +----+---------+----------+--------+----------+-------------+---------------+-----------+------------+-------+ | id | user_id | province | city | town | mobile | street | contact | is_default | notes | +----+---------+----------+--------+----------+-------------+---------------+-----------+------------+-------+ | 59 | 1 | 北京 | 北京 | 朝阳区 | 13900112222 | 金燕龙办公楼 | 李佳诚 | 0 | NULL | | 60 | 1 | 北京 | 北京 | 朝阳区 | 13700221122 | 修正大厦 | 李佳红 | 0 | NULL | | 61 | 1 | 上海 | 上海 | 浦东新区 | 13301212233 | 航头镇航头路 | 李佳星 | 1 | NULL | | 63 | 1 | 广东 | 佛山 | 永春 | 13301212233 | 永春武馆 | 李晓龙 | 0 | NULL | +----+---------+----------+--------+----------+-------------+---------------+-----------+------------+-------+ 4 rows in set (0.00 sec) 2.3.镜像 前面我们一直在使用别人准备好的镜像，那如果我要部署一个Java项目，把它打包为一个镜像该怎么做呢？\n2.3.1.镜像结构 要想自己构建镜像，必须先了解镜像的结构。\n之前我们说过，镜像之所以能让我们快速跨操作系统部署应用而忽略其运行环境、配置，就是因为镜像中包含了程序运行需要的系统函数库、环境、配置、依赖。\n因此，自定义镜像本质就是依次准备好程序运行的基础环境、依赖、应用本身、运行配置等文件，并且打包而成。\n举个例子，我们要从0部署一个Java应用，大概流程是这样：\n准备一个linux服务（CentOS或者Ubuntu均可） 安装并配置JDK 上传Jar包 运行jar包 那因此，我们打包镜像也是分成这么几步：\n准备Linux运行环境（java项目并不需要完整的操作系统，仅仅是基础运行环境即可） 安装并配置JDK 拷贝jar包 配置启动脚本 上述步骤中的每一次操作其实都是在生产一些文件（系统运行环境、函数库、配置最终都是磁盘文件），所以镜像就是一堆文件的集合。\n但需要注意的是，镜像文件不是随意堆放的，而是按照操作的步骤分层叠加而成，每一层形成的文件都会单独打包并标记一个唯一id，称为Layer（层）。这样，如果我们构建时用到的某些层其他人已经制作过，就可以直接拷贝使用这些层，而不用重复制作。\n例如，第一步中需要的Linux运行环境，通用性就很强，所以Docker官方就制作了这样的只包含Linux运行环境的镜像。我们在制作java镜像时，就无需重复制作，直接使用Docker官方提供的CentOS或Ubuntu镜像作为基础镜像。然后再搭建其它层即可，这样逐层搭建，最终整个Java项目的镜像结构如图所示：\n2.3.2.Dockerfile 由于制作镜像的过程中，需要逐层处理和打包，比较复杂，所以Docker就提供了自动打包镜像的功能。我们只需要将打包的过程，每一层要做的事情用固定的语法写下来，交给Docker去执行即可。\n而这种记录镜像结构的文件就称为Dockerfile，其对应的语法可以参考官方文档：\nhttps://docs.docker.com/engine/reference/builder/\n其中的语法比较多，比较常用的有：\n指令 说明 示例 FROM 指定基础镜像 FROM centos:6 ENV 设置环境变量，可在后面指令使用 ENV key value COPY 拷贝本地文件到镜像的指定目录 COPY ./xx.jar /tmp/app.jar RUN 执行Linux的shell命令，一般是安装过程的命令 RUN yum install gcc EXPOSE 指定容器运行时监听的端口，是给镜像使用者看的 EXPOSE 8080 ENTRYPOINT 镜像中应用的启动命令，容器运行时调用 ENTRYPOINT java -jar xx.jar 例如，要基于Ubuntu镜像来构建一个Java应用，其Dockerfile内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # 指定基础镜像 FROM ubuntu:16.04 # 配置环境变量，JDK的安装目录、容器内时区 ENV JAVA_DIR=/usr/local ENV TZ=Asia/Shanghai # 拷贝jdk和java项目的包 COPY ./jdk8.tar.gz $JAVA_DIR/ COPY ./docker-demo.jar /tmp/app.jar # 设定时区 RUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime \u0026amp;\u0026amp; echo $TZ \u0026gt; /etc/timezone # 安装JDK RUN cd $JAVA_DIR \\ \u0026amp;\u0026amp; tar -xf ./jdk8.tar.gz \\ \u0026amp;\u0026amp; mv ./jdk1.8.0_144 ./java8 # 配置环境变量 ENV JAVA_HOME=$JAVA_DIR/java8 ENV PATH=$PATH:$JAVA_HOME/bin # 指定项目监听的端口 EXPOSE 8080 # 入口，java项目的启动命令 ENTRYPOINT [\u0026#34;java\u0026#34;, \u0026#34;-jar\u0026#34;, \u0026#34;/app.jar\u0026#34;] 同学们思考一下：以后我们会有很多很多java项目需要打包为镜像，他们都需要Linux系统环境、JDK环境这两层，只有上面的3层不同（因为jar包不同）。如果每次制作java镜像都重复制作前两层镜像，是不是很麻烦。\n所以，就有人提供了基础的系统加JDK环境，我们在此基础上制作java镜像，就可以省去JDK的配置了：\n1 2 3 4 5 6 7 8 9 # 基础镜像 FROM openjdk:11.0-jre-buster # 设定时区 ENV TZ=Asia/Shanghai RUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime \u0026amp;\u0026amp; echo $TZ \u0026gt; /etc/timezone # 拷贝jar包 COPY docker-demo.jar /app.jar # 入口 ENTRYPOINT [\u0026#34;java\u0026#34;, \u0026#34;-jar\u0026#34;, \u0026#34;/app.jar\u0026#34;] 是不是简单多了。\n此段 Dockerfile 定义了一个基于 openjdk:11.0-jre-buster 镜像的 Docker 容器，用于运行一个 Java 应用程序。这个 Dockerfile 中的指令与底层操作系统（如 CentOS 或 Ubuntu）无关，因为它描述的是一个隔离的 Docker 环境，其中包含了运行 Java 应用程序所需的所有依赖。\n这里是 Dockerfile 中各行的含义：\nFROM openjdk:11.0-jre-buster：\n指定基础镜像，这里使用的是包含 OpenJDK 11 运行时环境的官方 Java 镜像，标签为 buster，基于 Debian GNU/Linux 系统。 ENV TZ=Asia/Shanghai：\n设置环境变量 TZ 为上海时区。 RUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime \u0026amp;\u0026amp; echo $TZ \u0026gt; /etc/timezone：\n创建一个符号链接，将 /usr/share/zoneinfo/$TZ 指向 /etc/localtime，设置容器的时区。 将时区信息写入 /etc/timezone 文件。 COPY docker-demo.jar /app.jar：\n将构建的 Java 应用程序 JAR 文件 docker-demo.jar 复制到容器中的 /app.jar。 ENTRYPOINT [\u0026quot;java\u0026quot;, \u0026quot;-jar\u0026quot;, \u0026quot;/app.jar\u0026quot;]：\n设置容器启动时执行的命令，即运行 /app.jar 这个 Java 应用程序。 这个 Dockerfile 适用于任何支持 Docker 的系统，包括 CentOS 和 Ubuntu。它不依赖于宿主机的操作系统，因为 Docker 容器在设计上就是为了提供一致的环境，无论宿主机是什么操作系统。\n要在 CentOS 或 Ubuntu 上使用这个 Dockerfile，你需要确保这些系统上安装了 Docker。然后，你可以在这些系统上执行以下步骤：\n将 Dockerfile 保存到你的项目目录中。 在该目录中运行 docker build 命令来构建镜像。 使用 docker run 命令来启动基于该镜像的容器。 例如：\n1 2 docker build -t my-java-app . docker run -d -p 8080:8080 my-java-app 这里 -t my-java-app 为新创建的镜像指定了一个标签，而 -p 8080:8080 将容器的 8080 端口映射到宿主机的 8080 端口。\n2.3.3.构建镜像 当Dockerfile文件写好以后，就可以利用命令来构建镜像了。\n在课前资料中，我们准备好了一个demo项目及对应的Dockerfile：\n首先，我们将课前资料提供的docker-demo.jar包以及Dockerfile拷贝到虚拟机的/root/demo目录：\n然后，执行命令，构建镜像：\n1 2 3 4 # 进入镜像目录 cd /root/demo # 开始构建 docker build -t docker-demo:1.0 . 命令说明：\ndocker build : 就是构建一个docker镜像\n-t docker-demo:1.0 ：-t参数是指定镜像的名称（repository和tag）\n. : 最后的点是指构建时Dockerfile所在路径，由于我们进入了demo目录，所以指定的是.代表当前目录，也可以直接指定Dockerfile目录：\n1 2 # 直接指定Dockerfile目录 docker build -t docker-demo:1.0 /root/demo 结果：\n查看镜像列表：\n1 2 3 4 5 6 7 # 查看镜像列表： docker images # 结果 REPOSITORY TAG IMAGE ID CREATED SIZE docker-demo 1.0 d6ab0b9e64b9 27 minutes ago 327MB nginx latest 605c77e624dd 16 months ago 141MB mysql latest 3218b38490ce 17 months ago 516MB 然后尝试运行该镜像：\n1 2 3 4 5 6 7 8 9 10 11 12 13 # 1.创建并运行容器 docker run -d --name dd -p 8080:8080 docker-demo:1.0 # 2.查看容器 dps # 结果 CONTAINER ID IMAGE PORTS STATUS NAMES 78a000447b49 docker-demo:1.0 0.0.0.0:8080-\u0026gt;8080/tcp, :::8090-\u0026gt;8090/tcp Up 2 seconds dd f63cfead8502 mysql 0.0.0.0:3306-\u0026gt;3306/tcp, :::3306-\u0026gt;3306/tcp, 33060/tcp Up 2 hours mysql # 3.访问 curl localhost:8080/hello/count # 结果： \u0026lt;h5\u0026gt;欢迎访问黑马商城, 这是您第1次访问\u0026lt;h5\u0026gt; 2.3.4curl命令 curl 是一个功能强大的命令行工具，用于传输数据，支持多种协议，包括 HTTP、HTTPS、FTP、SCP、SFTP 等。它常用于测试和调试网络服务、上传和下载文件、与 RESTful APIs 交互等。\n以下是一些常用的 curl 命令及其选项：\n基本 GET 请求：\n1 curl http://example.com 指定用户代理：\n1 curl -A \u0026#34;Mozilla/5.0\u0026#34; http://example.com 发送 POST 请求：\n1 curl -d \u0026#34;param1=value1\u0026amp;param2=value2\u0026#34; http://example.com/resource 发送 JSON 数据：\n1 curl -H \u0026#34;Content-Type: application/json\u0026#34; -d \u0026#39;{\u0026#34;key1\u0026#34;:\u0026#34;value1\u0026#34;, \u0026#34;key2\u0026#34;:\u0026#34;value2\u0026#34;}\u0026#39; http://example.com/resource 使用用户名和密码进行 HTTP 认证：\n1 curl -u username:password http://example.com 跟随重定向：\n1 curl -L http://example.com 设置请求超时：\n1 curl --connect-timeout 10 http://example.com 下载文件：\n1 curl -O http://example.com/file.zip 上传文件：\n1 curl -F \u0026#34;file=@localfile.txt\u0026#34; http://example.com/upload 使用 HTTPS：\n1 curl -k https://example.com 查看请求头：\n1 curl -I http://example.com 保存响应头到文件：\n1 curl -D headers.txt http://example.com 使用代理：\n1 curl -x http://proxyserver:port http://example.com 设置 Cookie：\n1 curl -b cookies.txt -c cookies.txt http://example.com 禁用 SSL 证书验证（不推荐在生产环境中使用）：\n1 curl -k https://example.com curl 命令的灵活性和多功能性使其成为网络相关任务的必备工具。通过组合不同的选项，你可以执行复杂的网络请求和操作。在使用 curl 时，请确保了解每个选项的含义，以避免不必要的安全风险。\n2.4.网络 上节课我们创建了一个Java项目的容器，而Java项目往往需要访问其它各种中间件，例如MySQL、Redis等。现在，我们的容器之间能否互相访问呢？我们来测试一下\n首先，我们查看下MySQL容器的详细信息，重点关注其中的网络IP地址：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # 1.用基本命令，寻找Networks.bridge.IPAddress属性 docker inspect mysql # 也可以使用format过滤结果 docker inspect --format=\u0026#39;{{range .NetworkSettings.Networks}}{{println .IPAddress}}{{end}}\u0026#39; mysql # 得到IP地址如下： 172.17.0.2 # 2.然后通过命令进入dd容器 docker exec -it dd bash # 3.在容器内，通过ping命令测试网络 ping 172.17.0.2 # 结果 PING 172.17.0.2 (172.17.0.2) 56(84) bytes of data. 64 bytes from 172.17.0.2: icmp_seq=1 ttl=64 time=0.053 ms 64 bytes from 172.17.0.2: icmp_seq=2 ttl=64 time=0.059 ms 64 bytes from 172.17.0.2: icmp_seq=3 ttl=64 time=0.058 ms 发现可以互联，没有问题。\n但是，容器的网络IP其实是一个虚拟的IP，其值并不固定与某一个容器绑定，如果我们在开发时写死某个IP，而在部署时很可能MySQL容器的IP会发生变化，连接会失败。\n所以，我们必须借助于docker的网络功能来解决这个问题，官方文档：\nhttps://docs.docker.com/engine/reference/commandline/network/\n常见命令有：\n命令 说明 文档地址 docker network create 创建一个网络 docker network create docker network ls 查看所有网络 docs.docker.com docker network rm 删除指定网络 docs.docker.com docker network prune 清除未使用的网络 docs.docker.com docker network connect 使指定容器连接加入某网络 docs.docker.com docker network disconnect 使指定容器连接离开某网络 docker network disconnect docker network inspect 查看网络详细信息 docker network inspect 教学演示：自定义网络\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 # 1.首先通过命令创建一个网络 docker network create hmall # 2.然后查看网络 docker network ls # 结果： NETWORK ID NAME DRIVER SCOPE 639bc44d0a87 bridge bridge local 403f16ec62a2 hmall bridge local 0dc0f72a0fbb host host local cd8d3e8df47b none null local # 其中，除了hmall以外，其它都是默认的网络 # 3.让dd和mysql都加入该网络，注意，在加入网络时可以通过--alias给容器起别名 # 这样该网络内的其它容器可以用别名互相访问！ # 3.1.mysql容器，指定别名为db，另外每一个容器都有一个别名是容器名 docker network connect hmall mysql --alias db # 3.2.db容器，也就是我们的java项目 docker network connect hmall dd # 4.进入dd容器，尝试利用别名访问db # 4.1.进入容器 docker exec -it dd bash # 4.2.用db别名访问 ping db # 结果 PING db (172.18.0.2) 56(84) bytes of data. 64 bytes from mysql.hmall (172.18.0.2): icmp_seq=1 ttl=64 time=0.070 ms 64 bytes from mysql.hmall (172.18.0.2): icmp_seq=2 ttl=64 time=0.056 ms # 4.3.用容器名访问 ping mysql # 结果： PING mysql (172.18.0.2) 56(84) bytes of data. 64 bytes from mysql.hmall (172.18.0.2): icmp_seq=1 ttl=64 time=0.044 ms 64 bytes from mysql.hmall (172.18.0.2): icmp_seq=2 ttl=64 time=0.054 ms OK，现在无需记住IP地址也可以实现容器互联了。\n总结：\n在自定义网络中，可以给容器起多个别名，默认的别名是容器名本身 在同一个自定义网络中的容器，可以通过别名互相访问 3.项目部署 好了，我们已经熟悉了Docker的基本用法，接下来可以尝试部署项目了。\n在课前资料中已经提供了一个黑马商城项目给大家，如图：\n项目说明：\nhmall：商城的后端代码 hmall-portal：商城用户端的前端代码 hmall-admin：商城管理端的前端代码 部署的容器及端口说明：\n项目 容器名 端口 备注 hmall hmall 8080 黑马商城后端API入口 hmall-portal nginx 18080 黑马商城用户端入口 hmall-admin 18081 黑马商城管理端入口 mysql mysql 3306 数据库 在正式部署前，我们先删除之前的nginx、dd两个容器：\n1 docker rm -f nginx dd mysql容器中已经准备好了商城的数据，所以就不再删除了。\n3.1.部署Java项目 hmall项目是一个maven聚合项目，使用IDEA打开hmall项目，查看项目结构如图：\n我们要部署的就是其中的hm-service，其中的配置文件采用了多环境的方式：\n其中的application-dev.yaml是部署到开发环境的配置，application-local.yaml是本地运行时的配置。\n查看application.yaml，你会发现其中的JDBC地址并未写死，而是读取变量：\n这两个变量在application-dev.yaml和application-local.yaml中并不相同：\n在dev开发环境（也就是Docker部署时）采用了mysql作为地址，刚好是我们的mysql容器名，只要两者在一个网络，就一定能互相访问。\n我们将项目打包：\n结果：\n将hm-service目录下的Dockerfile和hm-service/target目录下的hm-service.jar一起上传到虚拟机的root目录：\n部署项目：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 1.构建项目镜像，不指定tag，则默认为latest docker build -t hmall . # 2.查看镜像 docker images # 结果 REPOSITORY TAG IMAGE ID CREATED SIZE hmall latest 0bb07b2c34b9 43 seconds ago 362MB docker-demo 1.0 49743484da68 24 hours ago 327MB nginx latest 605c77e624dd 16 months ago 141MB mysql latest 3218b38490ce 17 months ago 516MB # 3.创建并运行容器，并通过--network将其加入hmall网络，这样才能通过容器名访问mysql docker run -d --name hmall --network hmall -p 8080:8080 hmall 测试，通过浏览器访问：http://你的虚拟机地址:8080/search/list\n3.2.部署前端 hmall-portal和hmall-admin是前端代码，需要基于nginx部署。在课前资料中已经给大家提供了nginx的部署目录：\n其中：\nhtml是静态资源目录，我们需要把hmall-portal以及hmall-admin都复制进去 nginx.conf是nginx的配置文件，主要是完成对html下的两个静态资源目录做代理 我们现在要做的就是把整个nginx目录上传到虚拟机的/root目录下：\n然后创建nginx容器并完成两个挂载：\n把/root/nginx/nginx.conf挂载到/etc/nginx/ng``inx.conf 把/root/nginx/html挂载到/usr/share/nginx/html 由于需要让nginx同时代理hmall-portal和hmall-admin两套前端资源，因此我们需要暴露两个端口：\n18080：对应hmall-portal 18081：对应hmall-admin 命令如下：\n1 2 3 4 5 6 7 8 docker run -d \\ --name nginx \\ -p 18080:18080 \\ -p 18081:18081 \\ -v /root/nginx/html:/usr/share/nginx/html \\ -v /root/nginx/nginx.conf:/etc/nginx/nginx.conf \\ --network hmall \\ nginx 测试，通过浏览器访问：http://你的虚拟机ip:18080\n3.3.DockerCompose 大家可以看到，我们部署一个简单的java项目，其中包含3个容器：\nMySQL Nginx Java项目 而稍微复杂的项目，其中还会有各种各样的其它中间件，需要部署的东西远不止3个。如果还像之前那样手动的逐一部署，就太麻烦了。\n而Docker Compose就可以帮助我们实现多个相互关联的Docker容器的快速部署。它允许用户通过一个单独的 docker-compose.yml 模板文件（YAML 格式）来定义一组相关联的应用容器。\n3.3.1.基本语法 docker-compose.yml文件的基本语法可以参考官方文档：\nhttps://docs.docker.com/compose/compose-file/compose-file-v3/\ndocker-compose文件中可以定义多个相互关联的应用容器，每一个应用容器被称为一个服务（service）。由于service就是在定义某个应用的运行时参数，因此与docker run参数非常相似。\n举例来说，用docker run部署MySQL的命令如下：\n1 2 3 4 5 6 7 8 9 10 docker run -d \\ --name mysql \\ -p 3306:3306 \\ -e TZ=Asia/Shanghai \\ -e MYSQL_ROOT_PASSWORD=123 \\ -v ./mysql/data:/var/lib/mysql \\ -v ./mysql/conf:/etc/mysql/conf.d \\ -v ./mysql/init:/docker-entrypoint-initdb.d \\ --network hmall mysql 如果用docker-compose.yml文件来定义，就是这样：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 version: \u0026#34;3.8\u0026#34; services: mysql: image: mysql container_name: mysql ports: - \u0026#34;3306:3306\u0026#34; environment: TZ: Asia/Shanghai MYSQL_ROOT_PASSWORD: 123 volumes: - \u0026#34;./mysql/conf:/etc/mysql/conf.d\u0026#34; - \u0026#34;./mysql/data:/var/lib/mysql\u0026#34; networks: - new networks: new: name: hmall 对比如下：\ndocker run 参数 docker compose 指令 说明 \u0026ndash;name container_name 容器名称 -p ports 端口映射 -e environment 环境变量 -v volumes 数据卷配置 \u0026ndash;network networks 网络 明白了其中的对应关系，相信编写docker-compose文件应该难不倒大家。\n黑马商城部署文件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 version: \u0026#34;3.8\u0026#34; services: mysql: image: mysql container_name: mysql ports: - \u0026#34;3306:3306\u0026#34; environment: TZ: Asia/Shanghai MYSQL_ROOT_PASSWORD: 123 volumes: - \u0026#34;./mysql/conf:/etc/mysql/conf.d\u0026#34; - \u0026#34;./mysql/data:/var/lib/mysql\u0026#34; - \u0026#34;./mysql/init:/docker-entrypoint-initdb.d\u0026#34; networks: - hm-net hmall: build: context: . dockerfile: Dockerfile container_name: hmall ports: - \u0026#34;8080:8080\u0026#34; networks: - hm-net depends_on: - mysql nginx: image: nginx container_name: nginx ports: - \u0026#34;18080:18080\u0026#34; - \u0026#34;18081:18081\u0026#34; volumes: - \u0026#34;./nginx/nginx.conf:/etc/nginx/nginx.conf\u0026#34; - \u0026#34;./nginx/html:/usr/share/nginx/html\u0026#34; depends_on: - hmall networks: - hm-net networks: hm-net: name: hmall 3.3.2.基础命令 编写好docker-compose.yml文件，就可以部署项目了。常见的命令：\nhttps://docs.docker.com/compose/reference/\n基本语法如下：\n1 docker compose [OPTIONS] [COMMAND] 其中，OPTIONS和COMMAND都是可选参数，比较常见的有：\n类型 参数或指令 说明 Options -f 指定compose文件的路径和名称 -p 指定project名称。project就是当前compose文件中设置的多个service的集合，是逻辑概念 Commands up 创建并启动所有service容器 down 停止并移除所有容器、网络 ps 列出所有启动的容器 logs 查看指定容器的日志 stop 停止容器 start 启动容器 restart 重启容器 top 查看运行的进程 exec 在指定的运行中容器中执行命令 教学演示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 # 1.进入root目录 cd /root # 2.删除旧容器 docker rm -f $(docker ps -qa) # 3.删除hmall镜像 docker rmi hmall # 4.清空MySQL数据 rm -rf mysql/data # 5.启动所有, -d 参数是后台启动 docker compose up -d # 结果： [+] Building 15.5s (8/8) FINISHED =\u0026gt; [internal] load build definition from Dockerfile 0.0s =\u0026gt; =\u0026gt; transferring dockerfile: 358B 0.0s =\u0026gt; [internal] load .dockerignore 0.0s =\u0026gt; =\u0026gt; transferring context: 2B 0.0s =\u0026gt; [internal] load metadata for docker.io/library/openjdk:11.0-jre-buster 15.4s =\u0026gt; [1/3] FROM docker.io/library/openjdk:11.0-jre-buster@sha256:3546a17e6fb4ff4fa681c3 0.0s =\u0026gt; [internal] load build context 0.0s =\u0026gt; =\u0026gt; transferring context: 98B 0.0s =\u0026gt; CACHED [2/3] RUN ln -snf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \u0026amp;\u0026amp; echo 0.0s =\u0026gt; CACHED [3/3] COPY hm-service.jar /app.jar 0.0s =\u0026gt; exporting to image 0.0s =\u0026gt; =\u0026gt; exporting layers 0.0s =\u0026gt; =\u0026gt; writing image sha256:32eebee16acde22550232f2eb80c69d2ce813ed099640e4cfed2193f71 0.0s =\u0026gt; =\u0026gt; naming to docker.io/library/root-hmall 0.0s [+] Running 4/4 ✔ Network hmall Created 0.2s ✔ Container mysql Started 0.5s ✔ Container hmall Started 0.9s ✔ Container nginx Started 1.5s # 6.查看镜像 docker compose images # 结果 CONTAINER REPOSITORY TAG IMAGE ID SIZE hmall root-hmall latest 32eebee16acd 362MB mysql mysql latest 3218b38490ce 516MB nginx nginx latest 605c77e624dd 141MB # 7.查看容器 docker compose ps # 结果 NAME IMAGE COMMAND SERVICE CREATED STATUS PORTS hmall root-hmall \u0026#34;java -jar /app.jar\u0026#34; hmall 54 seconds ago Up 52 seconds 0.0.0.0:8080-\u0026gt;8080/tcp, :::8080-\u0026gt;8080/tcp mysql mysql \u0026#34;docker-entrypoint.s…\u0026#34; mysql 54 seconds ago Up 53 seconds 0.0.0.0:3306-\u0026gt;3306/tcp, :::3306-\u0026gt;3306/tcp, 33060/tcp nginx nginx \u0026#34;/docker-entrypoint.…\u0026#34; nginx 54 seconds ago Up 52 seconds 80/tcp, 0.0.0.0:18080-18081-\u0026gt;18080-18081/tcp, :::18080-18081-\u0026gt;18080-18081/tcp 打开浏览器，访问：http://yourIp:8080\n","date":"2024-01-15T00:00:00Z","image":"https://gkxgithub.github.io/p/docker/01ac71a974dd7ba650a4a36d19e53fa_hu1806691600660867427.jpg","permalink":"https://gkxgithub.github.io/p/docker/","title":"docker"},{"content":"\npom.xm文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.4.5\u0026lt;/version\u0026gt; \u0026lt;relativePath/\u0026gt; \u0026lt;!-- lookup parent from repository --\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;groupId\u0026gt;com.itheima\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;reggie_take_out\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;java.version\u0026gt;1.8\u0026lt;/java.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;!--阿里云短信服务--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.aliyun\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;aliyun-java-sdk-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.5.16\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.aliyun\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;aliyun-java-sdk-dysmsapi\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.1.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;compile\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.baomidou\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mybatis-plus-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.4.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.projectlombok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lombok\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.18.20\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;fastjson\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.76\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;commons-lang\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-lang\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.6\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;runtime\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;druid-spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.1.23\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.4.5\u0026lt;/version\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;/project\u0026gt; yml文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 server: port: 8080 spring: application: # 应用的名称，可选 name: reggie_take_out datasource: druid: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/reggie?serverTimezone=Asia/Shanghai\u0026amp;useUnicode=true\u0026amp;characterEncoding=utf-8\u0026amp;zeroDateTimeBehavior=convertToNull\u0026amp;useSSL=false\u0026amp;allowPublicKeyRetrieval=true username: root password: 123456 mybatis-plus: configuration: #在映射实体或者属性时，将数据库中表名和字段名中的下划线去掉，按照驼峰命名法映射 map-underscore-to-camel-case: true log-impl: org.apache.ibatis.logging.stdout.StdOutImpl global-config: db-config: id-type: ASSIGN_ID reggie: path: D:\\ 就配置了个端口，连接池，mybatisp\n启动类 1 2 3 4 5 6 7 8 9 10 @Slf4j @SpringBootApplication @ServletComponentScan @EnableTransactionManagement public class ReggieApplication { public static void main(String[] args) { SpringApplication.run(ReggieApplication.class,args); log.info(\u0026#34;项目启动成功...\u0026#34;); } } @ServletComponentScan @ServletComponentScan 是 Spring Framework 提供的一个注解，它用于在 Spring Boot 应用中自动扫描并注册 Servlet、Filter 和 Listener 组件。这个注解可以替代传统的在 web.xml 文件中配置 Servlet、Filter 和 Listener 的方式，使得配置更加简洁和灵活。\n作用\n在 Spring Boot 应用的启动类（通常是带有 @SpringBootApplication 注解的类）上使用 @ServletComponentScan 注解后，Spring Boot 会在启动时自动扫描并注册所有带有 @WebServlet（控制器）、@WebFilter（过滤器）、@WebListener（监听器）注解的类。这些类将作为 Servlet、Filter 和 Listener 组件被注册到 Servlet 容器中，从而无需手动在 web.xml 文件中进行配置。\n使用方式\n要在 Spring Boot 应用中使用 @ServletComponentScan 注解，只需在启动类上添加该注解即可。例如：\n1 2 3 4 5 6 7 @SpringBootApplication @ServletComponentScan public class MyApplication { public static void main(String[] args) { SpringApplication.run(MyApplication.class, args); } } 注意事项\n扫描范围：@ServletComponentScan 默认扫描启动类所在的包以及子包。如果需要扫描其他包，可以通过设置 @ServletComponentScan 注解的 basePackages 或 basePackageClasses 属性来指定扫描的包。 类名约定：虽然 Spring Boot 不强制要求 Servlet、Filter 和 Listener 类的命名必须遵循特定规则，但按照惯例，这些类的名称通常会以 Servlet、Filter 或 Listener 结尾，以便于识别和区分。 依赖注入：使用 @WebServlet、@WebFilter 和 @WebListener 注解的类通常不由 Spring 容器管理，因此它们无法自动注入 Spring 管理的 Bean。如果需要在这些组件中使用 Spring 的依赖注入功能，可能需要通过其他方式（如使用 ServletContextListener 或 Spring 的 ApplicationListener）来手动设置这些依赖。 总结\n@ServletComponentScan 注解为 Spring Boot 应用提供了一种简洁和灵活的方式来配置 Servlet、Filter 和 Listener 组件。通过使用该注解，开发者可以避免手动在 web.xml 文件中进行繁琐的配置，从而提高开发效率和应用的可维护性。\n@EnableTransactionManagement 是 Spring Framework 提供的一个注解，用于启用声明式事务管理。当你在 Spring 应用中使用了这个注解后，Spring 容器会寻找带有 @Transactional 注解的 bean，并为它们创建代理，以便在方法执行时管理事务。\n@EnableTransactionManagement 启用事务管理：@EnableTransactionManagement 注解告诉 Spring 容器，应用将使用声明式事务管理。这意味着你可以通过在方法或类上使用 @Transactional 注解来声明事务的边界和规则。 自动代理：Spring 会自动为那些带有 @Transactional 注解的 bean 创建代理。这些代理会在方法调用前后执行必要的事务管理逻辑，如开启事务、提交事务或回滚事务。 配置事务管理器：虽然 @EnableTransactionManagement 本身不直接配置事务管理器，但它会触发 Spring 查找并注册一个事务管理器 bean。通常，你需要通过 Java 配置或 XML 配置来定义一个 PlatformTransactionManager 类型的 bean。 使用方式\n要在 Spring 应用中使用 @EnableTransactionManagement 注解，你只需在配置类上添加该注解即可。例如：\n1 2 3 4 5 6 7 8 9 10 11 @Configuration @EnableTransactionManagement public class TransactionConfig { // 配置事务管理器 @Bean public PlatformTransactionManager transactionManager(EntityManagerFactory emf) { return new JpaTransactionManager(emf); } // 其他配置... } 在这个例子中，TransactionConfig 是一个配置类，它使用了 @EnableTransactionManagement 注解来启用事务管理，并通过 @Bean 注解定义了一个 JpaTransactionManager 类型的 bean 作为事务管理器。\n注意事项\n事务管理器类型：你需要根据你的持久化技术（如 JPA、JDBC、Hibernate 等）选择适当的事务管理器类型。 代理类型：Spring 支持两种代理类型：JDK 动态代理和 CGLIB 代理。默认情况下，如果目标 bean 实现了至少一个接口，Spring 将使用 JDK 动态代理。如果目标 bean 没有实现任何接口，Spring 将使用 CGLIB 代理。你可以通过 @EnableTransactionManagement 注解的 proxyTargetClass 属性来显式指定代理类型。 事务传播行为：在 @Transactional 注解中，你可以指定事务的传播行为、隔离级别、超时时间等属性来控制事务的行为。 总结\n@EnableTransactionManagement 注解是 Spring 框架中用于启用声明式事务管理的重要注解。通过使用该注解，并结合 @Transactional 注解，你可以轻松地在 Spring 应用中实现事务管理，从而提高数据的一致性和完整性。\n@SpringBootApplication @SpringBootApplication 注解是 Spring Boot 项目的核心注解，它结合了多个其他 Spring 框架中的注解，以简化 Spring Boot 应用的配置。这个注解主要用于 Spring Boot 应用的主类上，以快速启动并配置应用。具体来说，@SpringBootApplication 注解执行了以下关键操作：\n定义配置类\n：\n@SpringBootApplication 实际上是 @Configuration 的一个特殊形式，用于定义配置类。在 Spring 中，@Configuration 类使用 @Bean 注解来定义和初始化对象，这些对象随后会被 Spring 容器管理。 @SpringBootConfiguration 不仅声明了当前类是一个配置类，还使得该类能够使用 Spring Boot 特有的自动配置功能。 启用自动配置\n：\n@EnableAutoConfiguration 注解内部包含了 @AutoConfigurationPackage，这个注解的作用是帮助 Spring Boot 找到主配置类所在的包，进而找到当前项目中有哪些配置类，并将它们返回给 Spring 容器。 @EnableAutoConfiguration 注解还借助 @Import(AutoConfigurationImportSelector.class) 的支持，收集和注册特定场景相关的 bean 定义。它会自动根据项目中添加的 jar 依赖来配置 Spring 应用。例如，如果检测到 classpath 中有 H2 数据库驱动，Spring Boot 就会自动配置一个嵌入式 H2 数据库。 启用组件扫描\n：\n@ComponentScan 注解用于启用组件扫描。当它被使用时，Spring Boot 会自动扫描当前包及其子包下的所有组件（如使用 @Component、@Service、@Repository、@Controller 等注解的类），并将这些组件注册为 Spring 应用上下文中的 bean。 通过这种方式，开发者无需显式地在配置类中定义每一个 bean，Spring Boot 会自动发现并管理这些 bean。 元注解功能\n：\n@SpringBootApplication 还使用了 @Documented、@Inherited、@Retention(RetentionPolicy.RUNTIME) 和 @Target(ElementType.TYPE) 等元注解，这些注解提供了关于 @SpringBootApplication 注解本身的额外信息，如文档记录、继承行为、保留策略和适用目标等。 允许自定义配置\n：\n@SpringBootApplication 注解还允许开发者通过其属性进行自定义配置。例如，使用 exclude 属性可以排除特定的自动配置类，以避免不需要的自动配置。 综上所述，@SpringBootApplication 注解通过结合多个 Spring 框架的注解，简化了 Spring Boot 应用的配置过程。它使得开发者能够快速地启动并运行一个 Spring Boot 应用，而无需进行大量的手动配置。在使用 @SpringBootApplication 注解时，主类通常放在根包名下，以确保能够扫描到所有的组件。\nWebMvcConfig 将文件和路径进行了映射处理，并且扩展了消息转换器。\n利用@Configuration注解，将其被Spring Boot自动扫描并加载到容器中，但是这一过程需要满足条件，如果配置类不在默认扫描的包路径下，可以通过在启动类上添加@ComponentScan注解来指定额外的扫描路径。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 @Slf4j @Configuration public class WebMvcConfig extends WebMvcConfigurationSupport { /** * 设置静态资源映射 * @param registry */ @Override protected void addResourceHandlers(ResourceHandlerRegistry registry) { log.info(\u0026#34;开始进行静态资源映射...\u0026#34;); registry.addResourceHandler(\u0026#34;/backend/**\u0026#34;).addResourceLocations(\u0026#34;classpath:/backend/\u0026#34;); registry.addResourceHandler(\u0026#34;/front/**\u0026#34;).addResourceLocations(\u0026#34;classpath:/front/\u0026#34;); } /** * 扩展mvc框架的消息转换器 * @param converters */ @Override protected void extendMessageConverters(List\u0026lt;HttpMessageConverter\u0026lt;?\u0026gt;\u0026gt; converters) { log.info(\u0026#34;扩展消息转换器...\u0026#34;); //创建消息转换器对象 MappingJackson2HttpMessageConverter messageConverter = new MappingJackson2HttpMessageConverter(); //设置对象转换器，底层使用Jackson将Java对象转为json messageConverter.setObjectMapper(new JacksonObjectMapper()); //将上面的消息转换器对象追加到mvc框架的转换器集合中 converters.add(0,messageConverter); } } WebMvcConfigurationSupport 在Spring MVC或Spring Boot MVC项目中，选择继承WebMvcConfigurationSupport类通常是为了实现自定义的Web MVC配置。这个类提供了许多可重写的方法，允许开发者根据需要对Spring MVC的默认行为进行定制。以下是关于继承WebMvcConfigurationSupport类的详细解答：\n为什么要继承WebMvcConfigurationSupport类？\n自定义配置：通过继承WebMvcConfigurationSupport类，开发者可以重写其中的方法来实现自定义的Web MVC配置。例如，可以添加自定义的拦截器、消息转换器、视图解析器等。 覆盖默认配置：在Spring Boot中，默认情况下会使用WebMvcAutoConfiguration类进行自动配置。然而，当开发者继承WebMvcConfigurationSupport类并实现自定义配置时，这种自动配置会被禁用。这意味着开发者可以完全控制Web MVC的配置，而无需受到Spring Boot默认配置的限制。 WebMvcConfigurationSupport类的作用\n提供基础配置：WebMvcConfigurationSupport类是Spring MVC配置的基础类，它提供了一系列与Web MVC相关的配置方法。这些方法包括添加拦截器、配置消息转换器、设置视图解析器等。 支持自定义扩展：通过重写WebMvcConfigurationSupport类中的方法，开发者可以根据项目需求进行自定义扩展。例如，可以添加额外的拦截器来处理特定的请求，或者配置自定义的消息转换器来处理不同类型的HTTP请求和响应。 如何使用WebMvcConfigurationSupport类？\n创建配置类：首先，需要创建一个新的配置类，并使其继承WebMvcConfigurationSupport类。 重写方法：在配置类中，根据需要重写WebMvcConfigurationSupport类中的方法。例如，如果希望添加自定义的拦截器，可以重写addInterceptors方法。 添加注解：在配置类上添加@Configuration注解，以将其标记为Spring的配置类。此外，由于WebMvcConfigurationSupport类本身没有被打上@Configuration注解，因此需要在自定义的配置类上显式添加该注解。 启动应用：完成配置后，启动Spring Boot应用。此时，自定义的Web MVC配置将生效，并覆盖Spring Boot的默认配置。 需要注意的是，一旦选择了继承WebMvcConfigurationSupport类来实现自定义配置，就意味着放弃了Spring Boot提供的Web MVC自动配置。因此，在重写方法时需要谨慎考虑，确保不会引入不必要的复杂性或影响应用的性能。如果只需要对默认配置进行简单的修改或扩展，建议使用实现WebMvcConfigurer接口的方式，这种方式可以在保留Spring Boot自动配置的基础上添加自定义配置。\n@Configuration 在Spring Boot项目中，带有@Configuration注解的类通常会被Spring Boot自动扫描并加载到容器中，但这一过程还需满足一些基本条件。以下是对这一问题的详细解答：\n基本条件\n注解的使用：类上必须明确标注@Configuration注解，以声明该类为配置类。 包扫描：默认情况下，Spring Boot会从启动类所在的包及其子包开始扫描带有@Component、@Service、@Repository、@Controller以及@Configuration等注解的类。因此，如果配置类位于这些默认扫描的包路径下，则无需额外操作。 非抽象类：带有@Configuration注解的类必须是非抽象的，因为Spring需要实例化这些类以创建Bean。 额外操作（如有必要）\n指定扫描路径：如果配置类不在默认扫描的包路径下，可以通过在启动类上添加@ComponentScan注解来指定额外的扫描路径。例如： 1 2 3 4 5 6 7 @SpringBootApplication @ComponentScan(basePackages = {\u0026#34;com.example.config\u0026#34;, \u0026#34;com.another.package\u0026#34;}) public class MyApplication { public static void main(String[] args) { SpringApplication.run(MyApplication.class, args); } } 导入配置类：如果配置类位于不同的模块或项目中，并且不希望或不能通过包扫描来加载，可以使用@Import注解在启动类或另一个配置类中导入这些配置类。例如： 1 2 3 4 5 6 7 @SpringBootApplication @Import(ExternalConfig.class) public class MyApplication { public static void main(String[] args) { SpringApplication.run(MyApplication.class, args); } } 其中，ExternalConfig是一个位于不同模块或项目中的配置类。\n启用特定配置：在某些情况下，可能需要通过@Enable系列注解来启用特定的配置或功能。例如，@EnableWebMvc用于启用Spring MVC配置，@EnableTransactionManagement用于启用声明式事务管理等。这些注解通常与特定的配置类结合使用。 总结\n通常情况下，只要满足基本条件（注解的使用、包扫描、非抽象类），带有@Configuration注解的类就会被Spring Boot自动扫描并加载到容器中。如果配置类位于非默认扫描路径下或需要跨模块/项目导入，则需要进行额外的操作来指定扫描路径或导入配置类。\n检查是否登录的过滤器 其实此处可以利用TOKEN、JWT，可以参考面试篇查看。\n利用@WebFilter将类指定为过滤器，并且已经对启动类进行配置，对带有此注解的类进行扫描了。\n重写doFilter方法，对于将参数进行强转了：\nJava的Servlet过滤器（Filter）的doFilter方法中，传入的ServletRequest和ServletResponse对象通常是HttpServletRequest和HttpServletResponse的父类实例，但实际上在Web应用程序中，我们通常处理的是HTTP请求和响应，这意味着我们更关心这些对象的HTTP特定属性和方法。\n具体来说，当你想要访问请求中的HTTP头部、参数、会话（session）等信息，或者想要控制HTTP响应的状态码、设置头部、发送内容等时，你会需要使用HttpServletRequest和HttpServletResponse接口中定义的方法。\n由于Java是静态类型语言，你不能直接在ServletRequest或ServletResponse对象上调用这些接口中的方法，因为它们没有这些方法（这些方法只在HttpServletRequest和HttpServletResponse接口中定义）。因此，你需要将ServletRequest和ServletResponse对象强制转换（强制类型转换，或称为“向下转型”）为HttpServletRequest和HttpServletResponse，以便能够访问和使用这些HTTP特定的方法和属性。\n通过获取了访问的路径，判断是否需要进行拦截或者放行。\n利用request.getRequestURI();获取到请求的uri，定义一些不需要处理的路径。如果路径需要进行处理，那么就需要判断用户是否登录了，判断request.getSession().getAttribute(\u0026ldquo;employee\u0026rdquo;) != null，看session中是否有\u0026quot;employee\u0026quot;的属性，因为当时登录的时候，如果成功登录了的话，已经将相应的信息存入了session当中了，request.getSession().setAttribute(\u0026ldquo;employee\u0026rdquo;,emp.getId());\n如果成功登录了的话利用filterChain.doFilter(request,response);将请求放行。退出登录的时候会request.getSession().removeAttribute(\u0026ldquo;employee\u0026rdquo;);。\n如果没有登录就会返回response.getWriter().write(JSON.toJSONString(R.error(\u0026ldquo;NOTLOGIN\u0026rdquo;)));。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 /** * 检查用户是否已经完成登录 */ @WebFilter(filterName = \u0026#34;loginCheckFilter\u0026#34;,urlPatterns = \u0026#34;/*\u0026#34;) @Slf4j public class LoginCheckFilter implements Filter{ //路径匹配器，支持通配符 public static final AntPathMatcher PATH_MATCHER = new AntPathMatcher(); @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException { HttpServletRequest request = (HttpServletRequest) servletRequest; HttpServletResponse response = (HttpServletResponse) servletResponse; //1、获取本次请求的URI String requestURI = request.getRequestURI();// /backend/index.html log.info(\u0026#34;拦截到请求：{}\u0026#34;,requestURI); //定义不需要处理的请求路径 String[] urls = new String[]{ \u0026#34;/employee/login\u0026#34;, \u0026#34;/employee/logout\u0026#34;, \u0026#34;/backend/**\u0026#34;, \u0026#34;/front/**\u0026#34;, \u0026#34;/common/**\u0026#34;, \u0026#34;/user/sendMsg\u0026#34;, \u0026#34;/user/login\u0026#34; }; //2、判断本次请求是否需要处理 boolean check = check(urls, requestURI); //3、如果不需要处理，则直接放行 if(check){ log.info(\u0026#34;本次请求{}不需要处理\u0026#34;,requestURI); filterChain.doFilter(request,response); return; } //4-1、判断登录状态，如果已登录，则直接放行 if(request.getSession().getAttribute(\u0026#34;employee\u0026#34;) != null){ log.info(\u0026#34;用户已登录，用户id为：{}\u0026#34;,request.getSession().getAttribute(\u0026#34;employee\u0026#34;)); Long empId = (Long) request.getSession().getAttribute(\u0026#34;employee\u0026#34;); BaseContext.setCurrentId(empId); filterChain.doFilter(request,response); return; } //4-2、判断登录状态，如果已登录，则直接放行 if(request.getSession().getAttribute(\u0026#34;user\u0026#34;) != null){ log.info(\u0026#34;用户已登录，用户id为：{}\u0026#34;,request.getSession().getAttribute(\u0026#34;user\u0026#34;)); Long userId = (Long) request.getSession().getAttribute(\u0026#34;user\u0026#34;); BaseContext.setCurrentId(userId); filterChain.doFilter(request,response); return; } log.info(\u0026#34;用户未登录\u0026#34;); //5、如果未登录则返回未登录结果，通过输出流方式向客户端页面响应数据 response.getWriter().write(JSON.toJSONString(R.error(\u0026#34;NOTLOGIN\u0026#34;))); return; } /** * 路径匹配，检查本次请求是否需要放行 * @param urls * @param requestURI * @return */ public boolean check(String[] urls,String requestURI){ for (String url : urls) { boolean match = PATH_MATCHER.match(url, requestURI); if(match){ return true; } } return false; } } AntPathMatcher AntPathMatcher 是 Spring 框架中用于路径匹配的一个工具类，它基于 Apache Ant 的路径模式，提供了一套强大的路径匹配机制。以下是 AntPathMatcher 的主要使用方法和场景：\n使用方法\n创建 AntPathMatcher 对象 首先，你需要创建一个 AntPathMatcher 对象：\n1 2 3 java复制代码 AntPathMatcher matcher = new AntPathMatcher(); 路径匹配 使用 match(String pattern, String path) 方法来检查一个路径是否与指定的模式相匹配：\n1 2 3 java复制代码 boolean isMatch = matcher.match(pattern, path); 其中 pattern 是一个包含 Ant 风格匹配模式的字符串，path 是要匹配的路径字符串。\n提取路径变量 如果你使用了路径变量（如 /user/{id}/info），你可以使用 extractPathWithinPattern(String pattern, String path) 或 extractUriTemplateVariables(String pattern, String path) 方法来提取这些变量：\n1 2 String variable = matcher.extractPathWithinPattern(pattern, path); // 提取路径片段，不包括变量名 Map\u0026lt;String, String\u0026gt; variables = matcher.extractUriTemplateVariables(pattern, path); // 提取路径中的变量并放入 Map 使用场景\nURL 映射 在 Spring MVC 中，AntPathMatcher 常用于定义 URL 映射规则。例如，你可以使用 @GetMapping(\u0026quot;/users/{id}\u0026quot;) 来匹配 /users/123 这样的 URL，其中 {id} 是一个路径变量。 安全控制 在安全控制场景中，你可能需要过滤掉某些请求 URL。使用 AntPathMatcher，你可以轻松定义需要过滤的模式，并检查请求 URL 是否与之匹配。 路由和转发 在 API 网关或路由服务中，AntPathMatcher 可以用于匹配传入的请求 URL，并根据匹配结果决定将其路由到哪个后端服务。 日志记录 你可以使用 AntPathMatcher 来过滤出不需要记录日志的请求 URL，或者为不同类型的请求 URL 设置不同的日志级别。 文件访问控制 如果你需要基于路径模式来控制对文件的访问权限，AntPathMatcher 可以帮助你实现这一功能。 特性\n通配符：AntPathMatcher 支持两种通配符：? 表示任意一个字符，* 表示零个或多个字符。 变量绑定：你可以在模式中使用 {variableName} 来定义路径变量，并使用 extractUriTemplateVariables 方法提取这些变量。 多重映射：你可以定义一个包含多个模式的数组，并使用 AntPathMatcher 一次性检查多个模式是否与给定路径匹配。 总结\nAntPathMatcher 是一个功能强大的路径匹配工具，它基于 Apache Ant 的路径模式，提供了灵活且易于使用的路径匹配机制。在 Spring 框架和其他 Java Web 应用程序中，它被广泛用于 URL 映射、安全控制、路由转发等场景。\nThreadLocal 使用了一个工具类对它进行了封装，使其能更方便使用。此处用它的作用就是可以做到自动填充当前登录的用户名，因为此时无法获取到HttpServletRequest或者session，因此就并没有很好的方法获取，就使用ThreadLocal来实现。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public class BaseContext { private static ThreadLocal\u0026lt;Long\u0026gt; threadLocal = new ThreadLocal\u0026lt;\u0026gt;(); /** * 设置值 * @param id */ public static void setCurrentId(Long id){ threadLocal.set(id); } /** * 获取值 * @return */ public static Long getCurrentId(){ return threadLocal.get(); } } 1 2 3 4 5 6 7 8 9 if(request.getSession().getAttribute(\u0026#34;employee\u0026#34;) != null){ log.info(\u0026#34;用户已登录，用户id为：{}\u0026#34;,request.getSession().getAttribute(\u0026#34;employee\u0026#34;)); Long empId = (Long) request.getSession().getAttribute(\u0026#34;employee\u0026#34;); BaseContext.setCurrentId(empId); filterChain.doFilter(request,response); return; } ThreadLocal的详细介绍和使用\n一、ThreadLocal的详细介绍\nThreadLocal是Java并发包（java.util.concurrent）中提供的一个类，用于解决多线程环境下变量共享所带来的线程安全问题。其主要作用是在多线程环境下为每个线程提供一个独立的变量副本，使得每个线程在访问ThreadLocal时获取到的都是自己的私有变量，而不是共享的同一个变量。这样，ThreadLocal能够隔离线程间的数据共享，提供线程级别的数据存储。\n定义与特点 ThreadLocal类提供了一种线程局部变量的机制，使得每个线程都可以独立地改变自己的变量副本，而不会影响到其他线程的变量副本。 每个线程在访问ThreadLocal变量时，都会获取到属于自己的、独立的变量副本。 应用场景 线程上下文信息传递：例如在web应用中，服务器接收到请求后，需要在不同的过滤器、处理器链路中传递用户会话信息，此时可以将这些信息存放在ThreadLocal中。 避免同步开销：对于那些只需要在单个线程内保持状态，不需要线程间共享的数据，使用ThreadLocal可以避免使用锁带来的性能损耗。 数据库连接、事务管理：在多线程环境下，每个线程有自己的数据库连接，可以使用ThreadLocal存储当前线程的数据库连接对象，以确保线程安全。 核心方法 set(T value)：设置当前线程的变量副本值。 get()：获取当前线程所对应的变量副本的值，如果此线程从未设置过值，那么返回null或者初始值（如果有的话）。 remove()：删除当前线程保存的变量副本，如果不主动清理，可能会造成内存泄露。 内存泄露问题 当线程结束生命周期后，如果没有显式调用remove()方法，存储在线程本地变量表中的ThreadLocal变量副本不会自动删除，这可能导致它们无法被垃圾回收，尤其是在线程池场景中，如果线程会被复用，这个问题更为突出。 线程安全的误解 虽然ThreadLocal保证了每个线程只能访问自己的变量副本，但是它并不能保证变量副本本身的线程安全性。即如果存放在ThreadLocal中的对象不是线程安全的，多个线程通过各自的ThreadLocal访问相同的非线程安全对象时，还需要采取额外的同步措施。 二、ThreadLocal的使用\n基本用法 创建一个ThreadLocal变量。 在每个线程内部，使用set(T value)方法给当前线程设置一个本地变量的值。 在需要的时候，使用get()方法来获取当前线程关联的本地变量的值。 使用完毕后，调用remove()方法清除当前线程的ThreadLocal变量。 代码示例 以下是一个简单的代码示例，展示了ThreadLocal的基本用法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 import java.lang.ThreadLocal; public class ThreadLocalExample { // 定义一个ThreadLocal变量，这里存储的是String类型 public static final ThreadLocal\u0026lt;String\u0026gt; threadLocal = new ThreadLocal\u0026lt;\u0026gt;(); public static void main(String[] args) { // 创建两个线程并启动 new Thread(() -\u0026gt; { // 设置当前线程的ThreadLocal变量 threadLocal.set(\u0026#34;Thread A\u0026#34;); System.out.println(\u0026#34;In Thread A: \u0026#34; + threadLocal.get()); }).start(); new Thread(() -\u0026gt; { // 设置当前线程的ThreadLocal变量，不影响其他线程 threadLocal.set(\u0026#34;Thread B\u0026#34;); System.out.println(\u0026#34;In Thread B: \u0026#34; + threadLocal.get()); // 清理本线程的ThreadLocal变量 threadLocal.remove(); // 此时尝试获取已经移除的ThreadLocal变量，应该返回null System.out.println(\u0026#34;After remove in Thread B: \u0026#34; + threadLocal.get()); }).start(); } } 在这个示例中，我们创建了一个ThreadLocal\u0026lt;String\u0026gt;类型的静态变量threadLocal。在每个线程内部，我们使用set(String value)方法给当前线程设置了一个本地变量的值。同样在每个线程内部，我们使用get()方法来获取当前线程关联的本地变量的值。注意，每个线程只能获取到自己设置的那个值，相互之间不会干扰。在第二个线程里展示了如何使用remove()方法清除当前线程的ThreadLocal变量。\n注意事项 在使用完ThreadLocal对象后，在finally中调用ThreadLocal对象的remove()方法，以避免内存泄露。 不要过度使用ThreadLocal，以免代码逻辑变得复杂，增加维护难度。 当线程间本来就需要共享数据时，不应该滥用ThreadLocal避免数据交换。 总之，ThreadLocal是一个在多线程环境下非常有用的工具类，它可以帮助我们避免线程安全问题，并提供线程级别的数据存储。但是，在使用时需要注意内存泄露问题和线程安全的误解等风险。\nMybatisP的自动填充功能 有时候有一些数据如果前端并不会传过来，并且后端存入数据库的时候还需要，那么此时就可以使用自动填充功能来实现了。\n例如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 @Data public class SetmealDish implements Serializable { private static final long serialVersionUID = 1L; private Long id; //套餐id private Long setmealId; //菜品id private Long dishId; //菜品名称 （冗余字段） private String name; //菜品原价 private BigDecimal price; //份数 private Integer copies; //排序 private Integer sort; @TableField(fill = FieldFill.INSERT) private LocalDateTime createTime; @TableField(fill = FieldFill.INSERT_UPDATE) private LocalDateTime updateTime; @TableField(fill = FieldFill.INSERT) private Long createUser; @TableField(fill = FieldFill.INSERT_UPDATE) private Long updateUser; //是否删除 private Integer isDeleted; } @TableField 写到需要自动填充的属性上面，并且需要指定fill的属性\n有一下几种类型：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public enum FieldFill { /** * 默认不处理 */ DEFAULT, /** * 插入时填充字段 */ INSERT, /** * 更新时填充字段 */ UPDATE, /** * 插入和更新时填充字段 */ INSERT_UPDATE } MetaObjectHandler 接着还需要对需要对自动填充进行配置，例如插入和更新时候分别怎样进行配置\n1.实现MetaObjectHandler\n2.类上面加@Component注解，将其纳入spring容器管理\n3.重写insertFill和updateFill方法，利用metaObject.setValue()对相应的属性进行赋值。例如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 @Component @Slf4j public class MyMetaObjecthandler implements MetaObjectHandler { /** * 插入操作，自动填充 * @param metaObject */ @Override public void insertFill(MetaObject metaObject) { log.info(\u0026#34;公共字段自动填充[insert]...\u0026#34;); log.info(metaObject.toString()); metaObject.setValue(\u0026#34;createTime\u0026#34;, LocalDateTime.now()); metaObject.setValue(\u0026#34;updateTime\u0026#34;,LocalDateTime.now()); metaObject.setValue(\u0026#34;createUser\u0026#34;,BaseContext.getCurrentId()); metaObject.setValue(\u0026#34;updateUser\u0026#34;,BaseContext.getCurrentId()); } /** * 更新操作，自动填充 * @param metaObject */ @Override public void updateFill(MetaObject metaObject) { log.info(\u0026#34;公共字段自动填充[update]...\u0026#34;); log.info(metaObject.toString()); long id = Thread.currentThread().getId(); log.info(\u0026#34;线程id为：{}\u0026#34;,id); metaObject.setValue(\u0026#34;updateTime\u0026#34;,LocalDateTime.now()); metaObject.setValue(\u0026#34;updateUser\u0026#34;,BaseContext.getCurrentId()); } } RESTFul风格以及接收请求的方法 RESTFul，即RESTful，是一种面向资源的软件架构风格，它是Representational State Transfer（表示状态转移）的缩写。以下是对RESTful风格的详细介绍：\n一、设计目标\nRESTful风格的设计目标是在分布式系统中实现统一的接口和交互方式，以提高系统的可扩展性、可靠性和可维护性。\n二、核心特点\n资源导向：RESTful架构将整个系统看作一组资源的集合，每个资源都有一个唯一的URI（统一资源标识符）。客户端通过URI来访问资源，服务器通过HTTP方法来操作资源。 统一接口：RESTful架构定义了一组统一的接口，包括HTTP方法（如GET、POST、PUT、DELETE等）、URI和HTTP状态码等。客户端和服务器之间的通信只需要遵循这些接口，就可以实现系统的交互。 无状态：RESTful架构是无状态的，每个请求都是独立的，服务器不需要维护客户端的状态信息。这样可以提高系统的可伸缩性和可靠性。 可缓存性：RESTful架构支持缓存机制，客户端可以通过缓存来提高系统的性能和可靠性。 三、HTTP方法\n在RESTful风格中，常见的HTTP方法包括：\nGET：用于获取资源。 POST：用于创建资源（在某些情况下，也可以用于更新资源）。 PUT：用于更新服务端的资源的全部信息。 DELETE：用于删除服务端的资源。 此外，还有PATCH方法，它用于更新服务端的资源的部分信息。\n四、资源的表现形式\n在RESTful架构中，资源的表现形式通常是XML或HTML。客户端通过操作资源的表现形式来操作资源。\n五、设计原则\n使用名词而不是动词：在定义URI时，应使用名词来表示资源，而不是动词。例如，使用“/users”来表示用户资源，而不是“/getAllUsers”。 GET方法和查询参数不应涉及状态改变：应使用PUT、POST和DELETE方法来改变状态，而不是GET方法。同时，查询参数应仅用于过滤和排序资源，而不应改变资源的状态。 保持URI的简洁和一致性：URI应简洁明了，易于理解和记忆。同时，应保持URI的一致性，以便于客户端正确地访问和操作资源。 使用HTTP头声明序列化格式：在客户端和服务端之间通信时，应使用HTTP头来声明序列化格式，以确保双方都能正确地解析和处理数据。 六、优势\n简化客户端与服务器的交互：通过定义一组统一的接口和交互方式，RESTful风格可以简化客户端与服务器的交互过程，降低通信的复杂性。 提高系统的可扩展性和可靠性：由于RESTful风格是无状态的，每个请求都是独立的，因此可以提高系统的可扩展性和可靠性。同时，支持缓存机制也可以进一步提高系统的性能。 易于实现和维护：RESTful风格基于HTTP协议的各种特性来实现资源的标识、状态的转移、缓存、安全性等功能，因此易于实现和维护。 综上所述，RESTful风格是一种基于HTTP协议的面向资源的软件架构风格，它通过定义一组统一的接口和交互方式，提高了系统的可扩展性、可靠性和可维护性。在实际开发中，应遵循RESTful风格的设计原则和设计规范，以确保系统的稳定性和高效性。\n后端接收数据的方法 Java Web开发中，前端数据可以通过多种方式传输到后端，并且后端会相应地解析这些请求以获取数据。以下是一些常见的数据传输方式以及后端如何接收这些数据的情况：\n1. 通过URL查询参数传输\n方式：前端将数据作为查询参数附加到URL的末尾。\n示例：http://example.com/resource?param1=value1\u0026amp;param2=value2\n接收：在后端，你可以使用@RequestParam注解来接收这些参数。\n1 2 3 4 @GetMapping(\u0026#34;/resource\u0026#34;) public ResponseEntity\u0026lt;?\u0026gt; getResource(@RequestParam String param1, @RequestParam String param2) { // 处理参数 } 2. 通过URL路径变量传输\n方式：前端将数据嵌入到URL的路径中。\n示例：http://example.com/resource/123/name\n接收：在后端，你可以使用@PathVariable注解来接收这些路径变量。\n1 2 3 4 @GetMapping(\u0026#34;/resource/{id}/{name}\u0026#34;) public ResponseEntity\u0026lt;?\u0026gt; getResource(@PathVariable Long id, @PathVariable String name) { // 处理路径变量 } 3. 通过表单数据（POST请求）传输\n方式：前端通过HTML表单或AJAX发送POST请求，数据在请求体中作为表单字段传输。\n接收：在后端，你可以使用@ModelAttribute或@RequestBody（如果数据是JSON或XML格式）来接收这些数据。对于简单的表单数据，@ModelAttribute更常用；对于复杂的JSON或XML数据，@RequestBody更合适。\n1 2 3 4 5 6 7 8 9 10 11 // 使用@ModelAttribute接收简单的表单数据 @PostMapping(\u0026#34;/form\u0026#34;) public ResponseEntity\u0026lt;?\u0026gt; handleFormSubmit(@ModelAttribute FormData formData) { // 处理表单数据 } // 使用@RequestBody接收JSON数据 @PostMapping(\u0026#34;/json\u0026#34;) public ResponseEntity\u0026lt;?\u0026gt; handleJsonSubmit(@RequestBody JsonData jsonData) { // 处理JSON数据 } 4. 通过请求体（非表单数据）传输\n方式：前端发送POST或PUT请求，数据作为请求体的内容（通常是JSON、XML或其他格式）传输。\n接收：在后端，你通常使用@RequestBody注解来接收这些数据，并将其反序列化为Java对象。\n1 2 3 4 @PostMapping(\u0026#34;/data\u0026#34;) public ResponseEntity\u0026lt;?\u0026gt; handleDataSubmit(@RequestBody DataObject dataObject) { // 处理数据对象 } 5. 通过请求头传输\n方式：前端将数据作为HTTP请求头的一部分发送。\n接收：在后端，你可以通过@RequestHeader注解来接收这些请求头。\n1 2 3 4 @GetMapping(\u0026#34;/header\u0026#34;) public ResponseEntity\u0026lt;?\u0026gt; getResourceByHeader(@RequestHeader String customHeader) { // 处理请求头 } 6. 通过文件上传传输\n方式：前端通过HTML表单或AJAX发送文件上传请求，数据作为文件内容传输。\n接收：在后端，你可以使用@RequestParam(\u0026quot;file\u0026quot;) MultipartFile file来接收上传的文件。\n1 2 3 4 @PostMapping(\u0026#34;/upload\u0026#34;) public ResponseEntity\u0026lt;?\u0026gt; handleFileUpload(@RequestParam(\u0026#34;file\u0026#34;) MultipartFile file) { // 处理上传的文件 } 总结\n查询参数：适用于GET请求，数据量少且简单。 路径变量：适用于GET请求，用于标识资源ID或名称等。 表单数据：适用于POST请求，数据作为表单字段传输。 请求体：适用于POST或PUT请求，数据作为请求体内容传输，可以是JSON、XML等格式。 请求头：适用于所有类型的请求，数据作为HTTP请求头的一部分传输。 文件上传：适用于POST请求，数据作为文件内容传输。 根据具体的应用场景和需求，选择合适的数据传输方式和接收方法。\n根据你提供的信息，这里是每种数据传输方式对应的前端请求示例：\n通过URL查询参数传输\n前端请求示例：使用JavaScript的fetch函数或者XMLHttpRequest来发送GET请求，并将查询参数附加到URL的末尾。 示例代码： 1 2 3 4 fetch(\u0026#39;http://example.com/resource?param1=value1\u0026amp;param2=value2\u0026#39;) .then(response =\u0026gt; response.json()) .then(data =\u0026gt; console.log(data)) .catch(error =\u0026gt; console.error(\u0026#39;Error:\u0026#39;, error)); 通过URL路径变量传输\n前端请求示例：使用JavaScript的fetch函数或者XMLHttpRequest来发送GET请求，并将数据嵌入到URL的路径中。 示例代码： 1 2 3 4 fetch(\u0026#39;http://example.com/resource/123/name\u0026#39;) .then(response =\u0026gt; response.json()) .then(data =\u0026gt; console.log(data)) .catch(error =\u0026gt; console.error(\u0026#39;Error:\u0026#39;, error)); 通过表单数据（POST请求）传输\n前端请求示例：使用表单或者AJAX发送POST请求，数据在请求体中作为表单字段传输。 示例代码（使用Fetch API）： 1 2 3 4 5 6 7 8 9 10 11 const formData = new FormData(); formData.append(\u0026#39;param1\u0026#39;, \u0026#39;value1\u0026#39;); formData.append(\u0026#39;param2\u0026#39;, \u0026#39;value2\u0026#39;); fetch(\u0026#39;http://example.com/form\u0026#39;, { method: \u0026#39;POST\u0026#39;, body: formData }) .then(response =\u0026gt; response.json()) .then(data =\u0026gt; console.log(data)) .catch(error =\u0026gt; console.error(\u0026#39;Error:\u0026#39;, error)); 通过请求体（非表单数据）传输\n前端请求示例：发送POST或PUT请求，数据作为请求体的内容（通常是JSON、XML或其他格式）传输。 示例代码（使用Fetch API发送JSON数据）： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 const data = { key1: \u0026#39;value1\u0026#39;, key2: \u0026#39;value2\u0026#39; }; fetch(\u0026#39;http://example.com/data\u0026#39;, { method: \u0026#39;POST\u0026#39;, headers: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, }, body: JSON.stringify(data), }) .then(response =\u0026gt; response.json()) .then(data =\u0026gt; console.log(data)) .catch(error =\u0026gt; console.error(\u0026#39;Error:\u0026#39;, error)); 通过请求头传输\n前端请求示例：将数据作为HTTP请求头的一部分发送。 示例代码（使用Fetch API）： 1 2 3 4 5 6 7 8 9 fetch(\u0026#39;http://example.com/header\u0026#39;, { method: \u0026#39;GET\u0026#39;, headers: { \u0026#39;Custom-Header\u0026#39;: \u0026#39;value\u0026#39; } }) .then(response =\u0026gt; response.json()) .then(data =\u0026gt; console.log(data)) .catch(error =\u0026gt; console.error(\u0026#39;Error:\u0026#39;, error)); 通过文件上传传输\n前端请求示例：通过HTML表单或AJAX发送文件上传请求，数据作为文件内容传输。 示例代码（使用Fetch API上传文件）： 1 2 3 4 5 6 7 8 9 10 11 const formData = new FormData(); const fileInput = document.querySelector(\u0026#39;input[type=\u0026#34;file\u0026#34;]\u0026#39;); formData.append(\u0026#39;file\u0026#39;, fileInput.files[0]); fetch(\u0026#39;http://example.com/upload\u0026#39;, { method: \u0026#39;POST\u0026#39;, body: formData }) .then(response =\u0026gt; response.json()) .then(data =\u0026gt; console.log(data)) .catch(error =\u0026gt; console.error(\u0026#39;Error:\u0026#39;, error)); 这些示例展示了如何使用JavaScript的Fetch API来发送不同类型的请求。对于HTML表单，你可以直接在表单标签中设置action和method属性，并通过浏览器的原生表单提交功能来发送请求。\nR类 为了方便前后端数据的传输而引出的类，它可以定义一些能够将前端需要的信息响应过去的属性，从而达到方比那传输的目的。\n对此处类的解析。它一个非常好的点就是利用了泛型，可以接收各种类型的变量。\n起初就在类首部定义为class R，好像也可以定义多个泛型。那么就可以去定义泛型数据private T data;接着去方法里运行。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 /** * 通用返回结果，服务端响应的数据最终都会封装成此对象 * @param \u0026lt;T\u0026gt; */ @Data public class R\u0026lt;T\u0026gt; { private Integer code; //编码：1成功，0和其它数字为失败 private String msg; //错误信息 private T data; //数据 private Map map = new HashMap(); //动态数据 public static \u0026lt;T\u0026gt; R\u0026lt;T\u0026gt; success(T object) { R\u0026lt;T\u0026gt; r = new R\u0026lt;T\u0026gt;(); r.data = object; r.code = 1; return r; } public static \u0026lt;T\u0026gt; R\u0026lt;T\u0026gt; error(String msg) { R r = new R(); r.msg = msg; r.code = 0; return r; } public R\u0026lt;T\u0026gt; add(String key, Object value) { this.map.put(key, value); return this; } } 1 2 3 4 5 6 public static \u0026lt;T\u0026gt; R\u0026lt;T\u0026gt; success(T object) { R\u0026lt;T\u0026gt; r = new R\u0026lt;T\u0026gt;(); r.data = object; r.code = 1; return r; } 可以使用的方法例如：\n1 2 3 4 5 public R\u0026lt;String\u0026gt; logout(HttpServletRequest request){ //清理Session中保存的当前登录员工的id request.getSession().removeAttribute(\u0026#34;employee\u0026#34;); return R.success(\u0026#34;退出成功\u0026#34;); } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public R\u0026lt;Employee\u0026gt; login(HttpServletRequest request,@RequestBody Employee employee){ String password = employee.getPassword(); password = DigestUtils.md5DigestAsHex(password.getBytes()); LambdaQueryWrapper\u0026lt;Employee\u0026gt; queryWrapper = new LambdaQueryWrapper\u0026lt;\u0026gt;(); queryWrapper.eq(Employee::getUsername,employee.getUsername()); Employee emp = employeeService.getOne(queryWrapper); if(emp == null){ return R.error(\u0026#34;登录失败\u0026#34;); } if(!emp.getPassword().equals(password)){ return R.error(\u0026#34;登录失败\u0026#34;); } if(emp.getStatus() == 0){ return R.error(\u0026#34;账号已禁用\u0026#34;); } request.getSession().setAttribute(\u0026#34;employee\u0026#34;,emp.getId()); return R.success(emp); } MP的分页插件 为了不很麻烦地手动写sql语句进行分页查询，此处选用配置MP分页插件来方便查询。\n1 2 3 4 5 6 7 8 9 10 @Configuration public class MybatisPlusConfig { @Bean public MybatisPlusInterceptor mybatisPlusInterceptor(){ MybatisPlusInterceptor mybatisPlusInterceptor = new MybatisPlusInterceptor(); mybatisPlusInterceptor.addInnerInterceptor(new PaginationInnerInterceptor()); return mybatisPlusInterceptor; } } 具体的使用\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 @GetMapping(\u0026#34;/page\u0026#34;) public R\u0026lt;Page\u0026gt; page(int page,int pageSize,String name){ log.info(\u0026#34;page = {},pageSize = {},name = {}\u0026#34; ,page,pageSize,name); //构造分页构造器 Page pageInfo = new Page(page,pageSize); //构造条件构造器 LambdaQueryWrapper\u0026lt;Employee\u0026gt; queryWrapper = new LambdaQueryWrapper(); //添加过滤条件 queryWrapper.like(StringUtils.isNotEmpty(name),Employee::getName,name); //添加排序条件 queryWrapper.orderByDesc(Employee::getUpdateTime); //执行查询 employeeService.page(pageInfo,queryWrapper); return R.success(pageInfo); } MyBatis-Plus中，MybatisPlusInterceptor 是一个核心的组件，它允许你插入自定义的拦截器来处理MyBatis的执行操作。当你配置了 MybatisPlusInterceptor 并添加了 PaginationInnerInterceptor 作为其内部拦截器时，这个分页拦截器会在执行查询操作时自动介入，处理分页逻辑。\n即使你没有在代码中显式地“使用”拦截器，只要你按照以下步骤配置了拦截器，它就会在后台自动工作：\n你的代码中确实使用了MyBatis-Plus的分页功能，并且用到了分页插件。让我们逐步分析你的代码，看看分页是如何实现的：\n@GetMapping(\u0026quot;/page\u0026quot;)：这是一个Spring MVC注解，用于将HTTP GET请求映射到page方法上。\npublic R\u0026lt;Page\u0026gt; page(int page, int pageSize, String name) { ... }：这是控制器中的方法，它接受三个参数：当前页码、每页显示的记录数和一个名字搜索条件，并返回一个分页结果。\nlog.info(\u0026quot;page = {},pageSize = {},name = {}\u0026quot;, page, pageSize, name);：这行代码使用SLF4J日志记录请求的分页参数，有助于调试。\nPage pageInfo = new Page(page, pageSize);：这里创建了一个新的Page对象，它是MyBatis-Plus分页功能的载体，包含了分页的请求参数。\nLambdaQueryWrapper\u0026lt;Employee\u0026gt; queryWrapper = new LambdaQueryWrapper\u0026lt;\u0026gt;();：创建了一个用于构建查询条件的LambdaQueryWrapper对象。\nqueryWrapper.like(StringUtils.isNotEmpty(name), Employee::getName, name);：如果name参数不为空，则添加一个模糊匹配条件，用于搜索员工名称。\nqueryWrapper.orderByDesc(Employee::getUpdateTime);：设置查询结果按员工更新时间降序排序。\nemployeeService.page(pageInfo, queryWrapper);：这是关键的一步，它调用了employeeService的page方法。在这个方法内部，MyBatis-Plus会利用你之前配置的MybatisPlusInterceptor和其中的PaginationInnerInterceptor来处理分页逻辑。这个方法会返回一个IPage类型的结果，它包含了分页查询的结果以及分页信息（如总记录数、总页数等）。\nreturn R.success(pageInfo);：最后，方法返回一个成功的响应，其中包含了分页信息和查询结果。\n你的代码中没有直接引用MybatisPlusInterceptor或PaginationInnerInterceptor，是因为这些组件是在Spring Boot的配置类中配置的，通常是在application.yml或application.properties文件中配置，或者如前所述，在Java配置类中通过@Bean方法配置。一旦配置完成，这些拦截器就会自动在MyBatis-Plus执行查询时起作用。\n因此，即使你的代码中没有显式地“使用”分页插件，只要你按照前面的步骤配置了MybatisPlusInterceptor和PaginationInnerInterceptor，它们就会在后台自动工作，为你的分页查询提供支持。这就是为什么你的代码能够实现分页功能的原因。\n拦截器（Interceptor）与过滤器（Filter）的区别：\n过滤器（Filter）： 工作在Web应用服务器的Servlet层面，可以在请求到达Servlet之前或响应返回给客户端之前进行拦截处理。 主要用于处理Web请求的预处理和后处理，如日志记录、权限检查、请求内容修改等。 通常用于处理HTTP请求和响应。 拦截器（Interceptor）： 工作在框架层面，如Spring或MyBatis，可以在业务逻辑执行前后进行拦截处理。 主要用于处理特定的业务逻辑，如事务管理、日志记录、性能监控等。 可以更细粒度地控制业务逻辑的执行流程。 在MyBatis-Plus中，MybatisPlusInterceptor 及其内部拦截器（如 PaginationInnerInterceptor）通常用于处理分页查询。下面我将给出两个案例，一个使用 PaginationInnerInterceptor 进行分页查询，另一个不使用它。\n使用 PaginationInnerInterceptor 的案例：\n在这个案例中，我们使用 MybatisPlusInterceptor 和 PaginationInnerInterceptor 来实现分页查询。首先，我们需要配置 MybatisPlusConfig 类，如你之前所示：\n1 2 3 4 5 6 7 8 9 10 @Configuration public class MybatisPlusConfig { @Bean public MybatisPlusInterceptor mybatisPlusInterceptor(){ MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor(); interceptor.addInnerInterceptor(new PaginationInnerInterceptor()); return interceptor; } } 然后，我们可以在服务层（Service）使用 Page 对象来执行分页查询：\n1 2 3 4 5 6 7 8 9 10 11 12 @Service public class EmployeeService { @Autowired private EmployeeMapper employeeMapper; public IPage\u0026lt;Employee\u0026gt; getEmployeesByPage(int currentPage, int pageSize) { Page\u0026lt;Employee\u0026gt; page = new Page\u0026lt;\u0026gt;(currentPage, pageSize); IPage\u0026lt;Employee\u0026gt; employeePage = employeeMapper.selectPage(page, null); return employeePage; } } 在控制器层（Controller），我们可以接收分页参数并调用服务层的方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 @RestController @RequestMapping(\u0026#34;/employees\u0026#34;) public class EmployeeController { @Autowired private EmployeeService employeeService; @GetMapping(\u0026#34;/page\u0026#34;) public R\u0026lt;IPage\u0026lt;Employee\u0026gt;\u0026gt; getEmployeesByPage(@RequestParam int page, @RequestParam int size) { IPage\u0026lt;Employee\u0026gt; employeePage = employeeService.getEmployeesByPage(page, size); return R.ok().data(\u0026#34;items\u0026#34;, employeePage.getRecords()).extra(\u0026#34;total\u0026#34;, employeePage.getTotal()); } } 不使用 PaginationInnerInterceptor 的案例：\n如果我们不使用 PaginationInnerInterceptor，那么我们需要在每次执行分页查询时手动编写分页逻辑。这通常涉及到编写特定的SQL语句来实现分页，或者在应用层手动处理分页逻辑。\n例如，不使用分页拦截器时，我们可能需要在Mapper接口中定义一个自定义的分页查询方法，并在XML文件中编写相应的SQL：\n1 2 3 4 // EmployeeMapper.java public interface EmployeeMapper extends BaseMapper\u0026lt;Employee\u0026gt; { IPage\u0026lt;Employee\u0026gt; selectPageWithCustomSql(IPage\u0026lt;?\u0026gt; page, @Param(\u0026#34;name\u0026#34;) String name); } 在XML文件中：\n1 2 3 4 5 6 \u0026lt;!-- EmployeeMapper.xml --\u0026gt; \u0026lt;select id=\u0026#34;selectPageWithCustomSql\u0026#34; resultType=\u0026#34;Employee\u0026#34;\u0026gt; SELECT * FROM employee WHERE name LIKE CONCAT(\u0026#39;%\u0026#39;, #{name}, \u0026#39;%\u0026#39;) LIMIT #{page.offset}, #{page.size} \u0026lt;/select\u0026gt; 在服务层，我们调用这个自定义的分页查询方法：\n1 2 3 4 5 6 7 8 9 10 11 12 @Service public class EmployeeService { @Autowired private EmployeeMapper employeeMapper; public IPage\u0026lt;Employee\u0026gt; getEmployeesByPage(int currentPage, int pageSize, String name) { Page\u0026lt;Employee\u0026gt; page = new Page\u0026lt;\u0026gt;(currentPage, pageSize); IPage\u0026lt;Employee\u0026gt; employeePage = employeeMapper.selectPageWithCustomSql(page, name); return employeePage; } } 在控制器层，我们同样接收分页参数并调用服务层的方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 @RestController @RequestMapping(\u0026#34;/employees\u0026#34;) public class EmployeeController { @Autowired private EmployeeService employeeService; @GetMapping(\u0026#34;/page\u0026#34;) public R\u0026lt;IPage\u0026lt;Employee\u0026gt;\u0026gt; getEmployeesByPage(@RequestParam int page, @RequestParam int size, @RequestParam String name) { IPage\u0026lt;Employee\u0026gt; employeePage = employeeService.getEmployeesByPage(page, size, name); return R.ok().data(\u0026#34;items\u0026#34;, employeePage.getRecords()).extra(\u0026#34;total\u0026#34;, employeePage.getTotal()); } } 在这个案例中，我们没有使用 PaginationInnerInterceptor，因此需要在每次查询时手动处理分页逻辑，这增加了代码的复杂性，并且降低了代码的可维护性。使用 PaginationInnerInterceptor 可以简化这个过程，使得分页查询更加方便和高效。\nMyBatis-Plus 提供了多种内置拦截器，除了分页拦截器 PaginationInnerInterceptor 外，还包括但不限于以下几种：\n多租户插件 TenantLineInnerInterceptor：用于实现多租户场景下的数据隔离。通过这个拦截器，可以根据租户的ID或其他标识来动态修改SQL，以确保每个租户只能访问到自己的数据。这对于SaaS应用尤其有用。\n动态表名插件 DynamicTableNameInnerInterceptor：允许在运行时动态改变表名。这对于需要根据不同条件访问不同数据库表的场景非常有用。\n乐观锁插件 OptimisticLockerInnerInterceptor：提供了乐观锁机制，用于处理并发更新数据时可能出现的冲突。通过版本号或其他机制来确保数据的一致性。\nSQL性能规范插件 IllegalSQLInnerInterceptor：用于检查和防止执行可能影响数据库性能的SQL语句，如没有WHERE子句的UPDATE或DELETE语句。\n防止全表更新与删除插件 BlockAttackInnerInterceptor：用于防止执行可能导致全表扫描或锁定的有害SQL语句，如不带WHERE子句的UPDATE或DELETE操作。\n数据权限控制拦截器：可以实现基于用户权限的动态SQL修改，以控制不同用户可以访问的数据范围。这通常通过自定义拦截器实现，根据当前用户的角色或权限来修改SQL语句。\n自定义拦截器：除了内置的拦截器，MyBatis-Plus 也支持开发者根据具体需求自定义拦截器。自定义拦截器可以实现各种功能，如添加租户隔离、审计日志记录、SQL优化等。\n这些拦截器可以通过配置类 MybatisPlusConfig 进行配置，如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Configuration public class MybatisPlusConfig { @Bean public MybatisPlusInterceptor mybatisPlusInterceptor(){ MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor(); interceptor.addInnerInterceptor(new PaginationInnerInterceptor()); // 添加其他拦截器 interceptor.addInnerInterceptor(new TenantLineInnerInterceptor()); interceptor.addInnerInterceptor(new DynamicTableNameInnerInterceptor()); // ...添加更多拦截器 return interceptor; } } 那么实际开发中，根据项目的具体需求选择合适的拦截器进行配置，可以有效地增强MyBatis-Plus的功能，提高开发效率和应用性能。\nPage类 在MyBatis-Plus中，Page 类是一个非常重要的类，它用于承载分页查询的请求参数以及返回的分页结果。当你执行分页查询并获得结果时，Page 对象包含了以下主要内容：\n当前页码（Current Page）：\n表示请求的页码，即用户请求查看的是哪一页的数据。 每页数量（Page Size）：\n表示每一页显示的记录数。 总记录数（Total Count）：\n表示查询条件下的总记录数。这个数字是通过对整个数据集进行计数获得的，对于分页查询来说，这个数字是非常重要的，因为它决定了可以分多少页。 总页数（Total Pages）：\n根据总记录数和每页数量计算出的总页数。如果总记录数不能被每页数量整除，总页数会向上取整。 记录列表（Records）：\n包含了当前页的记录列表。这是执行分页查询后，数据库返回的当前页的数据记录。 是否第一页（Is First Page）：\n一个布尔值，表示当前页是否是第一页。 是否最后一页（Is Last Page）：\n一个布尔值，表示当前页是否是最后一页。 是否有前一页（Has Previous Page）：\n一个布尔值，表示当前页是否有前一页。 是否有下一页（Has Next Page）：\n一个布尔值，表示当前页是否有下一页。 分页参数（Page Parameters）：\n可能包含一些额外的分页参数，如排序信息等。 当你使用 employeeService.page(pageInfo, queryWrapper) 方法执行分页查询时，MyBatis-Plus框架会在内部处理分页逻辑，并填充 Page 对象的上述属性。最终，你可以通过返回的 Page 对象获取到所有这些分页信息，以及当前页的数据记录。\n在实际的Web应用中，这些信息通常被用来构建分页导航，以及展示当前页的数据。例如，你可以使用总页数来生成分页控件中的页码链接，使用记录列表来显示当前页的数据。\n对应前端代码 在前端使用Vue.js处理分页数据，你可以创建一个Vue组件来发送请求、处理响应并展示数据。以下是使用Vue 2.x版本的示例：\n1. 创建Vue组件\n首先，确保你已经在你的项目中安装了Axios，这是一个用于发送HTTP请求的库。如果还没有安装，可以通过以下命令安装：\n1 npm install axios 然后，创建一个名为EmployeePage.vue的Vue组件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 \u0026lt;template\u0026gt; \u0026lt;div\u0026gt; \u0026lt;h1\u0026gt;Employee List\u0026lt;/h1\u0026gt; \u0026lt;input v-model=\u0026#34;searchName\u0026#34; placeholder=\u0026#34;Search by name\u0026#34; @input=\u0026#34;fetchPageData\u0026#34; /\u0026gt; \u0026lt;table\u0026gt; \u0026lt;thead\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th\u0026gt;Name\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;Age\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;Update Time\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/thead\u0026gt; \u0026lt;tbody\u0026gt; \u0026lt;tr v-for=\u0026#34;employee in pageInfo.records\u0026#34; :key=\u0026#34;employee.id\u0026#34;\u0026gt; \u0026lt;td\u0026gt;{{ employee.name }}\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;{{ employee.age }}\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;{{ formatDate(employee.updateTime) }}\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/tbody\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;div class=\u0026#34;pagination\u0026#34;\u0026gt; \u0026lt;button v-if=\u0026#34;pageInfo.current \u0026gt; 1\u0026#34; @click=\u0026#34;fetchPageData(pageInfo.current - 1, pageInfo.size)\u0026#34; \u0026gt; Previous \u0026lt;/button\u0026gt; \u0026lt;span\u0026gt;{{ pageInfo.current }}\u0026lt;/span\u0026gt; of \u0026lt;span\u0026gt;{{ pageInfo.pages }}\u0026lt;/span\u0026gt; \u0026lt;button v-if=\u0026#34;pageInfo.current \u0026lt; pageInfo.pages\u0026#34; @click=\u0026#34;fetchPageData(pageInfo.current + 1, pageInfo.size)\u0026#34; \u0026gt; Next \u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;script\u0026gt; import axios from \u0026#39;axios\u0026#39;; export default { data() { return { pageInfo: { records: [] }, searchName: \u0026#39;\u0026#39;, currentPage: 1, pageSize: 10 }; }, methods: { async fetchPageData(page, size) { try { const response = await axios.get(`/page`, { params: { page, size, name: this.searchName } }); this.pageInfo = response.data; } catch (error) { console.error(\u0026#39;Error fetching page data:\u0026#39;, error); } }, formatDate(dateString) { const date = new Date(dateString); return date.toLocaleDateString(); } }, created() { this.fetchPageData(this.currentPage, this.pageSize); } }; \u0026lt;/script\u0026gt; \u0026lt;style\u0026gt; table { width: 100%; border-collapse: collapse; } th, td { border: 1px solid #ddd; padding: 8px; text-align: left; } .pagination { margin-top: 20px; } \u0026lt;/style\u0026gt; 2. 注册和使用组件\n确保在你的Vue应用中注册了EmployeePage.vue组件，然后在父组件或App.vue中使用它：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026lt;template\u0026gt; \u0026lt;div id=\u0026#34;app\u0026#34;\u0026gt; \u0026lt;employee-page\u0026gt;\u0026lt;/employee-page\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/template\u0026gt; \u0026lt;script\u0026gt; import EmployeePage from \u0026#39;./components/EmployeePage.vue\u0026#39;; export default { name: \u0026#39;App\u0026#39;, components: { EmployeePage } }; \u0026lt;/script\u0026gt; 3. 运行你的Vue应用\n确保你的Vue应用正在运行，并且后端服务也已经启动。然后，在浏览器中打开你的Vue应用，你应该能够看到员工列表，并能够通过分页控件浏览不同的页面。\n这个Vue组件使用了组合式API来处理数据获取和分页逻辑。它在组件创建时（created生命周期钩子）发送一个初始请求，然后根据用户的输入和分页按钮点击来更新数据。日期格式化函数formatDate用于将日期字符串转换为更易读的格式。\n那么M的分页插件呢 配置JacksonObjectMapper对象映射器 将它配置好过后还需要进行纳入spring容器管理，等用到的时候会默认自动调用。\n可以从前面笔记地WebMvcConfig里面看\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 /** * 对象映射器:基于jackson将Java对象转为json，或者将json转为Java对象 * 将JSON解析为Java对象的过程称为 [从JSON反序列化Java对象] * 从Java对象生成JSON的过程称为 [序列化Java对象到JSON] */ public class JacksonObjectMapper extends ObjectMapper { public static final String DEFAULT_DATE_FORMAT = \u0026#34;yyyy-MM-dd\u0026#34;; public static final String DEFAULT_DATE_TIME_FORMAT = \u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;; public static final String DEFAULT_TIME_FORMAT = \u0026#34;HH:mm:ss\u0026#34;; public JacksonObjectMapper() { super(); //收到未知属性时不报异常 this.configure(FAIL_ON_UNKNOWN_PROPERTIES, false); //反序列化时，属性不存在的兼容处理 this.getDeserializationConfig().withoutFeatures(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES); SimpleModule simpleModule = new SimpleModule() .addDeserializer(LocalDateTime.class, new LocalDateTimeDeserializer(DateTimeFormatter.ofPattern(DEFAULT_DATE_TIME_FORMAT))) .addDeserializer(LocalDate.class, new LocalDateDeserializer(DateTimeFormatter.ofPattern(DEFAULT_DATE_FORMAT))) .addDeserializer(LocalTime.class, new LocalTimeDeserializer(DateTimeFormatter.ofPattern(DEFAULT_TIME_FORMAT))) .addSerializer(BigInteger.class, ToStringSerializer.instance) .addSerializer(Long.class, ToStringSerializer.instance) .addSerializer(LocalDateTime.class, new LocalDateTimeSerializer(DateTimeFormatter.ofPattern(DEFAULT_DATE_TIME_FORMAT))) .addSerializer(LocalDate.class, new LocalDateSerializer(DateTimeFormatter.ofPattern(DEFAULT_DATE_FORMAT))) .addSerializer(LocalTime.class, new LocalTimeSerializer(DateTimeFormatter.ofPattern(DEFAULT_TIME_FORMAT))); //注册功能模块 例如，可以添加自定义序列化器和反序列化器 this.registerModule(simpleModule); } } 1 2 3 4 5 6 7 8 9 10 @Override protected void extendMessageConverters(List\u0026lt;HttpMessageConverter\u0026lt;?\u0026gt;\u0026gt; converters) { log.info(\u0026#34;扩展消息转换器...\u0026#34;); //创建消息转换器对象 MappingJackson2HttpMessageConverter messageConverter = new MappingJackson2HttpMessageConverter(); //设置对象转换器，底层使用Jackson将Java对象转为json messageConverter.setObjectMapper(new JacksonObjectMapper()); //将上面的消息转换器对象追加到mvc框架的转换器集合中 converters.add(0,messageConverter); } 这段代码定义了一个名为 JacksonObjectMapper 的类，它继承自 ObjectMapper 类。ObjectMapper 是 Jackson 库中的核心类，用于将 Java 对象序列化成 JSON 格式的字符串，以及将 JSON 字符串反序列化成 Java 对象。下面是代码中每个部分的详细解释：\n自定义日期时间格式：\nDEFAULT_DATE_FORMAT、DEFAULT_DATE_TIME_FORMAT 和 DEFAULT_TIME_FORMAT 是定义的日期和时间格式字符串，它们分别对应不同的日期时间组件（如日期、日期时间、时间）。 配置 ObjectMapper：\nthis.configure(FAIL_ON_UNKNOWN_PROPERTIES, false); 这行代码配置 ObjectMapper，在反序列化时遇到 JSON 中的未知属性不抛出异常。这在处理 JSON 数据时非常有用，特别是当 JSON 数据包含一些 Java 对象中不存在的属性时。 反序列化配置：\nthis.getDeserializationConfig().withoutFeatures(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES); 这行代码同样用于在反序列化时忽略未知属性，这是另一种配置方式，确保配置被正确应用。 自定义序列化和反序列化器：\nSimpleModule 是 Jackson 库中的一个类，用于注册自定义的序列化器和反序列化器。 addDeserializer 方法用于添加自定义的反序列化器，这里为 LocalDateTime、LocalDate 和 LocalTime 添加了对应的反序列化器，它们使用预定义的格式来解析日期和时间。 addSerializer 方法用于添加自定义的序列化器，这里为 BigInteger、Long、LocalDateTime、LocalDate 和 LocalTime 添加了对应的序列化器，它们将这些类型的值转换为指定格式的字符串。 注册模块：\nthis.registerModule(simpleModule); 这行代码将配置好的 SimpleModule 注册到 ObjectMapper 实例中，使其生效。 为什么需要这样处理，Java程序自带的不行吗？\nJava 自带的序列化机制（如 Serializable 接口）和 Jackson 库做的事情是不同的：\nJava 序列化：Java 通过实现 Serializable 接口提供了一种序列化机制，但它通常用于将整个对象图转换为字节流，以便可以将其持久保存到磁盘或通过网络发送。这种序列化是二进制形式的，不是人类可读的，且不如 JSON 灵活和通用。\nJackson 序列化：Jackson 库提供的序列化机制是将 Java 对象转换为 JSON 格式的字符串。JSON 是一种轻量级的数据交换格式，易于人阅读和编写，同时也易于机器解析和生成。JSON 在 Web 开发中被广泛使用，特别是在前后端分离的架构中。\n此外，Jackson 提供了灵活的配置和扩展机制，允许开发者自定义序列化和反序列化的行为，以满足特定的业务需求。例如，你可以自定义日期时间的格式，处理一些特殊的数据类型（如 BigInteger），或者在序列化和反序列化时执行额外的逻辑。\n因此，虽然 Java 提供了序列化机制，但在需要处理 JSON 数据或需要更灵活的序列化配置时，使用 Jackson 库是更合适的选择。\n全局异常处理器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 /** * 全局异常处理 */ @ControllerAdvice(annotations = {RestController.class, Controller.class}) @ResponseBody @Slf4j public class GlobalExceptionHandler { /** * 异常处理方法 * @return */ @ExceptionHandler(SQLIntegrityConstraintViolationException.class) public R\u0026lt;String\u0026gt; exceptionHandler(SQLIntegrityConstraintViolationException ex){ log.error(ex.getMessage()); if(ex.getMessage().contains(\u0026#34;Duplicate entry\u0026#34;)){ String[] split = ex.getMessage().split(\u0026#34; \u0026#34;); String msg = split[2] + \u0026#34;已存在\u0026#34;; return R.error(msg); } return R.error(\u0026#34;未知错误\u0026#34;); } /** * 异常处理方法 * @return */ @ExceptionHandler(CustomException.class) public R\u0026lt;String\u0026gt; exceptionHandler(CustomException ex){ log.error(ex.getMessage()); return R.error(ex.getMessage()); } } 这段代码定义了一个名为 GlobalExceptionHandler 的类，它的作用是全局异常处理。这意味着，无论你的Spring应用程序中的哪个部分抛出了异常，只要这个异常是 GlobalExceptionHandler 中定义的方法可以处理的类型，那么这个异常就会被这些方法捕获并统一处理。下面我会逐行解释这段代码：\n@ControllerAdvice 注解：\n这个注解用于定义一个全局的控制器增强器（例如异常处理、数据预处理等），可以被加到任何Spring MVC的控制器上。 annotations = {RestController.class, Controller.class} 参数表示这个增强器会应用到所有标记了 @RestController 或 @Controller 注解的控制器上。 @ResponseBody 注解：\n这个注解表示该类中的所有方法的返回值都将直接作为HTTP响应的正文返回。由于这个注解加在了类上，所以这个类中的所有方法都会自动应用 @ResponseBody 的效果。 @Slf4j 注解：\n这是一个由Lombok库提供的注解，用于自动为类生成日志对象（通常是 private static final Logger log = LoggerFactory.getLogger(Class.class);）。 类定义 public class GlobalExceptionHandler：\n定义了一个公共类 GlobalExceptionHandler。 @ExceptionHandler(SQLIntegrityConstraintViolationException.class) 注解：\n这个注解表示下面的方法将处理 SQLIntegrityConstraintViolationException 类型的异常。 第一个 exceptionHandler 方法：\npublic R\u0026lt;String\u0026gt; exceptionHandler(SQLIntegrityConstraintViolationException ex)： 这个方法接受一个 SQLIntegrityConstraintViolationException 类型的参数 ex，表示它会处理这个类型的异常。 log.error(ex.getMessage());： 使用日志记录器记录异常信息。 if(ex.getMessage().contains(\u0026quot;Duplicate entry\u0026quot;))： 检查异常消息中是否包含 \u0026ldquo;Duplicate entry\u0026rdquo; 字符串。 String msg = split[2] + \u0026quot;已存在\u0026quot;;： 如果包含，则从异常消息中提取出错的数据名称，并拼接上 \u0026ldquo;已存在\u0026rdquo; 字符串，形成新的异常消息。 return R.error(msg);： 返回一个错误响应 R.error(msg)，其中 R 是一个通用响应类，用于封装响应数据。 return R.error(\u0026quot;未知错误\u0026quot;);： 如果异常消息不包含 \u0026ldquo;Duplicate entry\u0026rdquo;，则返回一个通用的错误消息。 第二个 exceptionHandler 方法：\n@ExceptionHandler(CustomException.class)： 这个注解表示下面的方法将处理 CustomException 类型的异常。 public R\u0026lt;String\u0026gt; exceptionHandler(CustomException ex)： 这个方法接受一个 CustomException 类型的参数 ex。 log.error(ex.getMessage());： 记录异常信息。 return R.error(ex.getMessage());： 返回一个错误响应，消息内容为异常 ex 的消息。 总结来说，GlobalExceptionHandler 类是一个全局异常处理器，它捕获并处理特定类型的异常，然后返回统一的错误响应。这样做的好处是，你可以在一个地方集中处理异常，而不是在每个控制器方法中单独处理，这有助于保持代码的整洁和一致性。\n在Java中，确实不能在同一个类中有多个具有相同方法名和参数列表的方法，这被称为方法的重载（Method Overloading）。然而，你提到的GlobalExceptionHandler类中的两个exceptionHandler方法并不是重载，因为它们接受的参数类型不同。\n第一个exceptionHandler方法接受的参数是SQLIntegrityConstraintViolationException类型：\n1 2 3 public R\u0026lt;String\u0026gt; exceptionHandler(SQLIntegrityConstraintViolationException ex){ // ... } 第二个exceptionHandler方法接受的参数是CustomException类型：\n1 2 3 public R\u0026lt;String\u0026gt; exceptionHandler(CustomException ex){ // ... } 由于这两个方法的参数类型不同，它们并不违反Java的重载规则。Java的方法重载是根据方法名和参数列表（包括参数的数量和类型）来区分的。只要参数列表不同，即使方法名相同，它们也是两个完全不同的方法。\n在GlobalExceptionHandler类中，每个exceptionHandler方法都通过@ExceptionHandler注解指定了它所处理的异常类型。当Spring MVC框架遇到相应的异常时，它会调用对应的处理方法。这种方法的组织方式使得异常处理更加模块化和清晰，并且每个方法都可以有自己独特的逻辑来处理特定类型的异常。\n自定义业务异常类 1 2 3 4 5 6 7 8 /** * 自定义业务异常类 */ public class CustomException extends RuntimeException { public CustomException(String message){ super(message); } } 这段代码定义了一个名为 CustomException 的自定义异常类，它继承自 Java 的 RuntimeException 类。下面是对这个类的详细解释：\npublic class CustomException：\n这是一个新的公共类的声明，类名为 CustomException。 extends RuntimeException：\nCustomException 继承自 Java 的 RuntimeException 类。RuntimeException 是一个非受查异常（unchecked exception），意味着编译器不会强制你捕获或抛出这个异常。它通常用于表示程序运行时的错误，比如数组越界、空指针异常等。 public CustomException(String message)：\n这是 CustomException 类的构造器（constructor），它接受一个字符串类型的参数 message。这个构造器用于在创建 CustomException 对象时初始化异常信息。 super(message)：\n这行代码调用了父类 RuntimeException 的构造器，并传递了 message 参数。这样做是为了设置异常的消息，这个信息通常在调试时非常有用，因为它可以提供关于异常原因的详细信息。 总的来说，CustomException 是一个自定义的异常类，你可以在业务逻辑中抛出这个异常来表示特定的业务错误。例如，如果用户输入了无效的数据，你可以抛出一个 CustomException 来表示这个错误，并提供相应的错误消息。\n使用自定义异常的好处是，你可以创建更具体、更有意义的异常类型来表示你的应用程序可能遇到的各种错误情况。这有助于错误处理和调试，也使得异常处理代码更加清晰和易于维护。\n下面是一个使用 CustomException 的例子：\n1 2 3 4 5 6 7 8 9 10 11 public void someBusinessMethod() { try { // 业务逻辑... if (某个条件) { throw new CustomException(\u0026#34;发生了一个业务错误\u0026#34;); } } catch (CustomException e) { // 处理 CustomException e.printStackTrace(); } } 在这个例子中，如果 某个条件 为真，someBusinessMethod 方法将抛出一个 CustomException，异常的消息是 \u0026ldquo;发生了一个业务错误\u0026rdquo;。然后，你可以在 catch 块中捕获并处理这个异常。\n短信发送工具 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 /** * 短信发送工具类 */ public class SMSUtils { /** * 发送短信 * @param signName 签名 * @param templateCode 模板 * @param phoneNumbers 手机号 * @param param 参数 */ public static void sendMessage(String signName, String templateCode,String phoneNumbers,String param){ DefaultProfile profile = DefaultProfile.getProfile(\u0026#34;cn-hangzhou\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;); IAcsClient client = new DefaultAcsClient(profile); SendSmsRequest request = new SendSmsRequest(); request.setSysRegionId(\u0026#34;cn-hangzhou\u0026#34;); request.setPhoneNumbers(phoneNumbers); request.setSignName(signName); request.setTemplateCode(templateCode); request.setTemplateParam(\u0026#34;{\\\u0026#34;code\\\u0026#34;:\\\u0026#34;\u0026#34;+param+\u0026#34;\\\u0026#34;}\u0026#34;); try { SendSmsResponse response = client.getAcsResponse(request); System.out.println(\u0026#34;短信发送成功\u0026#34;); }catch (ClientException e) { e.printStackTrace(); } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 /** * 随机生成验证码工具类 */ public class ValidateCodeUtils { /** * 随机生成验证码 * @param length 长度为4位或者6位 * @return */ public static Integer generateValidateCode(int length){ Integer code =null; if(length == 4){ code = new Random().nextInt(9999);//生成随机数，最大为9999 if(code \u0026lt; 1000){ code = code + 1000;//保证随机数为4位数字 } }else if(length == 6){ code = new Random().nextInt(999999);//生成随机数，最大为999999 if(code \u0026lt; 100000){ code = code + 100000;//保证随机数为6位数字 } }else{ throw new RuntimeException(\u0026#34;只能生成4位或6位数字验证码\u0026#34;); } return code; } /** * 随机生成指定长度字符串验证码 * @param length 长度 * @return */ public static String generateValidateCode4String(int length){ Random rdm = new Random(); String hash1 = Integer.toHexString(rdm.nextInt()); String capstr = hash1.substring(0, length); return capstr; } } 文件的上传与回显 用户通过前端将文件（图片等信息）提交，前端将信息发送给后端，后端通过springmvc提供的MultipartFile接收到文件，将文件先转存到本地磁盘的某一地方，接着等前端需要将文件进行回显的时候，就要从本地获取流，通过HttpServletResponse将文件写回浏览器。\n利用@Value将配置文件中的信息更加方便地注入给basePath。\n拿到文件后利用UUID获取一串字符为文件名重新赋值，防止重名导致的文件覆盖，并且将重命名的文件名传给前端，当前端想回显时利用新的文件名进行请求。\n利用File创建出来的是可以带路径的文件，如果路径文件夹不存在，可以通过mkdirs方法进行创建。\n需要设置为response.setContentType(\u0026ldquo;image/jpeg\u0026rdquo;);\n将文件进行回显的时候，通过文件输入流和HttpServletResponse获取输出流，将文件写回到浏览器。\n1 2 3 4 5 6 7 8 response.setContentType(\u0026#34;image/jpeg\u0026#34;); int len = 0; byte[] bytes = new byte[1024]; while ((len = fileInputStream.read(bytes)) != -1){ outputStream.write(bytes,0,len); outputStream.flush(); } 并且要记得关闭资源。\nMultipartFile MultipartFile 是 Spring MVC 提供的一个接口，用于处理 HTTP 请求中的文件上传部分。它极大地简化了文件上传的处理过程，提供了多种方法来访问和操作上传的文件。以下是 MultipartFile 的一些常用方法和使用场景：\nMultipartFile 的常用方法：\ngetOriginalFilename()：获取上传文件的原始文件名。 getContentType()：获取文件的 MIME 类型，这可以帮助你确定文件的类型。 isEmpty()：检查上传的文件是否为空。 getSize()：获取文件的大小，单位是字节。 getBytes()：将文件内容转换为字节数组。 getInputStream()：获取文件内容的输入流。 transferTo(File dest)：将上传的文件保存到服务器的指定路径。 使用场景和示例：\n1. 单文件上传：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @PostMapping(\u0026#34;/upload\u0026#34;) public String handleFileUpload(@RequestParam(\u0026#34;file\u0026#34;) MultipartFile file) { if (file.isEmpty()) { return \u0026#34;文件为空，请选择一个文件上传。\u0026#34;; } try { String originalFilename = file.getOriginalFilename(); File destFile = new File(\u0026#34;/uploads/\u0026#34; + originalFilename); file.transferTo(destFile); return \u0026#34;文件上传成功：\u0026#34; + originalFilename; } catch (IOException e) { e.printStackTrace(); return \u0026#34;文件上传失败：\u0026#34; + e.getMessage(); } } 在这个例子中，我们接收一个名为 file 的文件，并将其保存到服务器的 /uploads/ 目录下。\n2. 多文件上传：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @PostMapping(\u0026#34;/uploadMultiple\u0026#34;) public String handleMultipleFileUpload(@RequestParam(\u0026#34;files\u0026#34;) MultipartFile[] files) { for (MultipartFile file : files) { if (file.isEmpty()) continue; try { String originalFilename = file.getOriginalFilename(); File destFile = new File(\u0026#34;/uploads/\u0026#34; + originalFilename); file.transferTo(destFile); } catch (IOException e) { e.printStackTrace(); return \u0026#34;文件上传失败：\u0026#34; + e.getMessage(); } } return \u0026#34;所有文件上传成功\u0026#34;; } 在这个例子中，我们接收一个文件数组，并遍历数组中的每个文件，将它们保存到服务器的 /uploads/ 目录下。\n3. 文件下载：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 @GetMapping(\u0026#34;/download\u0026#34;) public void handleFileDownload(HttpServletRequest request, HttpServletResponse response) { String filePath = \u0026#34;/path/to/file.jpg\u0026#34;; File file = new File(filePath); response.setContentType(\u0026#34;application/octet-stream\u0026#34;); response.setHeader(\u0026#34;Content-Disposition\u0026#34;, \u0026#34;attachment; filename=\\\u0026#34;\u0026#34; + file.getName() + \u0026#34;\\\u0026#34;\u0026#34;); try (InputStream in = new FileInputStream(file); OutputStream out = response.getOutputStream()) { byte[] buffer = new byte[8192]; int bytesRead; while ((bytesRead = in.read(buffer)) != -1) { out.write(buffer, 0, bytesRead); } } catch (IOException e) { e.printStackTrace(); } } 在这个例子中，我们提供了一个文件下载的接口，用户可以通过这个接口下载服务器上的文件。\n注意事项：\n文件大小限制：Spring Boot 允许你通过配置文件来限制上传文件的大小，以防止恶意上传大文件。 文件名处理：用户上传的文件名可能包含特殊字符，需要进行适当的处理。 文件存储路径：上传的文件应该存储在安全的路径下，以防止文件被恶意访问。 通过这些方法和示例，你可以熟练地使用 MultipartFile 来处理文件上传和下载的需求。\n@Value 在Spring框架中，@Value 注解用于将配置文件中的值注入到Spring管理的Bean的字段中。这个注解提供了一种方便的方式来将外部配置（如.properties或.yml文件中的值）绑定到Java对象的属性上。\n使用方法：\n@Value 注解可以用于字段、设置方法（setter methods）或普通方法上。当用于字段上时，Spring会在创建Bean时自动将配置值注入到这些字段中。如果用于方法上，Spring会调用这些方法并将配置值作为参数传递。\n基本语法：\n1 2 @Value(\u0026#34;${property.name}\u0026#34;) private String propertyName; 或者，如果你需要进行一些表达式评估，可以使用SpEL（Spring Expression Language）：\n1 2 @Value(\u0026#34;#{systemProperties[\u0026#39;user.home\u0026#39;]}\u0026#34;) private String userHome; 使用场景：\n注入简单值：\n用于将配置文件中的简单值（如字符串、数字等）注入到Bean的字段中。 注入集合或数组：\n可以将配置文件中的列表或数组值注入到Bean的集合或数组字段中。 注入SpEL表达式：\n可以利用SpEL的强大功能，执行更复杂的注入操作，如调用方法、访问环境变量等。 示例代码：\n假设你有一个application.properties配置文件，其中包含以下属性：\n1 2 3 app.name=MyApplication app.description=This is a sample application. app.version=1.0.0 你可以使用@Value注解将这些值注入到Bean中：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 import org.springframework.beans.factory.annotation.Value; import org.springframework.stereotype.Component; @Component public class ApplicationProperties { @Value(\u0026#34;${app.name}\u0026#34;) private String name; @Value(\u0026#34;${app.description}\u0026#34;) private String description; @Value(\u0026#34;${app.version}\u0026#34;) private String version; // Getters and Setters public String getName() { return name; } public void setName(String name) { this.name = name; } public String getDescription() { return description; } public void setDescription(String description) { this.description = description; } public String getVersion() { return version; } public void setVersion(String version) { this.version = version; } } 在这个例子中，ApplicationProperties 类的字段被@Value注解标记，Spring容器在创建这个Bean时会自动从配置文件中读取相应的值并注入到这些字段中。\n注意事项：\n表达式结果为null：如果@Value注解的表达式结果为null，且字段没有初始值，则会抛出异常。为了避免这个问题，你可以为字段提供一个默认值。\n安全性：不要将敏感信息（如密码、密钥等）直接放在配置文件中。可以使用Spring Boot的配置属性替换功能来实现敏感信息的加密和解密。\n类型转换：Spring会尝试将注入的值转换为字段的类型。如果转换失败，会抛出异常。\n@Value 注解提供了一种简单而强大的方式，将外部配置与应用程序代码解耦，使得应用程序更容易配置和维护。\nContent-Type response.setContentType(\u0026quot;image/jpeg\u0026quot;); 这行代码设置了HTTP响应的内容类型（Content-Type）为 image/jpeg。这个头部信息告诉客户端（通常是浏览器）响应的内容是JPEG格式的图片。\n为什么要设置内容类型：\n内容协商：\n内容类型是HTTP内容协商的一部分，它允许客户端根据响应的内容类型决定如何处理这些数据。例如，浏览器会根据内容类型显示图片或执行其他操作。 正确的渲染：\n如果不设置内容类型，或者设置错误，客户端可能无法正确渲染或处理响应内容。例如，浏览器可能不知道如何处理二进制数据，可能会将其视为文本或下载文件。 保存文件时的文件类型：\n当用户通过浏览器下载文件时，正确的内容类型可以提示浏览器以正确的格式保存文件。 安全性：\n某些内容类型可能会触发客户端的安全检查，如执行JavaScript代码。正确的内容类型有助于避免潜在的安全问题。 如果没有设置内容类型可以吗？\n不设置内容类型，HTTP响应默认可能不会有 Content-Type 头部，或者继承自配置的默认值。在某些情况下，即使没有显式设置内容类型，客户端可能仍然能够正确处理响应，特别是如果响应的内容能够被客户端自动识别（例如，某些浏览器可以识别JPEG文件的二进制签名）。\n然而，不设置内容类型可能会导致以下问题：\n客户端行为不确定：\n客户端可能无法确定如何处理响应内容，导致渲染不正确或出现错误。 下载文件时的问题：\n如果用户正在下载文件，没有正确的内容类型，下载的文件可能无法以正确的格式保存。 安全性问题：\n在某些情况下，缺少内容类型可能会绕过客户端的安全检查，导致潜在的安全风险。 因此，为了确保最佳的兼容性和安全性，建议在发送特定类型的响应时总是设置正确的 Content-Type。这是一个良好的实践，可以确保你的应用程序在不同的客户端和环境中表现一致。\nresponse.setContentType 方法用于设置HTTP响应的内容类型（Content-Type），它告诉客户端（如浏览器）响应的内容是什么类型的数据。以下是一些常见的内容类型及其使用场景和示例：\n文本类型：\ntext/html：用于传输HTML文档。当你想返回一个网页时使用此类型。 1 response.setContentType(\u0026#34;text/html; charset=utf-8\u0026#34;); text/plain：用于传输纯文本数据。适用于返回简单的文本信息。 1 response.setContentType(\u0026#34;text/plain; charset=utf-8\u0026#34;); text/xml：用于传输XML数据。常用于配置文件或API响应。 1 response.setContentType(\u0026#34;text/xml; charset=utf-8\u0026#34;); text/css：用于传输CSS样式表。 1 response.setContentType(\u0026#34;text/css; charset=utf-8\u0026#34;); text/javascript：用于传输JavaScript代码。 1 response.setContentType(\u0026#34;text/javascript; charset=utf-8\u0026#34;); 图像类型：\nimage/jpeg：用于传输JPEG格式的图片。 1 response.setContentType(\u0026#34;image/jpeg\u0026#34;); image/png：用于传输PNG格式的图片。 1 response.setContentType(\u0026#34;image/png\u0026#34;); image/gif：用于传输GIF格式的图片。 1 response.setContentType(\u0026#34;image/gif\u0026#34;); 应用类型：\napplication/json：用于传输JSON格式的数据。常用于API响应。 1 response.setContentType(\u0026#34;application/json; charset=utf-8\u0026#34;); application/xml：用于传输XML数据。 1 response.setContentType(\u0026#34;application/xml; charset=utf-8\u0026#34;); application/pdf：用于传输PDF文件。 1 response.setContentType(\u0026#34;application/pdf\u0026#34;); application/zip：用于传输ZIP压缩文件。 1 response.setContentType(\u0026#34;application/zip\u0026#34;); 多部分类型：\nmultipart/form-data：用于文件上传。当表单包含文件上传时使用此类型。 1 response.setContentType(\u0026#34;multipart/form-data; boundary=----WebKitFormBoundaryXXXXX\u0026#34;); multipart/byteranges：用于传输文件的特定部分。 1 response.setContentType(\u0026#34;multipart/byteranges\u0026#34;); 音频和视频类型：\naudio/mpeg：用于传输MP3音频文件。 1 response.setContentType(\u0026#34;audio/mpeg\u0026#34;); video/mp4：用于传输MP4视频文件。 1 response.setContentType(\u0026#34;video/mp4\u0026#34;); 其他类型：\napplication/octet-stream：用于传输二进制流数据，如文件下载。 1 response.setContentType(\u0026#34;application/octet-stream\u0026#34;); application/x-www-form-urlencoded：用于传输表单数据。这是表单提交的默认编码类型。 1 response.setContentType(\u0026#34;application/x-www-form-urlencoded\u0026#34;); 正确设置内容类型对于确保数据正确传输和处理至关重要。例如，如果你返回一个图片文件，但没有设置正确的内容类型，浏览器可能会将响应视为普通文本，导致无法正确显示图片。同样，如果你返回JSON数据，但没有设置application/json类型，客户端可能无法正确解析数据。\n在实际开发中，根据你传输的数据类型选择正确的Content-Type，以确保数据能够被客户端正确处理。\n代码和解析： 1 2 reggie: path: D:\\ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 /** * 文件上传和下载 */ @RestController @RequestMapping(\u0026#34;/common\u0026#34;) @Slf4j public class CommonController { @Value(\u0026#34;${reggie.path}\u0026#34;) private String basePath; /** * 文件上传 * @param file * @return */ @PostMapping(\u0026#34;/upload\u0026#34;) public R\u0026lt;String\u0026gt; upload(MultipartFile file){ //file是一个临时文件，需要转存到指定位置，否则本次请求完成后临时文件会删除 log.info(file.toString()); //原始文件名 String originalFilename = file.getOriginalFilename();//abc.jpg String suffix = originalFilename.substring(originalFilename.lastIndexOf(\u0026#34;.\u0026#34;)); //使用UUID重新生成文件名，防止文件名称重复造成文件覆盖 String fileName = UUID.randomUUID().toString() + suffix;//dfsdfdfd.jpg //创建一个目录对象 File dir = new File(basePath); //判断当前目录是否存在 if(!dir.exists()){ //目录不存在，需要创建 dir.mkdirs(); } try { //将临时文件转存到指定位置 file.transferTo(new File(basePath + fileName)); } catch (IOException e) { e.printStackTrace(); } return R.success(fileName); } /** * 文件下载 * @param name * @param response */ @GetMapping(\u0026#34;/download\u0026#34;) public void download(String name, HttpServletResponse response){ try { //输入流，通过输入流读取文件内容 FileInputStream fileInputStream = new FileInputStream(new File(basePath + name)); //输出流，通过输出流将文件写回浏览器 ServletOutputStream outputStream = response.getOutputStream(); response.setContentType(\u0026#34;image/jpeg\u0026#34;); int len = 0; byte[] bytes = new byte[1024]; while ((len = fileInputStream.read(bytes)) != -1){ outputStream.write(bytes,0,len); outputStream.flush(); } //关闭资源 outputStream.close(); fileInputStream.close(); } catch (Exception e) { e.printStackTrace(); } } } 这段代码是一个Spring Boot控制器CommonController，它提供了文件上传和下载的功能。下面我将逐行解释这段代码：\n@RestController：\n这个注解表明这个类是一个REST控制器，意味着类中的方法会返回数据而不是视图。它相当于@Controller和@ResponseBody的组合。 @RequestMapping(\u0026quot;/common\u0026quot;)：\n这个注解用于映射Web请求到控制器的处理方法上。在这里，它指定了所有请求的URL前缀为/common。 @Slf4j：\n这是Lombok库提供的一个注解，用于自动为类生成一个日志对象（private static final Logger log = LoggerFactory.getLogger(CommonController.class);）。 @Value(\u0026quot;${reggie.path}\u0026quot;)：\n这个注解用于从Spring Boot的配置文件中注入配置值。在这里，它注入了配置文件中reggie.path的值，通常用于指定文件存储的路径。 private String basePath;：\n这是一个类的字段，用于存储文件的存储路径。 @PostMapping(\u0026quot;/upload\u0026quot;)：\n这个注解用于映射POST请求到upload方法上。这意味着当有POST请求发送到/common/upload时，会调用这个方法。 public R\u0026lt;String\u0026gt; upload(MultipartFile file)：\n这是一个处理文件上传的方法。它接受一个MultipartFile类型的参数，这个参数是由Spring MVC自动解析上传的文件。 log.info(file.toString());：\n使用日志记录器记录上传的文件信息。 String originalFilename = file.getOriginalFilename();：\n获取上传文件的原始文件名。 String suffix = originalFilename.substring(originalFilename.lastIndexOf(\u0026quot;.\u0026quot;));：\n从原始文件名中提取文件后缀。 String fileName = UUID.randomUUID().toString() + suffix;：\n生成一个新的文件名，使用UUID确保文件名唯一，防止文件名冲突。 File dir = new File(basePath);：\n创建一个File对象，指向存储文件的目录。 if(!dir.exists()){ dir.mkdirs(); }：\n检查目录是否存在，如果不存在则创建它。 file.transferTo(new File(basePath + fileName));：\n将上传的临时文件移动到指定的存储路径。 return R.success(fileName);：\n返回一个成功的响应，包含新生成的文件名。 接下来是文件下载的方法：\n@GetMapping(\u0026quot;/download\u0026quot;)：\n这个注解用于映射GET请求到download方法上。这意味着当有GET请求发送到/common/download时，会调用这个方法。 public void download(String name, HttpServletResponse response)：\n这是一个处理文件下载的方法。它接受文件名和HttpServletResponse对象作为参数。 FileInputStream fileInputStream = new FileInputStream(new File(basePath + name));：\n创建一个文件输入流，用于读取要下载的文件。 ServletOutputStream outputStream = response.getOutputStream();：\n获取HttpServletResponse的输出流，用于将文件内容写回客户端。 response.setContentType(\u0026quot;image/jpeg\u0026quot;);：\n设置响应的内容类型，这里假设文件是JPEG图片。 int len = 0; byte[] bytes = new byte[1024];：\n定义一个缓冲区，用于存储从文件中读取的数据。 while ((len = fileInputStream.read(bytes)) != -1){ outputStream.write(bytes,0,len); outputStream.flush(); }：\n读取文件内容，并写入到响应的输出流中。 outputStream.close(); fileInputStream.close();：\n关闭打开的流资源。 这个方法通过读取服务器上的文件并将其写入HTTP响应，允许客户端下载文件。需要注意的是，这个方法没有处理异常，实际使用时应该添加适当的异常处理逻辑。此外，basePath应该是一个有效的目录路径，并且在运行应用程序的服务器上可写。\nDTO 它可以说是为了更好的接收和发送数据等，对本来已经有的entity类进行加强。\n接收DTO 例如：\n本来Dish就只有这么多属性，但是现在前端给它传输的不止这些属性，还有一个口味的集合，因此如果想要用@RequestBody Dish dish来就收前端发送过来的请求就没法接收到全部信息了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 /** 菜品 */ @Data public class Dish implements Serializable { private static final long serialVersionUID = 1L; private Long id; private String name; private Long categoryId; private BigDecimal price; private String code; private String image; private String description; private Integer status; private Integer sort; @TableField(fill = FieldFill.INSERT) private LocalDateTime createTime; @TableField(fill = FieldFill.INSERT_UPDATE) private LocalDateTime updateTime; @TableField(fill = FieldFill.INSERT) private Long createUser; @TableField(fill = FieldFill.INSERT_UPDATE) private Long updateUser; } 此时可以利用Dto类。\n将DishDto继承Dish类，就意味着它里面有了Dish的全部属性。现在又往里面添加了一些属性，就形成了Dish的加强类，例如用List集合接收口味的集合。\n1 2 3 4 5 6 7 8 9 10 @Data public class DishDto extends Dish { //菜品对应的口味数据 private List\u0026lt;DishFlavor\u0026gt; flavors = new ArrayList\u0026lt;\u0026gt;(); private String categoryName; private Integer copies; } 此时就可以用DishDto类进行接收信息，但是呢就不能调用MP默认实现的方法了，需要自定义方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 /** * 新增菜品 * @param dishDto * @return */ @PostMapping public R\u0026lt;String\u0026gt; save(@RequestBody DishDto dishDto){ log.info(dishDto.toString()); dishService.saveWithFlavor(dishDto); return R.success(\u0026#34;新增菜品成功\u0026#34;); } 1 2 3 4 5 6 7 8 9 10 11 public interface DishService extends IService\u0026lt;Dish\u0026gt; { //新增菜品，同时插入菜品对应的口味数据，需要操作两张表：dish、dish_flavor public void saveWithFlavor(DishDto dishDto); //根据id查询菜品信息和对应的口味信息 public DishDto getByIdWithFlavor(Long id); //更新菜品信息，同时更新对应的口味信息 public void updateWithFlavor(DishDto dishDto); } 利用已经纳入spring容器管理的DishServiceImpl类，对自身进行处理。\n利用this.save(dishDto);将其中的菜品的属性保存起来，那些多出来的属性就不处理。\n接着对其它属性进行处理。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 @Service @Slf4j public class DishServiceImpl extends ServiceImpl\u0026lt;DishMapper,Dish\u0026gt; implements DishService { @Autowired private DishFlavorService dishFlavorService; /** * 新增菜品，同时保存对应的口味数据 * @param dishDto */ @Transactional public void saveWithFlavor(DishDto dishDto) { //保存菜品的基本信息到菜品表dish this.save(dishDto); Long dishId = dishDto.getId();//菜品id //菜品口味 List\u0026lt;DishFlavor\u0026gt; flavors = dishDto.getFlavors(); flavors = flavors.stream().map((item) -\u0026gt; { item.setDishId(dishId); return item; }).collect(Collectors.toList()); //保存菜品口味数据到菜品口味表dish_flavor dishFlavorService.saveBatch(flavors); } } 发送DTO 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 /** * 菜品信息分页查询 * @param page * @param pageSize * @param name * @return */ @GetMapping(\u0026#34;/page\u0026#34;) public R\u0026lt;Page\u0026gt; page(int page,int pageSize,String name){ //构造分页构造器对象。之所以要有两个，而不直接使用前端需要的DishDto，原因是它并没有对应的各种service、mapper层。 //那么变先将Dish的Page作为桥梁，将其中的数据经过处理转入到DishDto的Page对象里，接着返回给前端。 Page\u0026lt;Dish\u0026gt; pageInfo = new Page\u0026lt;\u0026gt;(page,pageSize); Page\u0026lt;DishDto\u0026gt; dishDtoPage = new Page\u0026lt;\u0026gt;(); //条件构造器 LambdaQueryWrapper\u0026lt;Dish\u0026gt; queryWrapper = new LambdaQueryWrapper\u0026lt;\u0026gt;(); //添加过滤条件 queryWrapper.like(name != null,Dish::getName,name); //添加排序条件 queryWrapper.orderByDesc(Dish::getUpdateTime); //执行分页查询，此时执行过了pageInfo就会包含分页的相关信息 dishService.page(pageInfo,queryWrapper); //对象拷贝，利用spring框架提供的工具类，对类之间数据的转移进行传递，先将获取到的分页后的信息忽略了，因为 //那些信息还需要经过处理才能被使用，等处理好了再放进去，要不然重新覆盖影响效率。 BeanUtils.copyProperties(pageInfo,dishDtoPage,\u0026#34;records\u0026#34;); //获取分页后的具体内容信息 List\u0026lt;Dish\u0026gt; records = pageInfo.getRecords(); //此处对于集合中数据的处理，利用了stream流 List\u0026lt;DishDto\u0026gt; list = records.stream().map((item) -\u0026gt; { DishDto dishDto = new DishDto(); BeanUtils.copyProperties(item,dishDto); Long categoryId = item.getCategoryId();//分类id //根据id查询分类对象 Category category = categoryService.getById(categoryId); if(category != null){ String categoryName = category.getName(); dishDto.setCategoryName(categoryName); } return dishDto; }).collect(Collectors.toList()); dishDtoPage.setRecords(list); return R.success(dishDtoPage); } 像这个也是同种类型的\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 @GetMapping(\u0026#34;/list\u0026#34;) public R\u0026lt;List\u0026lt;DishDto\u0026gt;\u0026gt; list(Dish dish){ //构造查询条件 LambdaQueryWrapper\u0026lt;Dish\u0026gt; queryWrapper = new LambdaQueryWrapper\u0026lt;\u0026gt;(); queryWrapper.eq(dish.getCategoryId() != null ,Dish::getCategoryId,dish.getCategoryId()); //添加条件，查询状态为1（起售状态）的菜品 queryWrapper.eq(Dish::getStatus,1); //添加排序条件 queryWrapper.orderByAsc(Dish::getSort).orderByDesc(Dish::getUpdateTime); List\u0026lt;Dish\u0026gt; list = dishService.list(queryWrapper); List\u0026lt;DishDto\u0026gt; dishDtoList = list.stream().map((item) -\u0026gt; { DishDto dishDto = new DishDto(); BeanUtils.copyProperties(item,dishDto); Long categoryId = item.getCategoryId();//分类id //根据id查询分类对象 Category category = categoryService.getById(categoryId); if(category != null){ String categoryName = category.getName(); dishDto.setCategoryName(categoryName); } //当前菜品的id Long dishId = item.getId(); LambdaQueryWrapper\u0026lt;DishFlavor\u0026gt; lambdaQueryWrapper = new LambdaQueryWrapper\u0026lt;\u0026gt;(); lambdaQueryWrapper.eq(DishFlavor::getDishId,dishId); //SQL:select * from dish_flavor where dish_id = ? List\u0026lt;DishFlavor\u0026gt; dishFlavorList = dishFlavorService.list(lambdaQueryWrapper); dishDto.setFlavors(dishFlavorList); return dishDto; }).collect(Collectors.toList()); return R.success(dishDtoList); } Service和Controller层经常用到的知识点 @RestController @RestController 是 Spring Framework 中的一个注解，用于定义 RESTful 控制器。这个注解是 @Controller 和 @ResponseBody 注解的组合，它表明该控制器中的所有方法都会自动将返回值作为 HTTP 响应的正文（Body），并且不需要返回视图（View）。\n下面是 @RestController 注解的一些关键点：\n注解组合：\n@RestController 是一个组合注解，它本身就包含了 @Controller 和 @ResponseBody。 @Controller 表示该类是一个控制器，用于处理 HTTP 请求。 @ResponseBody 表示该控制器中的方法返回值将直接作为 HTTP 响应正文返回。 自动序列化：\n当你使用 @RestController 注解时，Spring MVC 会自动将方法的返回值序列化为 JSON（或其他格式，取决于配置的消息转换器）并写入 HTTP 响应正文中。 无需视图解析器：\n由于 @RestController 包含了 @ResponseBody，所以不需要 Spring 的视图解析器来解析返回值。这意味着你可以返回任意的 Java 对象，而不需要担心它们如何被渲染为 HTML。 简化代码：\n使用 @RestController 可以简化代码，因为你不需要在每个方法上都添加 @ResponseBody 注解。 RESTful API：\n@RestController 通常用于构建 RESTful API，因为它使得返回 JSON 数据变得非常简单。 下面是一个使用 @RestController 注解的简单示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; @RestController public class MyRestController { @GetMapping(\u0026#34;/hello\u0026#34;) public String sayHello() { return \u0026#34;Hello, World!\u0026#34;; } @GetMapping(\u0026#34;/users/{id}\u0026#34;) public User getUserById(@PathVariable Long id) { // 假设这里通过 id 获取用户信息 return new User(id, \u0026#34;John Doe\u0026#34;); } } 在这个例子中，MyRestController 类使用了 @RestController 注解，所以它的所有方法都会自动将返回值作为 HTTP 响应正文返回。sayHello 方法返回一个简单的字符串，而 getUserById 方法返回一个 User 对象，这个对象将被自动序列化为 JSON 格式。\n使用 @RestController 注解是创建 RESTful Web 服务时的一种常见做法，它使得控制器代码更加简洁和专注于业务逻辑。\n@RequestMapping @RequestMapping 是 Spring Framework 中的一个注解，用于将 HTTP 请求映射到特定的处理方法上。这个注解可以用于定义请求的类型、路径以及其他映射信息，它表明了控制器中的方法如何处理特定的 HTTP 请求。\n以下是 @RequestMapping 注解的一些关键特性：\n请求类型：\n可以通过 method 属性指定请求的类型，如 GET、POST、PUT、DELETE 等。 请求路径：\n可以通过 value 或 path 属性指定请求的路径。value 是 path 的别名，两者可以互换使用。 参数条件：\n可以通过 params 属性指定请求参数的条件，只有当这些条件满足时，请求才会映射到对应的方法。 头部条件：\n可以通过 headers 属性指定请求头部的条件。 请求消费类型：\n可以通过 consumes 属性指定请求体可以消费的媒体类型。 请求产生类型：\n可以通过 produces 属性指定响应可以产生的媒体类型。 组合使用：\n可以在同一个方法上使用多个 @RequestMapping 注解，来处理不同的路径或请求类型。 继承：\n@RequestMapping 注解可以继承，这意味着你可以在控制器类上使用 @RequestMapping 来定义一个基础路径，然后在该类的方法上使用 @RequestMapping 来定义相对路径。 下面是一个使用 @RequestMapping 注解的示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RequestMethod; import org.springframework.web.bind.annotation.RestController; @RestController public class MyController { // 映射 GET 请求到 \u0026#34;/employees\u0026#34; 路径 @RequestMapping(value = \u0026#34;/employees\u0026#34;, method = RequestMethod.GET) public List\u0026lt;Employee\u0026gt; getAllEmployees() { // 返回所有员工信息 return employeeService.getAllEmployees(); } // 映射 POST 请求到 \u0026#34;/employees\u0026#34; 路径 @RequestMapping(value = \u0026#34;/employees\u0026#34;, method = RequestMethod.POST) public Employee createEmployee(@RequestBody Employee employee) { // 创建一个新的员工 return employeeService.createEmployee(employee); } } 在这个例子中，MyController 类中的两个方法分别处理不同的 HTTP 请求类型。getAllEmployees 方法处理 GET 请求，返回所有员工的信息；createEmployee 方法处理 POST 请求，创建一个新的员工记录。\n使用 @RequestMapping 注解可以清晰地定义控制器方法与 HTTP 请求之间的关系，使得代码更加模块化和易于维护。\n@Slf4j @Slf4j 是 Lombok 库提供的一个注解，用于在类中自动生成一个日志对象。当你在类上使用 @Slf4j 注解时，Lombok 会在编译期间为你生成一个日志实例，通常是 private static final Logger log = LoggerFactory.getLogger(YourClass.class); 这样的形式。\n下面是 @Slf4j 注解的一些关键点：\n日志实例：\n@Slf4j 注解会自动为你的类创建一个日志实例，你可以直接在类的方法中使用这个实例来记录日志。 无需手动创建：\n使用 @Slf4j 注解后，你不需要手动创建日志对象，这简化了代码，特别是在有许多日志记录的类中。 支持多种日志框架：\nLombok 支持多种日志框架，包括 SLF4J、Log4j、Java Util Logging 等。@Slf4j 注解特别为 SLF4J 日志框架生成日志实例。 线程安全：\n自动生成的日志实例是线程安全的，可以在多线程环境中使用。 性能：\n使用 @Slf4j 注解生成的日志实例通常比手动创建的日志实例性能更好，因为它们是通过注解在编译时生成的。 灵活性：\n你可以选择在类级别使用 @Slf4j 注解，或者在方法级别使用其他 Lombok 日志注解，如 @Log（Log4j）、@Logger（Java Util Logging）等。 下面是一个使用 @Slf4j 注解的示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import lombok.extern.slf4j.Slf4j; @Slf4j public class MyClass { public void doSomething() { log.info(\u0026#34;Doing something\u0026#34;); // 如果发生异常 try { // 一些可能抛出异常的代码 } catch (Exception e) { log.error(\u0026#34;Error occurred\u0026#34;, e); } } } 在这个例子中，MyClass 类使用了 @Slf4j 注解，因此它自动获得了一个日志实例 log。在 doSomething 方法中，你可以使用 log 来记录不同级别的日志信息。\n使用 @Slf4j 注解可以显著减少样板代码，让你更专注于业务逻辑。此外，它还有助于保持代码的整洁和一致性。\n@Data @Data 是 Lombok 库提供的一个注解，用于在类上自动生成一系列的常用方法，包括：\ngetter 和 setter 方法：为类的每个字段生成对应的获取（getter）和设置（setter）方法。\ntoString() 方法：生成一个包含所有字段值的字符串表示形式的方法。\nequals() 方法：生成一个比较两个对象是否相等的方法，通常基于所有字段的值进行比较。\nhashCode() 方法：生成一个基于对象字段值的哈希码计算方法。\n使用 @Data 注解可以显著减少在 Java 类中编写样板代码的工作量，让你更专注于业务逻辑的实现。下面是一个使用 @Data 注解的示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 import lombok.Data; @Data public class User { private String name; private int age; private String email; // 使用 @Data 注解后，以下方法将自动生成： // - name() getter 方法 // - setName(String name) setter 方法 // - age() getter 方法 // - setAge(int age) setter 方法 // - email() getter 方法 // - setEmail(String email) setter 方法 // - User [name=Kimi, age=30, email=kimi@moonshot.cn] toString() 方法 // - equals(Object o) 方法 // - hashCode() 方法 } 在这个例子中，User 类使用了 @Data 注解，因此 Lombok 会在编译时自动为这个类的每个字段生成 getter 和 setter 方法，以及 toString()、equals() 和 hashCode() 方法。\n使用 @Data 注解的好处包括：\n减少代码量：自动生成的方法减少了手动编写这些常用方法的需要。 保持一致性：自动生成的方法遵循一致的编码风格和逻辑。 提高效率：减少了编写和维护样板代码的时间，提高了开发效率。 减少错误：自动生成的方法减少了手动编写方法时可能出现的错误。 请注意，为了使用 Lombok 注解，你需要在项目中引入 Lombok 库，并确保你的 IDE 支持 Lombok 插件。这样，当你编译项目时，Lombok 会在编译期间自动为你生成所有注解指定的代码。\n@RequiredArgsConstructor @RequiredArgsConstructor 是 Lombok 提供的一个注解，它用于在类上自动生成一个构造函数，这个构造函数包括所有被标记为 final 的成员变量以及用 @NonNull 注解标记的成员变量。这个注解大大简化了必须参数的构造函数的编写，尤其是在需要注入依赖或常量值时。\n以下是 @RequiredArgsConstructor 注解的一些关键点：\n自动生成构造函数：\n@RequiredArgsConstructor 会为类生成一个构造函数，包含所有 final 字段和标记为 @NonNull 的字段作为参数。 减少代码量：\n使用 @RequiredArgsConstructor 可以避免手动编写构造函数，从而减少代码量。 强制依赖注入：\n通过生成的构造函数，可以实现依赖的自动注入，这对于 Spring 框架中的依赖注入尤为重要。 支持不变性：\n对于被标记为 final 的字段，一旦它们通过构造函数被赋值后，就不能被更改，这有助于创建更稳定、可预测的代码。 清晰的依赖关系：\n自动生成的构造函数明确要求必须提供所有必需的依赖，这使得开发者在使用类的时候更加清晰地了解到哪些依赖是必须的。 使用示例：\n1 2 3 4 5 6 7 8 import lombok.RequiredArgsConstructor; import org.springframework.stereotype.Service; @Service @RequiredArgsConstructor public class MyService { private final MyDependency dependency; } 在这个例子中，MyService 类使用了 @RequiredArgsConstructor 注解，因此 Lombok 会生成一个构造函数，该构造函数要求必须提供 MyDependency 的一个实例。这样，Spring 就可以通过这个构造函数自动注入 MyDependency 的实例。\n需要注意的是，使用 @RequiredArgsConstructor 注解时，需要注入的类成员变量必须被声明为 final，或者使用 @NonNull 注解标记为非空。这样可以确保这些依赖在使用前已经被正确初始化。\n@Autowired @Autowired 是 Spring 框架中使用的一个注解，用于实现依赖注入。当你在一个字段、构造函数、设置方法（setter method）或者普通方法（non-constructor, non-setter method）上使用 @Autowired 注解时，Spring 容器在创建 Bean 实例时会自动注入相应的依赖。\n以下是 @Autowired 注解的一些关键特性：\n自动注入：\nSpring 会自动注入与注解标记的字段、构造函数或方法参数相匹配的 Bean。 按类型注入：\n默认情况下，@Autowired 按照类型（by type）进行注入，这意味着如果存在多个相同类型的 Bean，Spring 将抛出异常，除非你使用 @Qualifier 注解指定具体的 Bean 名称。 按名称注入：\n通过结合使用 @Autowired 和 @Qualifier 注解，可以按照 Bean 的名称（by name）进行注入。 构造函数注入：\n当 @Autowired 注解用于构造函数时，Spring 将使用构造函数注入（constructor injection）的方式创建 Bean 实例。 设置方法注入：\n当 @Autowired 注解用于设置方法（如 setSomething(Something something)）时，Spring 将调用该方法注入依赖。 字段注入：\n当 @Autowired 注解直接用于字段时，Spring 将直接注入依赖到该字段。 可选依赖：\n可以通过设置 @Autowired 注解的 required 属性为 false 来标记某个依赖是可选的。如果该依赖不存在，Spring 不会抛出异常。 在普通方法上的使用：\n从 Spring 4.3 开始，@Autowired 也可以用于普通方法上，这允许更灵活的依赖注入方式。 下面是一个使用 @Autowired 注解的示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Component; @Component public class MyComponent { private final MyDependency myDependency; @Autowired public MyComponent(MyDependency myDependency) { this.myDependency = myDependency; } // 或者使用设置方法注入 @Autowired public void setMyDependency(MyDependency myDependency) { this.myDependency = myDependency; } // 或者直接在字段上使用 @Autowired private MyDependency myDependency; // 使用 @Qualifier 按名称注入 @Autowired private MyDependency myDependency; public void doSomething() { myDependency.doSomething(); } } 在这个例子中，MyComponent 类通过构造函数注入的方式注入了 MyDependency 的实例。如果 MyDependency 只有一个 Bean 定义，Spring 将自动注入这个 Bean。如果有多个 MyDependency 类型的 Bean，你需要使用 @Qualifier 来指定注入哪一个。\n使用 @Autowired 注解可以显著减少配置工作量，使代码更简洁，并且有助于实现松耦合和更高的测试性。\nBeanUtils类 BeanUtils 是 Spring 框架提供的一个实用工具类，位于 org.springframework.beans 包中。它主要用于简化 JavaBean 对象之间的属性拷贝和赋值操作。以下是 BeanUtils 中一些常用方法的使用方法和案例：\n1. BeanUtils.copyProperties(source, target)\n这个方法用于将一个 JavaBean 对象（source）的属性值复制到另一个 JavaBean 对象（target）中。它会自动匹配两个 Bean 对象中相同名称的属性，并将源 Bean 对象中对应属性的值复制到目标 Bean 对象中。\n使用方法：\n1 BeanUtils.copyProperties(sourceBean, targetBean); 案例： 假设我们有两个类 User 和 UserDto，我们想将 User 对象的属性复制到 UserDto 对象中：\n1 2 3 4 5 6 User user = new User(); user.setId(1L); user.setName(\u0026#34;John Doe\u0026#34;); UserDto userDto = new UserDto(); BeanUtils.copyProperties(user, userDto); 在这个例子中，user 对象的 id 和 name 属性将被复制到 userDto 对象中 。\n2. BeanUtils.copyProperties(dest, orig, ignoreProperties)\n这个方法是在 copyProperties 的基础上，增加了忽略特定属性的功能。当你不想复制某些属性时，可以使用这个方法。\n使用方法：\n1 BeanUtils.copyProperties(sourceBean, targetBean, \u0026#34;ignoreProperty1\u0026#34;, \u0026#34;ignoreProperty2\u0026#34;); 案例： 假设我们不想复制 User 对象的 password 属性：\n1 2 3 4 5 6 7 User user = new User(); user.setId(1L); user.setName(\u0026#34;John Doe\u0026#34;); user.setPassword(\u0026#34;secret\u0026#34;); UserDto userDto = new UserDto(); BeanUtils.copyProperties(user, userDto, \u0026#34;password\u0026#34;); 在这个例子中，user 对象的 id 和 name 属性将被复制到 userDto 对象中，但 password 属性将被忽略 。\n3. BeanUtils.copyProperties(dest, orig, Class\u0026lt;?\u0026gt; editable)\n这个方法允许你指定一个编辑类，只有在这个类中定义的属性才会被复制。\n使用方法：\n1 BeanUtils.copyProperties(sourceBean, targetBean, SomeInterface.class); 案例： 假设我们有一个接口 Auditable，它定义了 createdBy 和 createdDate 属性。我们只想复制实现了这个接口的类的属性：\n1 2 3 Auditable auditable = new SomeAuditableImpl(); User user = new User(); BeanUtils.copyProperties(auditable, user, Auditable.class); 在这个例子中，只有 Auditable 接口中定义的属性将被复制到 user 对象中 。\n注意事项：\n属性名称和类型匹配：源对象和目标对象的属性名必须相同，类型也需要匹配或可以自动转换。 浅拷贝：BeanUtils.copyProperties 实现的是浅拷贝，即如果属性是引用类型，复制的是引用而不是实际的对象 。 null值覆盖：默认情况下，源对象中的 null 值属性会覆盖目标对象中对应的属性值 。 安全性：使用反射可能会带来安全风险，需要确保代码的安全性。 性能：反射机制可能会影响性能，尤其是在性能敏感的场景下 。 通过这些方法，你可以灵活地在不同的 JavaBean 对象之间复制属性，从而简化代码并提高开发效率。\nMD5以及其它加密算法 在现代密码学中，有多种加密算法被认为比MD5更安全，以下是一些常用的加密算法及其特点：\nSHA-256：\nSHA-256（Secure Hash Algorithm 256）是SHA-2家族中的一种加密哈希函数。它生成一个256位（32字节）的哈希值，对输入数据进行唯一的固定大小哈希值映射。 特点包括数据完整性验证、唯一性和不可逆性。SHA-256在区块链技术中被广泛使用，如比特币区块链。 SHA-512：\nSHA-512是SHA-2家族中的另一种加密哈希函数，它生成一个512位（64字节）的哈希值。 它比SHA-256提供更高的安全性，因为哈希值更长，但计算速度较慢。通常用于存储高度敏感数据的场景。 Argon2：\nArgon2是一种内存硬哈希函数，设计用于密码哈希，需要大量内存来计算哈希值，这使得它非常适合用于保护密码。 Argon2在2015年赢得了密码哈希竞赛，被选为新的密码哈希标准。它能有效抵抗暴力破解攻击。 bcrypt：\nbcrypt是一种专门设计用于密码存储的哈希函数，它通过使用“代价函数”来增加破解密码的难度。 bcrypt在哈希计算过程中使用盐值（salt）和多次迭代来增强安全性，被广泛用于保护用户密码。 AES（Advanced Encryption Standard）：\nAES是一个广泛使用的对称加密标准，用于保护电子数据的安全性。 AES支持多种密钥长度（128、192、256位），并且因其强大的安全性和较高的效率而被许多组织采用。 ECC（Elliptic-curve cryptography）：\nECC是一种基于椭圆曲线数学的公钥加密技术，它提供了与非对称加密算法（如RSA）相比更短的密钥长度和更高的安全性。 ECC在需要高效密钥交换和数字签名的场景中非常有用。 Twofish：\nTwofish是一种对称密钥加密算法，由Bruce Schneier设计，用于替代Blowfish和DES。 Twofish使用128至256位的密钥长度，提供了强大的安全性和较快的处理速度。 Quantum-resistant algorithms：\n随着量子计算的发展，一些加密算法可能在未来面临安全威胁。为了应对这一挑战，NIST（美国国家标准与技术研究院）已经选择了一些量子抗性加密算法，如CRYSTALS-Kyber、CRYSTALS-Dilithium、FALCON和SPHINCS+。这些算法基于结构化格和哈希函数，旨在抵御量子计算机的攻击。 选择哪种加密算法取决于具体的应用场景、数据敏感性、性能要求和安全需求。对于需要高安全性的应用，推荐使用SHA-256、SHA-512、Argon2或AES等算法。对于需要抵御量子计算攻击的场景，可以考虑使用NIST推荐的量子抗性加密算法。\n移动端本地验证码生成和登录 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 package com.itheima.reggie.utils; import java.util.Random; /** * 随机生成验证码工具类 */ public class ValidateCodeUtils { /** * 随机生成验证码 * @param length 长度为4位或者6位 * @return */ public static Integer generateValidateCode(int length){ Integer code =null; if(length == 4){ code = new Random().nextInt(9999);//生成随机数，最大为9999 if(code \u0026lt; 1000){ code = code + 1000;//保证随机数为4位数字 } }else if(length == 6){ code = new Random().nextInt(999999);//生成随机数，最大为999999 if(code \u0026lt; 100000){ code = code + 100000;//保证随机数为6位数字 } }else{ throw new RuntimeException(\u0026#34;只能生成4位或6位数字验证码\u0026#34;); } return code; } /** * 随机生成指定长度字符串验证码 * @param length 长度 * @return */ public static String generateValidateCode4String(int length){ Random rdm = new Random(); String hash1 = Integer.toHexString(rdm.nextInt()); String capstr = hash1.substring(0, length); return capstr; } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 @RestController @RequestMapping(\u0026#34;/user\u0026#34;) @Slf4j public class UserController { @Autowired private UserService userService; /** * 发送手机短信验证码 * @param user * @return */ @PostMapping(\u0026#34;/sendMsg\u0026#34;) public R\u0026lt;String\u0026gt; sendMsg(@RequestBody User user, HttpSession session){ //获取手机号 String phone = user.getPhone(); if(StringUtils.isNotEmpty(phone)){ //生成随机的4位验证码 String code = ValidateCodeUtils.generateValidateCode(4).toString(); log.info(\u0026#34;code={}\u0026#34;,code); //调用阿里云提供的短信服务API完成发送短信 //SMSUtils.sendMessage(\u0026#34;瑞吉外卖\u0026#34;,\u0026#34;\u0026#34;,phone,code); //需要将生成的验证码保存到Session session.setAttribute(phone,code); return R.success(\u0026#34;手机验证码短信发送成功\u0026#34;); } return R.error(\u0026#34;短信发送失败\u0026#34;); } /** * 移动端用户登录 * @param map * @param session * @return */ @PostMapping(\u0026#34;/login\u0026#34;) public R\u0026lt;User\u0026gt; login(@RequestBody Map map, HttpSession session){ log.info(map.toString()); //获取手机号 String phone = map.get(\u0026#34;phone\u0026#34;).toString(); //获取验证码 String code = map.get(\u0026#34;code\u0026#34;).toString(); //从Session中获取保存的验证码 Object codeInSession = session.getAttribute(phone); //进行验证码的比对（页面提交的验证码和Session中保存的验证码比对） if(codeInSession != null \u0026amp;\u0026amp; codeInSession.equals(code)){ //如果能够比对成功，说明登录成功 LambdaQueryWrapper\u0026lt;User\u0026gt; queryWrapper = new LambdaQueryWrapper\u0026lt;\u0026gt;(); queryWrapper.eq(User::getPhone,phone); User user = userService.getOne(queryWrapper); if(user == null){ //判断当前手机号对应的用户是否为新用户，如果是新用户就自动完成注册 user = new User(); user.setPhone(phone); user.setStatus(1); userService.save(user); } session.setAttribute(\u0026#34;user\u0026#34;,user.getId()); return R.success(user); } return R.error(\u0026#34;登录失败\u0026#34;); } } 其它的都是一些逻辑性的东西，以及m和mp的知识点，和stream流 成功\n","date":"2024-01-06T00:00:00Z","image":"https://gkxgithub.github.io/p/%E7%91%9E%E5%90%89%E5%A4%96%E5%8D%96%E9%A1%B9%E7%9B%AE%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB/6bca15b627dacad59c574b85416e62e_hu12018104262536241019.jpg","permalink":"https://gkxgithub.github.io/p/%E7%91%9E%E5%90%89%E5%A4%96%E5%8D%96%E9%A1%B9%E7%9B%AE%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB/","title":"瑞吉外卖项目代码解读"},{"content":"第一章linux相关的基础 1.linux的常见目录结构 如果版本不同，linux的目录结构可能略有不同。\ncentos7的文件目录结构\nlinux根目录下的常见目录及作用\n1. /bin：★(/usr/bin,/usr/local/bin)\n是Binary的缩写, 这个目录存放着最经常使用的命令,Linux默认的环境变量已经包含该路径,所以可以直接使用该路径下的指令如 cd指令 可以通过echo $PATH查看系统环境变量来看是否包含了该目录\n2. /sbin：(/usr/sbin, /usr/local/sbin)\ns就是Super User的意思，这里存放的是系统管理员使用的系统管理程序。\n以上6个目录，任何命令在任意目录下都可执行命令\n3. /home：★\n存放普通用户的主目录，在Linux中每个用户都有一个自己的目录，一般该目录名是以用户的账号命名的。\n4. /root：★\n该目录为系统管理员，也称作超级权限者的用户主目录。\n5. /lib：\n系统开机所需要最基本的动态连接共享库，其作用类似于Windows里的DLL文件。几乎所有的应用程序都需要用到这些共享库。\n6. /lost+found：\n这个目录一般情况下是空的，当系统非法关机后，这里就存放了一些文件。\n7. /etc：★\n所有的系统管理所需要的配置文件和子目录。my.cnf\n8. /usr：★ 这是一个非常重要的目录，用户的很多应用程序和文件都放在这个目录下，类似与windows下的program files目录。\n9. /boot：★\n这里存放的是启动Linux时使用的一些核心文件，包括一些连接文件以及镜像文件，自己的安装别放这里 10. /proc：\n这个目录是一个虚拟的目录，它是系统内存的映射，我们可以通过直接访问这个目录来获取系统信息。\n11. /srv：\nservice缩写，该目录存放一些服务启动之后需要提取的数据。\n12. /sys： 这是linux2.6内核的一个很大的变化。该目录下安装了2.6内核中新出现的一个文件系统 sysfs 。（内核）\n13. /tmp：\n这个目录是用来存放一些临时文件的。\n14. /dev：★\nDevice(设备)的缩写,类似windows的设备管理器，把所有的硬件用文件的形式存储。 15. /media：★\nlinux系统会自动识别一些设备，例如U盘、光驱等等，当识别后，linux会把识别的设备挂载到这个目录下。CentOS6 就在/media下,CentOS7换目录了/\n16. /mnt：★\n系统提供该目录是为了让用户临时挂载别的文件系统的，我们可以将光驱挂载在/mnt/上，然后进入该目录就可以查看光驱里的内容了。\n17. /opt：★\n这是给主机额外安装软件所摆放的目录。\n比如你安装JDK、Tomcat则就可以放到这个目录下。默认是空的。\n18. /usr/local: ★\n这是另一个给主机额外安装软件所摆放的目录.一般是通过编译源码方式安装的程序。\n19. /var：★\n这个目录中存放着在不断扩充着的东西，我们习惯将那些经常被修改的目录放在这个目录下。包括各种日志文件。\n2.虚拟机网络配置 学习目标\n1 熟练查看虚拟机网络配置信息\n2 熟悉WMware的联网模式及特点\n3 熟练在NAT模式下,将虚拟机IP设置为固定IP\n2.1查看网络信息 在VMware中查看当前虚拟机的联网模式\n模式1 仅主机模式特点 特点 虚拟机只能和宿主机之间实现通信 缺点 只有宿主机和虚拟机之前能通信,虚拟机联网需要做更多的配置 模式2 桥接模式特点 特点 宿主机和虚拟机,都是由局域网路由(DHCP)进行IP的分配 宿主机和本地的虚拟机之间可以进行通信 局域网内其他机器也可以与虚拟机进行通信 缺点 虚拟机会占用大量的IP,局域网内如果机器太多,或者虚拟机太多,那么会出现大量的IP冲突 模式3 NAT模式特点 特点 宿主机和其他机器的IP由局域网路由进行IP的分配,虚拟机的IP通过VMnet8虚拟交换机进行分配 宿主机和本地的虚拟机之间可以进行通信 不会占用宿主机所在路由IP,不会造成IP冲突 缺点 局域网内的机器无法与其他机器上的虚拟机进行通信 关于模式的选择 什么时候选择NAT模式? 在教室内,因为大量同学使用同一个路由,避免大量的IP冲突 我们在学习阶段,主要满足我们自己的计算机(宿主机)和本地虚拟机之间的通信以及虚拟机的联网 什么时候选择桥接模式? 自己独立的路由,想在局域网内实现虚拟机和其他计算机之间的通信 未来如何选择 未来这些问题会由运维人员来处理 未来我们使用的服务器不会在本地,使用远程服务器,自然也不需要我们来处理这种问题 2.2修改网络配置信息 第一步: 打开VMware,打开虚拟网络编辑器\n第二步: 选择NAT模式,对网段进行调整\n第三步: 设置NAT模式的网关\n第四步: 检查是否有漏选的选项\n第五步: 修改虚拟机自己的网络模式选用模式为NAT\n第六步: 修改虚拟机ens33网卡的网络配置信息\n3.虚拟机管理操作 3.1VMware为虚拟机拍摄快照 通过快照可快速保存虚拟机当前的状态,后续可以使用快照,将虚拟机还原到某个快照的状态. 如某个软件安装失败,可以通过快照快速还原回指定的某个状态\n选择指定的虚拟机拍摄快照 输入快照名称,添加快照描述 通过快照恢复虚拟机状态 管理和废弃快照 3.2VMware为虚拟机执行克隆 第一步: 关闭要克隆的虚拟机\n第二步: 选中虚拟机,右击\u0026gt;管理\u0026gt;克隆\n第三步: 可以选择虚拟当前状态和某个快照状态进行克隆\n第四步: 创建完整克隆\n第五步: 注意修改克隆之后的虚拟机的名称和存放路径\n第六步: 克隆完成,关闭即可\n第七步: 修改克隆出来的虚拟机的主机名和IP配置,然后重启\n4.远程工具的使用 学习目标\n1 熟练安装和使用Xhsell\n2 熟练安装和使用Xftp\n3 熟练安装和使用 finalshell\n4.1Xshell的安装和使用 Linux一般作为服务器使用,服务器一般都放在机房,不可能是你身边的Linux服务器,这时候我们需要一些工具来连接远程的Linux服务器来进行操作,xshell就是一种远程连接工具,其他Windows上常见的远程登录客户端有 SecureCRT, Putty,SSHSecure Shell,等\nLinux系统中是通过SSH服务 实现的远程登录功能,默认ssh服务的端口号是22\n双击安装程序,进行安装 开始安装 选择商业 接收许可协议 购买软件后输入密钥 选择合适的安装位置 选择程序文件夹,直接下一步 选择语言 安装进度 安装完成 重启windows计算机 启动Xshell,建立和服务器连接 输入虚拟机IP和连接名称 点击连接远程Linux 接受主机密钥并保存 输入并记住用户名 输入并记住密码 连接成功 设置字体大小 断开连接 查看已经创建好的连接 点击连接即可自动连接对应的服务器 4.2Xftp的安装和使用 通过Xshell可以连接远程Linux服务器,并通过命令操作远程虚拟机,但是Xshell无法完成较大的文件上传和下载,此时需要Xftp来完成\n安装过程和Xshell基本一致 安装完成后,可以通过XShell来开启Xftp,然后执行文件上传下载操作 xshell连接虚拟机如果比较慢 修改/etc/ssh 目录下的配置文件 sshd_config 命令 vim/etc/ssh/sshd_config 在sshd_config 115行,将 UseDNS前面的#去掉,然后将值改为no 重启虚拟机,应该就能很快连接上 4.3finalShell的安装和使用 finalShell是一款国产的服务器远程连接工具,集成了命令操作和文件上传功能,基础功能基本免费\n双击安装包,开始安装 选择合适的安装位置 点击确定继续安装 安装完成启动程序创建连接 连接成功,查看已创建的连接列表 查看服务器目前的状态信息 5.拓展Linux阿里云ECS的安装部署 5.1学习目标 了解阿里云ECS 购买阿里云服务器 使用XShell远程连接ECS 了解 ECS与虚拟机的区别 认识阿里云ECS的安全组机制 5.2ECS是什么 ​ 云服务器 ECS（Elastic Compute Service）是一种安全可靠、弹性可伸缩的云计算服务，帮助用户降低 IT 成本，提升运维效率，使用户更专注于核心业务创新。\n​ 支持包年包月，按量付费等多种购买方式。更有利于生产开发中弹性扩容服务器数量。自动化的安装部署加维护，也让使用变得更加便捷。\n5.3购买ECS ​ 点击产品ECS进入到阿里云购买页面。\n​ 选择购买类型为抢占式实例，相对比较便宜。选择地域接近的物理地址，延迟比较低。使用默认的交换机。\n​ 选择硬件配置，使用推荐的经济型就可以完成Linux的学习。\n​ 选择不要自动释放，由用户手动控制释放。\n​ 设置使用的网络类型，推荐使用流量付费，相对比较便宜。\n​ 填写root用户的密码用于登录使用，之后确认协议即可下单。\n​ 之后在控制台就能看到对应购买完成的服务器\n5.4使用XShell远程连接 ​ 打开XShell编译几个新的连接\n​ 同时点击用户认证页面，添加用户名和密码。\n​ 实际生产开发中，会一次性采购多台阿里云ECS，由于公网IP都是随机发布的，为了使用方便一般会使用hosts文件映射。\n​ windows电脑的hosts文件在路径C:\\Windows\\System32\\drivers\\etc下面。\n​ 使用管理员权限打开一个文本编辑器\n之后修改内容到hosts文件末尾即可\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #-------- 公共配置 -------- # Copyright (c) 1993-2009 Microsoft Corp. # # This is a sample HOSTS file used by Microsoft TCP/IP for Windows. # # This file contains the mappings of IP addresses to host names. Each # entry should be kept on an individual line. The IP address should # be placed in the first column followed by the corresponding host name. # The IP address and the host name should be separated by at least one # space. # # Additionally, comments (such as these) may be inserted on individual # lines or following the machine name denoted by a \u0026#39;#\u0026#39; symbol. # # For example: # # 102.54.94.97 rhino.acme.com # source server # 38.25.63.10 x.acme.com # x client host # localhost name resolution is handled within DNS itself. #\t127.0.0.1 localhost #\t::1 localhost 121.40.184.76\taliyun200 ​ 之后连接ECS的ip地址就可以全部替换为aliyun200\n​ 5.5认识修改ECS的安全组设置 ​ 可以在阿里云页面修改ECS的主机名称，保持在阿里云页面的对应关系。\n修改完成之后重启ECS服务器生效。\n阿里云安全组是一种虚拟防火墙，用于控制安全组内 ECS实例的入流量和出流量。因为在实际的生产开发中，是不可能将防火墙关闭掉的，所有的端口放开都需要进行单独的配置。\n​ 配置的参数主要有两个，一个是放开的端口号，一个是运行访问的ip地址。\n请根据实际场景设置授权对象的CIDR，另外，0.0.0.0/0或者掩码为0，代表允许或拒绝所有IP的访问，设置时请务必谨慎。\n第二章常见linux命令 1 了解Linux帮助类命令\n2 熟悉开关机命令\n3 熟练文件目录类命令\n4 熟悉时间日期类命令\n5 熟悉用户管理命令\n6 熟悉组管理命令\n7 熟练文件权限命令\n8 熟悉搜索查找类命令\n9 熟练压缩和解压缩命令\n10 熟悉磁盘分区类命令\n11 熟练进程线程类命令\n12 了解系统定时任务命令\n1.帮助类命令 man获取帮助信息\n语法\nman [命令或配置文件] （功能描述：获得帮助信息） 显示说明\n信息 功能 NAME 命令的名称和单行描述 SYNOPSIS 怎样使用命令 DESCRIPTION 命令功能的深入讨论 EXAMPLES 怎样使用命令的例子 SEE ALSO 相关主题（通常是手册页） 实操案例\n查看ls命令的帮助信息 1 [root@centos100 ~]# man ls help获得shell内置命令的帮助信息\n基本语法\nhelp 命令 （功能描述：获得shell内置命令的帮助信息） 案例实操\n查看cd命令的帮助信息 1 [root@centos100 ~]# help cd 2.开关机类命令 一般Linux不会经常进行关机操作,正确的关机流程为: sync\u0026gt;shutdown\u0026gt; reboot \u0026gt;poweroff\n基本语法\nsync 将内存中的数据同步到硬盘中 poweroff 关闭系统, 等同于shutdown -h now reboot 重启系统,等同于shutdown -r now shutdown[选项] 时间 选项\n选项 功能 -h -h=halt关机 -r -r=reboot重启 参数 参数 功能 now 立刻关机 时间 等待多久之后关机,单位为分钟 注意事项\nLinux系统中为了提高磁盘读写效率,对磁盘采取了\u0026quot;预读迟写\u0026quot;操作方式,当用户保存文件时,Linux核心并不一定对保存的数据立刻写入物理磁盘,而是将数据保存在缓冲区中,等缓冲区写满时再写入磁盘,这种方式可以极大的提高磁盘写入数据的效率.同时也带来了安全隐患. 如果数据还未写入磁盘时,系统掉电或者出现其他严重的问题造成宕机,可能会造成数据的丢失.使用sync指令可以立即将缓冲区的数据写入磁盘\n临时开关服务命令\n语法\ncentos6 service 服务名 start 开启服务 service 服务名 stop 关闭服务 service 服务名 restart 重启服务 service 服务名 status 查看服务状态 centos7 systemctl start 服务名 开启服务 systemctl stop 服务名 关闭服务 systemctl restart 服务名 重启服务 systemctl status 服务名 查看服务 systemctl \u0026ndash;type service 查看正在运行的服务 实操\n1 查看网络服务状态 1 systemctl status network.service 2 关闭服务 1 systemctl stop network.service 3 启动服务 1 systemctl start network.service 4 重启服务 1 systemctl restart network.service 查看所有服务 1 systemctl --type service .service后缀可以省略不写\n永久开关服务命令\n语法\ncentos6 chkconfig 查看所有服务自启配置 chkconfig 服务名 off 关闭服务自启 chkconfig 服务名 on 开启服务自启 chkconfig 服务名 \u0026ndash;list 查看服务开机启动状态 centos7 systemctl enable 服务名 打开自启 systemctl disable 服务名 关闭自启 systemctl is-enabled 服务名 查看服务是否自启 systemctl list-unit-files 查看所有服务自启配置 实操\n1 关闭防火墙自动启动 1 2 systemctl status firewalld 查看防火墙 systemctl disable firewalld 关闭防火墙自启 2 开启防火墙自启 1 systemctl enable firewalld 3 查看防火墙是否自启 1 systemctl is-enabled firewalld 4 关闭网络管理器服务 1 2 3 4 查看服务systemctl status NetworkManager.service 停止服务 systemctl stop NetworkManager 查看自启动 systemctl is-enabled NetworkManager 关闭自启动systemctl disable NetworkManager Linux系统有7种运行级别(runlevel)：常用的是级别3和5(CentOS7中只有两个级别了：3和5)\n运行级别0：系统停机状态，系统默认运行级别不能设为0，否则不能正常启动\n运行级别1：单用户工作状态，root权限，用于系统维护，禁止远程登陆\n运行级别2：多用户状态(没有NFS)，不支持网络\n运行级别3：完全的多用户状态(有NFS)，登陆后进入控制台命令行模式\n运行级别4：系统未使用，保留\n运行级别5：X11控制台，登陆后进入图形GUI模式\n运行级别6：系统正常关闭并重启，默认运行级别不能设为6，否则不能正常启动\n![](../../BaiduNetdiskDownload/尚硅谷运维 linux shell/笔记/3第三章 常见Linux命令/image/service1_gFcZwwFe4P.png)\n3.文件目录类命令 pwd(print working directory ) 打印当前工作目录的绝对路径\n基本语法\npwd （功能描述：显示当前工作目录的绝对路径） 案例实操\n显示当前工作目录的绝对路径 1 2 [root@centos100 ~]# pwd /root ls(list) 列出目录内容\n基本语法\nls [选项] [目录或是文件] 选项说明\n选项 功能 -a 全部的文件，连同隐藏档( 开头为 . 的文件) 一起列出来(常用) -l 长数据串列出，包含文件的属性与权限等等数据；(常用) 显示说明\n每行列出的信息依次是： 文件类型与权限 链接数 文件属主 文件属组 文件大小用byte来表示 建立或最近修改的时间 名字 实操案例\n查看当前目录的所有内容信息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 [root@centos100 ~]# ls -al 总用量 80 dr-xr-x---. 15 root root 4096 11月 7 19:08 . dr-xr-xr-x. 17 root root 224 11月 3 20:18 .. -rw-------. 1 root root 1533 11月 3 20:19 anaconda-ks.cfg -rw-------. 1 root root 1996 11月 7 18:54 .bash_history -rw-r--r--. 1 root root 18 12月 29 2013 .bash_logout -rw-r--r--. 1 root root 176 12月 29 2013 .bash_profile -rw-r--r--. 1 root root 176 12月 29 2013 .bashrc drwx------. 15 root root 4096 11月 6 14:03 .cache drwxr-xr-x. 16 root root 4096 11月 6 17:00 .config -rw-r--r--. 1 root root 100 12月 29 2013 .cshrc drwx------. 3 root root 25 11月 3 20:25 .dbus -rw-------. 1 root root 16 11月 3 20:28 .esd_auth -rw-------. 1 root root 1550 11月 7 19:04 .ICEauthority -rw-r--r--. 1 root root 1581 11月 3 20:25 initial-setup-ks.cfg drwx------. 3 root root 19 11月 3 20:28 .local drwx------. 5 root root 66 11月 3 20:29 .mozilla -rw-r--r--. 1 root root 6939 11月 6 15:35 smartd1.conf -rw-r--r--. 1 root root 6792 11月 6 15:48 smartd.conf -rw-r--r--. 1 root root 129 12月 29 2013 .tcshrc -rw-------. 1 root root 4518 11月 7 19:08 .viminfo -rw-------. 1 root root 165 11月 7 18:55 .Xauthority cd(Change Directory)切换路径\n基本语法\ncd [参数] 参数说明\n参数 功能 cd 绝对路径 切换路径 cd 相对路径 切换路径 cd ~或者cd 回到自己的家目录 cd - 回到上一次所在目录 cd .. 回到当前目录的上一级目录 cd -P 跳转到实际物理路径，而非快捷方式路径 cd / 回到系统根目录 实操案例\n使用绝对路径切换到root目录 1 [root@centos100 ~]# cd /root/ 使用相对路径切换到“公共的”目录 1 [root@centos100 ~]# cd 公共的/ 表示回到自己的家目录，亦即是 /root 这个目录 1 [root@centos100 公共的]# cd ~ cd- 回到上一次所在目录 1 [root@centos100 ~]# cd - 表示回到当前目录的上一级目录，亦即是 “/root/公共的”的上一级目录的意思； 1 [root@centos100 公共的]# cd .. mkdir(Make directory) 建立目录\n基本语法\nmkdir [选项] 要创建的目录 选项说明\n选项 功能 -p 创建多层目录 实操案例\n创建一个目录 1 2 3 [root@centos100 ~]# mkdir xiyou [root@centos100 ~]# mkdir xiyou/yaojing 创建一个多级目录 1 [root@centos100 ~]# mkdir -p xiyou/qujing/meihouwang rmdir(Remove directory) 删除目录\n基本语法\nrmdir 要删除的空目录 实操案例\n删除一个空的文件夹 1 [root@centos100 ~]# rmdir xiyou/qujing/meihouwang touch 创建空文件\n基本语法\ntouch 文件名称 实操案例\n1 [root@centos100 ~]# touch xiyou/qujing/sunwukong.txt cp 复制文件或目录\n基本语法\ncp [选项] source dest （功能描述：复制source文件到dest） 选项说明\n选项 功能 -r 递归复制整个文件夹 参数说明\n参数 功能 source 源文件 dest 目标文件 实操案例\n复制文件 1 [root@centos100 ~]# cp xiyou/qujing/suwukong.txt xiyou/mingjie/ 递归复制整个文件夹 1 [root@centos100 ~]# cp -r a/b/ ./ 注意事项\n强制覆盖不提示的方法：\\cp\nrm移除文件或者目录\n基本语法\nrm [选项] deleteFile 选项说明\n选项 功能 -r 递归删除目录所有内容 -f 强制删除,不提示用户进行确认 -v 显示指令的详细执行过程 实操案例\n删除目录中的内容 1 [root@centos100 ~]# rm xiyou/mingjie/sunwukong.txt 递归删除目录中所有内容 1 [root@centos100 ~]# rm -rf qujing/ mv移动文件与目录或重命名\n基本语法\n重命名 1 mv oldNameFile newNameFile 移动文件 1 mv /temp/movefile /targetFolder 实操案例\n重命名 1 [root@centos100 ~]# mv xiyou/qujing/suwukong.txt xiyou/qujing/houge.txt 移动文件 1 [root@centos100 ~]# mv xiyou/qujing/houge.txt ./ cat查看文件内容\n基本语法\ncat [选项] 文件 查看文件内容,从第一行开始显示 选项说明\n选项 功能描述 - n 显示所有行的行号,包括空行 经验技巧\n1 一般查看比较小的文件,一屏幕能显示全的 实操案例\n查看文件内容并显示行号 1 [atguigu@centos100 ~]$ cat -n houge.txt more 文件分屏查看器\n基本语法\n1 more 要查看的文件 1 more指令是一个基于VI编辑器的文本过滤器，它以全屏幕的方式按页显示文本文件的内容。more指令中内置了若干快捷键，详见操作说明。 操作说明\n操作 功能说明 空白键 (space) 代表向下翻一页； Enter 代表向下翻『一行』； q 代表立刻离开 more ，不再显示该文件内容。 Ctrl+F 向下滚动一屏 Ctrl+B 返回上一屏 = 输出当前行的行号 :f 输出文件名和当前行的行号 实操案例\n（1）采用more查看文件 1 [root@centos100 ~]# more smartd.conf less 分屏显示文件内容\n基本语法\n1 2 3 less指令用来分屏查看文件内容，它的功能与more指令类似，但是比more指令更加强大，支持各种显示终端。less指令在显示文件内容时，并不是一次将整个文件加载之后才显示，而是根据显示需要加载内容，对于显示大型文件具有较高的效率。 less 要查看的文件 操作说明\n操作 功能说明 空白键 向下翻动一页； [pagedown] 向下翻动一页 [pageup] 向上翻动一页； /字串 向下搜寻『字串』的功能；n：向下查找；N：向上查找； ?字串 向上搜寻『字串』的功能；n：向上查找；N：向下查找； q 离开 less 这个程序； 实操案例\n（1）采用less查看文件 1 [root@centos100 ~]# less smartd.conf head显示文件头部内容\n基本语法\n1 2 3 4 head用于显示文件的开头部分内容，默认情况下head指令显示文件的前10行内容。 head 文件 （功能描述：查看文件头10行内容） head -n 5 文件 （功能描述：查看文件头5行内容，5可以是任意行数） 选项说明\n选项 功能 -n \u0026lt;行数\u0026gt; 指定显示头部内容的行数 实操案例\n（1）查看文件的头2行 1 [root@centos100 ~]# head -n 2 smartd.conf tail 输出文件尾部内容\n基本语法\n1 2 3 4 tail用于输出文件中尾部的内容，默认情况下tail指令显示文件的后10行内容。 （1）tail 文件 （功能描述：查看文件后10行内容） （2）tail -n 5 文件 （功能描述：查看文件后5行内容，5可以是任意行数） （3）tail -f 文件 （功能描述：实时追踪该文档的所有更新） 选项说明\n选项 功能 -n\u0026lt;行数\u0026gt; 输出文件尾部n行内容 -f 显示文件最新追加的内容，监视文件变化 实操案例\n（1）查看文件头1行内容 1 [root@centos100 ~]# tail -n 1 smartd.conf （2）实时追踪该档的所有更新 1 [root@centos100 ~]# tail -f houge.txt echo 打印信息\n基本语法\n1 2 3 echo输出内容到控制台 System.out.println(); echo [选项] [输出内容] 选项说明\n选项 功能 -e 支持反斜线控制的字符转换 控制字符 作用 \u0026mdash;- \u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; \\\\ 输出\\本身 \\n 换行符 \\t 制表符，也就是Tab键 实操案例\n(1) 打印文字信息 1 2 3 4 [atguigu@centos100 ~]$ echo \u0026#34;hello\\tworld\u0026#34; hello\\tworld [atguigu@centos100 ~]$ echo -e \u0026#34;hello\\tworld\u0026#34; hello world (2) 打印环境变量 1 [atguigu@centos100 ~]$ echo $PATH \u0026gt; 覆盖和\u0026raquo;追加\n基本语法\n1 2 3 4 （1）ll \u0026gt;文件 （功能描述：列表的内容写入文件a.txt中（**覆盖写**）） （2）ll \u0026gt;\u0026gt;文件 （功能描述：列表的内容**追加**到文件aa.txt的末尾） （3）cat 文件1 \u0026gt; 文件2 （功能描述：将文件1的内容覆盖到文件2） （4）echo “内容” \u0026gt;\u0026gt; 文件 实操案例\n（1）将ls查看信息写入到文件中 1 [root@centos100 ~]# ls -l\u0026gt;houge.txt （2）将ls查看信息追加到文件中 1 [root@centos100 ~]# ls -l\u0026gt;\u0026gt;houge.txt （3）采用echo将hello单词追加到文件中 1 [root@centos100 ~]# echo hello\u0026gt;\u0026gt;houge.txt ln创建链接和软连接\n基本语法\n1 2 3 链接表示目标资源的另外的访问方式,表示一种路径 软链接也称为符号链接，类似于windows里的快捷方式，有自己的数据块，主要存放了链接其他文件的路径。 ln [-s] [原文件或目录] [链接名] （功能描述：给原文件创建一个链接） 选项说明\n选项 功能 -s 创建的链接为 软连接 经验技巧\n1 2 删除软链接： rm -rf 软链接名，而不是rm -rf 软链接名/ 查询：通过ll就可以查看，列表属性第1位是l，尾部会有位置指向。 实操案例\n（1）创建软连接 1 2 3 4 [root@centos100 ~]# mv houge.txt xiyou/qujing/ [root@centos100 ~]# ln -s /root/xiyou/qujing/houge.txt /root/houzi [root@centos100 ~]# ll lrwxrwxrwx. 1 root root 20 6月 17 12:56 houzi -\u0026gt; xiyou/qujing/houge.txt （2）删除软连接 1 [root@centos100 ~]# rm -rf houzi （3）进入软连接实际物理路径 1 2 [root@centos100 ~]# ln -s xiyou/qujing/ ./qujing [root@centos100 ~]# cd -P qujing/ history查看历史命令\n基本语法\n1 history （功能描述：查看已经执行过历史命令） 实操案例\n（1）查看已经执行过的历史命令 1 [root@centos100 test1]# history (2) /root/.bash_history文件中也是历史命令 1 less /root/.bash_history 4.VI和VIM编辑器 学习目标\n1 了解什么 是VI和VIM 编辑器\n2 熟练VIM编辑器一般模式的常见操作\n3 熟练VIM编辑器编辑模式的的进入和退出方式\n4 熟练VIM编辑器命令模式的常见命令\n4.1 什么是VI和VIM编辑器 vi是Unix和类Unix操作系统中出现的通用的文本编辑器。vim是从vi发展出来的一个性能更强大的文本编辑器,可以主动的以字体颜色辨别语法的正确性,方便程序设计,vim和vi编辑器完全兼容。使用：vi xxx文件 或者vim xxx文件,简单来说,就是用来编辑文件的一个工具,类似于我们再Windows上的一些文本编辑工具,只不过,这里是命令行形式的,不是图形用户界面形式的.接下来我们就准备一个文件,使用VIM对文件进行修改\n复制一个系统的配置文件到Root目录下，用以联系vim命令\n1 2 [root@192 ~]# cp /etc/smartmontools/smartd.conf /root [root@192 ~]# cd /root/ 4.2 VIM的一般模式 默认模式,在这个模式中， 你可以使用『上下左右』按键来移动光标，你可以使用『删除字符』或『删除整行』来处理档案内容， 也可以使用『复制、贴上』来处理你的文件数据。\n1.删除和复制操作\n2.光标移动操作\n4.3 VIM的编辑模式 在一般模式中可以进行删除、复制、贴上等等的动作，但是却无法编辑文件内容的！要等到你按下『i, I, o, O, a, A, r, R』等任何一个字母之后才会进入编辑模式。注意了！通常在 Linux 中，按下这些按键时，在画面的左下方会出现『INSERT 或 REPLACE 』的字样，此时才可以进行编辑。而如果要回到一般模式时， 则必须要按下『Esc』这个按键即可退出编辑模式。\n4.4VIM的命令模式 可以进行存盘、退出、显示行号、搜索、批量替换等操作。要在一般模式下输入\u0026quot; / \u0026ldquo;或 \u0026rdquo; : \u0026ldquo; 或者\u0026rdquo;?\u0026ldquo;可进入命令模式,当命令执行前按esc或者命令执行完毕,自动回到一般模式\n![](../../BaiduNetdiskDownload/尚硅谷运维 linux shell/笔记/3第三章 常见Linux命令/image/vim4_rT-Bi1oF_I.png)\n![](../../BaiduNetdiskDownload/尚硅谷运维 linux shell/笔记/3第三章 常见Linux命令/image/vim5_Oecz0qPFT2.png)\n如果非正常退出,如使用ctrl+z退出,再次编辑会提示交换文件\u0026rdquo;. .swp\u0026quot;,文件存在,并给出相应的处理方式选项,如果不删除交换文件,每次编辑都会提示,这时可以删除交换文件,通过命令: rm -rf \u0026lsquo;.swp\u0026rsquo; 即可\n![](../../BaiduNetdiskDownload/尚硅谷运维 linux shell/笔记/3第三章 常见Linux命令/image/vim7_ue_qTXxwmG.png)\n![](../../BaiduNetdiskDownload/尚硅谷运维 linux shell/笔记/3第三章 常见Linux命令/image/vim6_YNzby63b4C.png)\n4.5时间日期类命令 date显示当前时间\n基本语法\n1 2 3 4 5 （1）date （功能描述：显示当前时间） ​（2）date +%Y （功能描述：显示当前年份） ​（3）date +%m （功能描述：显示当前月份） ​（4）date +%d （功能描述：显示当前是哪一天） ​（5）date \u0026#34;+%Y-%m-%d %H:%M:%S\u0026#34; （功能描述：显示年月日时分秒） 实操案例\n（1）显示当前时间信息 1 2 [root@centos100 ~]# date 2017年 06月 19日 星期一 20:53:30 CST （2）显示当前时间年月日 1 2 [root@centos100 ~]# date +%Y%m%d 20170619 （3）显示当前时间年月日时分秒 1 2 [root@centos100 ~]# date \u0026#34;+%Y-%m-%d %H:%M:%S\u0026#34; 2017-06-19 20:54:58 date显示非当前时间\n基本语法\n1 2 （1）date -d \u0026#39;1 days ago\u0026#39; （功能描述：显示前一天时间） （2）date -d \u0026#39;-1 days ago\u0026#39; （功能描述：显示明天时间） 实操案例\n（1）显示前一天 1 2 [root@centos100 ~]# date -d \u0026#39;1 days ago\u0026#39; 2017年 06月 18日 星期日 21:07:22 CST （2）显示明天时间 1 2 [root@centos100 ~]#date -d \u0026#39;-1 days ago\u0026#39; 2017年 06月 20日 星期日 21:07:22 CST date设置系统时间\n基本语法\n1 date -s 字符串时间 实操案例\n（1）设置系统当前时间 1 [root@centos100 ~]# date -s \u0026#34;2017-06-19 20:52:18\u0026#34; 4.6用户管理命令 useradd添加新用户\n基本语法\n1 2 useradd 用户名 （功能描述：添加新用户） ​useradd -g 组名 用户名 （功能描述：添加新用户到某个组） 实操案例\n（1）添加一个用户 1 2 [root@centos100 ~]# useradd tangseng [root@centos100 ~]#ll /home/ passwd设置用户密码\n基本语法\n1 passwd 用户名 （功能描述：设置用户密码） 实操案例\n（1）设置用户的密码 1 [root@centos100 ~]# passwd tangseng id查看用户是否存在\n基本语法\n1 id 用户名 实操案例\n（1）查看用户是否存在 1 [root@centos100 ~]#id tangseng cat /etc/passwd 查看创建的所有用户\n实操案例\n(1) 查看创建的所有用户 1 [root@centos100 ~]# cat /etc/passwd su(switch user )切换用户\n基本语法\n1 2 su 用户名称 （功能描述：切换用户，只能获得用户的执行权限，不能获得环境变量） su - 用户名称 （功能描述：切换到用户并获得该用户的环境变量及执行权限） 实操案例\n（1）切换用户 1 2 3 4 5 6 7 [root@centos100 ~]#su tangseng [root@centos100 ~]#echo $PATH /usr/lib64/qt-3.3/bin:/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/bin [root@centos100 ~]#exit [root@centos100 ~]#su - tangseng [root@centos100 ~]#echo $PATH /usr/lib64/qt-3.3/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/tangseng/bin (2) exit 回退到上一个用户 1 [root@centos100 ~]#exit userdel删除用户\n基本语法\n1 2 （1）userdel 用户名 （功能描述：删除用户但保存用户主目录） ​（2）userdel -r 用户名 （功能描述：用户和用户主目录，都删除） 选项说明\n选项 功能 -r 删除用户的同时，删除与用户相关的所有文件。 实操案例\n（1）删除用户但保存用户主目录 1 2 [root@centos100 ~]#userdel tangseng [root@centos100 ~]#ll /home/ （2）删除用户和用户主目录，都删除 1 2 3 4 [root@centos100 ~]#useradd zhubajie [root@centos100 ~]#ll /home/ [root@centos100 ~]#userdel -r zhubajie [root@centos100 ~]#ll /home/ who 查看登录用户信息\n基本语法\n1 2 （1）whoami （功能描述：显示自身用户名称） ​（2）who am i （功能描述：显示登录用户的用户名） 案例实操\n（1）显示自身用户名称 1 [root@centos100 opt]# whoami （2）显示登录用户的用户名 1 [root@centos100 opt]# who am i sudo 设置普通用户具有root权限\n基本语法\n1 sudo 命令 实操案例\n(1) 添加atguigu用户，并对其设置密码 1 2 [root@centos100 ~]#useradd atguigu [root@centos100 ~]#passwd atguigu (2)修改配置文件 1 [root@centos100 ~]#vi /etc/sudoers 1 2 3 4 5 修改 /etc/sudoers 文件，找到下面一行(101行)，在root下面添加一行，如下 \\## Allow root to run any commands anywhere root ALL=(ALL) ALL atguigu ALL=(ALL) ALL 1 2 3 4 5 6 7 或者配置成采用sudo命令时，不需要输入密码 \\## Allow root to run any commands anywhere root ALL=(ALL) ALL atguigu ALL=(ALL) NOPASSWD:ALL 修改完毕，现在可以用atguigu帐号登录，然后用命令 sudo ，即可获得root权限进行操作。 (3)用普通用户在/opt目录下创建一个文件夹 1 [atguigu@centos100 opt]$ sudo mkdir module 4.7组管理类命令 每个用户都有一个用户组，系统可以对一个用户组中的所有用户进行集中管理。不同Linux 系统对用户组的规定有所不同，如Linux下的用户属于与它同名的用户组，这个用户组在创建用户时同时创建。用户组的管理涉及用户组的添加、删除和修改。组的增加、删除和修改实际上就是对/etc/group文件的更新。\ngroupadd新增组\n基本语法\n1 groupadd 组名 实操案例\n（1）添加一个xitianqujing组 1 [root@centos100 opt]#groupadd xitianqujing groupdel删除组\n基本语法\n1 groupdel 组名 实操案例\n（1）删除xitianqujing组 1 [root@centos100 opt]# groupdel xitianqujing 查看创建了那些组\n实操案例\n1 [root@centos100 atguigu]# cat /etc/group usermod修改用户\n基本语法\n1 usermod -g 用户组 用户名 选项说明\n选项 功能 -g 修改用户的初始登录组，给定的组必须存在 实操案例\n（1）将用户加入到用户组 1 [root@centos100 opt]#usermod -g xitianqujing tangseng 4.8文件权限类命令 文件属性信息解读\n文件类型和权限的表示\n![](../../BaiduNetdiskDownload/尚硅谷运维 linux shell/笔记/3第三章 常见Linux命令/image/q1_nv6bwk6rOu.png)\n（1） 0首位表示类型 在Linux中第一个字符代表这个文件是目录、文件或链接文件等等\n符号 对应文件类型 - 代表文件 （2）第1-3位确定属主（该文件的所有者）拥有该文件的权限。U →User\n（3）第4-6位确定属组（所有者的同组用户）拥有该文件的权限，G→Group\n（4）第7-9位确定其他用户拥有该文件的权限 , O →Other\nrwx作用到目录和文件的不同含义\n作用到文件 1 2 3 [ r ]代表可读(read): 可以读取，查看 ​[ w ]代表可写(write): 可以修改，但是不能删除该文件，对该文件所在的目录有写权限，才能删除. ​[ x ]代表可执行(execute):可以被系统执行 作用到目录 1 2 3 [ r ]代表可读(read): 可以读取，ls查看目录内容 ​[ w ]代表可写(write): 可以修改，目录内创建+删除+重命名目录 [ x ]代表可执行(execute):可以进入该目录 实操案例\n(1)查看文件权限信息 1 2 3 4 5 [root@centos100 ~]# ll 总用量 104 -rw-------. 1 root root 1248 1月 8 17:36 anaconda-ks.cfg drwxr-xr-x. 2 root root 4096 1月 12 14:02 qujing lrwxrwxrwx. 1 root root 20 1月 12 14:32 houzi -\u0026gt; xiyou/qujing/houge.tx (2)文件属性介绍 1 ls -l ![](../../BaiduNetdiskDownload/尚硅谷运维 linux shell/笔记/3第三章 常见Linux命令/image/q2_pSl919toNE.png)\n** 如果查看到是文件：链接数指的是硬链接个数** ** 如果查看的是文件夹：链接数指的是子文件夹个数 **​\nchmod改变文件权限\n基本语法\n![](../../BaiduNetdiskDownload/尚硅谷运维 linux shell/笔记/3第三章 常见Linux命令/image/q3_8nnL2OIZNs.png)\n第一种方式变更权限 1 chmod [{ugoa}{+-=}{rwx}] 文件或目录 第二种方式变更权限 1 chmod [mode=421 ] [文件或目录] 经验技巧\n1 2 3 u:所有者 g:所有组 o:其他人 a:所有人(u、g、o的总和) ​r=4 w=2 x=1 rwx=4+2+1=7 实操案例\n（1）修改文件使其所属主用户具有执行权限 1 2 [root@centos100 ~]# cp xiyou/qujing/houge.txt ./ [root@centos100 ~]# chmod u+x houge.txt （2）修改文件使其所属组用户具有执行权限 1 [root@centos100 ~]# chmod g+x houge.txt （3）修改文件所属主用户执行权限,并使其他用户具有执行权限 1 [root@centos100 ~]# chmod u-x,o+x houge.txt （4）采用数字的方式，设置文件所有者、所属组、其他用户都具有可读可写可执行权限。 1 [root@centos100 ~]# chmod 777 houge.txt （5）修改整个文件夹里面的所有文件的所有者、所属组、其他用户都具有可读写执行权限。 1 [root@centos100 ~]# chmod -R 777 xiyou/ chown 改变所有者\n基本语法\n1 chown [选项] [最终用户] [文件或目录] （功能描述：改变文件或者目录的所有者） 选项说明\n选项 功能 -R 递归操作 实操案例\n（1）修改文件所有者 1 2 3 [root@centos100 ~]# chown atguigu houge.txt [root@centos100 ~]# ls -al -rwxrwxrwx. 1 atguigu root 551 5月 23 13:02 houge.txt （2）递归改变文件所有者和所有组 1 2 3 4 5 [root@centos100 xiyou]# ll drwxrwxrwx. 2 root root 4096 9月 3 21:20 xiyou [root@centos100 xiyou]# chown -R atguigu:atguigu xiyou/ [root@centos100 xiyou]# ll drwxrwxrwx. 2 atguigu atguigu 4096 9月 3 21:20 xiyou chgrp改变所属组\n基本语法\n1 chgrp [最终用户组] [文件或目录] （功能描述：改变文件或者目录的所属组） 实操案例\n（1）修改文件的所属组 1 2 3 [root@centos100 ~]# chgrp root houge.txt [root@centos100 ~]# ls -al -rwxrwxrwx. 1 atguigu root 551 5月 23 13:02 houge.txt 实战演练\n1 2 3 4 1.在opt目录下创建java目录，用于安装java框架。所有者为java部门的领导张总，所属组为java部门，张总有全部的权限，部门其他开发有读和执行的权限，其他人只有读的权限。 2.在opt目录下创建bigdata目录，用于大数据框架的安装。所有者为大数据部门的王总，所属组为bigdata部门，王总有全部的权限，部门其他人有读写执行权限，其他人没有权限。 3.使用root用户在opt目录下创建mysql文件夹，用于安装mysql，赋予其他用户读的权限。 4.使用root用户在opt目录下创建redis文件夹，用于安装使用redis，赋予其他用户读和执行的权限。 4.9搜索查找类命令 find 查找文件或者目录\n基本语法\n1 2 find指令将从指定目录向下递归地遍历其各个子目录，将满足条件的文件显示在终端。 find [搜索范围] [选项] 选项说明\n选项 功能 -name\u0026lt;查询方式\u0026gt; 按照指定的文件名查找模式查找文件 -user\u0026lt;用户名\u0026gt; 查找属于指定用户名所有文件 -size\u0026lt;文件大小\u0026gt; 按照指定的文件大小查找文件。 实操案例\n（1）按文件名：根据名称查找/目录下的filename.txt文件。 1 [root@centos100 ~]# find xiyou/ -name “*.txt” （2）按拥有者：查找/opt目录下，用户名称为-user的文件 1 [root@centos100 ~]# find opt/ -user atguigu （3）按文件大小：在/home目录下查找大于200m的文件（+n 大于 -n小于 n等于） 1 [root@centos100 ~]find /home -size +204800 grep 过滤查找及“|”管道符\n基本语法\n1 2 管道符，“|”，表示将前一个命令的处理结果输出传递给后面的命令处理 grep 选项 查找内容 源文件 选项说明\n选项 功能 -n 显示匹配及行号 实操案例\n（1）查找某文件在第几行 1 [root@centos100 ~]# ls | grep -n test 4.10压缩和解压缩命令 gzip/gunzip 压缩\n基本语法\n1 2 gzip 文件 （功能描述：压缩文件，只能将文件压缩为*.gz文件） gunzip 文件.gz （功能描述：解压缩文件命令） 经验技巧\n1 2 （1）只能压缩文件,不能压缩目录 （2）不保留原来的文件 实操案例\n（1）gzip压缩 1 2 3 4 5 [root@centos100 ~]# ls houge.txt [root@centos100 ~]# gzip houge.txt [root@centos100 ~]# ls houge.txt.gz （2）gunzip解压缩文件 1 2 3 [root@centos100 ~]# gunzip houge.txt.gz [root@centos100 ~]# ls houge.txt zip/unzip压缩\n基本语法\n1 2 zip [选项] XXX.zip 将要压缩的内容 （功能描述：压缩文件和目录的命令） ​unzip [选项] XXX.zip （功能描述：解压缩文件） 选项说明\nzip选项 功能 -r 压缩目录 unzip选项 功能 \u0026mdash;\u0026mdash;- \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; -d\u0026lt;目录\u0026gt; 指定解压后文件的存放目录 经验技巧\n1 zip 压缩命令在window/linux都通用，**可以压缩目录且保留源文件**。 实操案例\n（1）压缩文件 1 2 3 4 5 6 [root@centos100 opt]# touch bailongma.txt [root@centos100 ~]# zip houma.zip houge.txt bailongma.txt adding: houge.txt (stored 0%) adding: bailongma.txt (stored 0%) [root@centos100 opt]# ls houge.txt bailongma.txt houma.zip （2）解压文件 1 2 3 4 5 6 [root@centos100 ~]# unzip houma.zip Archive: houma.zip extracting: houge.txt extracting: bailongma.txt [root@centos100 ~]# ls houge.txt bailongma.txt houma.zip （3）解压到指定目录-d 1 2 [root@centos100 ~]# unzip houma.zip -d /opt [root@centos100 ~]# ls /opt/ tar打包\n基本语法\n1 tar [选项] XXX.tar.gz 将要打包进去的内容 （功能描述：打包目录，压缩后的文件格式.tar.gz） 选项说明\n选项 功能 -z 打包同时压缩 -c 产生.tar打包文件 -v 显示详细信息 -f 指定压缩后的文件名 -x 解包.tar文件 实操案例\n（1）压缩多个文件 1 2 3 4 5 [root@centos100 opt]# tar -zcvf houma.tar.gz houge.txt bailongma.txt houge.txt bailongma.txt [root@centos100 opt]# ls houma.tar.gz houge.txt bailongma.txt （2）压缩目录 1 2 3 4 5 [root@centos100 ~]# tar -zcvf xiyou.tar.gz xiyou/ xiyou/ xiyou/mingjie/ xiyou/qujing/ xiyou/qujing/houge.txt （3）解压到当前目录 1 [root@centos100 ~]# tar -zxvf houma.tar.gz （4）解压到指定目录 1 2 [root@centos100 ~]# tar -zxvf xiyou.tar.gz -C /opt [root@centos100 ~]# ll /opt/ 实战演练\n1 2 3 使用提供的flume安装包tar.gz完成解压缩,放置到/opt/module目录下,之后在flume的根目录运行flume程序, 运行命令如下: bin/flume-ng agent -c conf/ -n a1 -f job/test.conf 之后查找flume的日志文件flume.log 4.11磁盘分区类命令 df (disk free 空余硬盘)查看磁盘空间使用情况 基本语法\n1 df 选项 （功能描述：列出文件系统的整体磁盘使用量，检查文件系统的磁盘空间占用情况） 选项说明\n选项 说明 -h 以人们较易阅读的 GBytes, MBytes, KBytes 等格式自行显示； 实操案例\n（1）查看磁盘使用情况 1 2 3 4 [root@centos100 ~]# df -h Filesystem Size Used Avail Use% Mounted on /dev/sda2 15G 3.5G 11G 26% / tmpfs 939M 224K 939M 1% /dev/shm fdisk 查看分区\n基本语法\n1 fdisk -l （功能描述：查看磁盘分区详情） 选项说明\n选项 功能 -l 显示所有硬盘的分区列表 经验技巧\n该命令必须在root用户下才能使用 功能说明\n（1）Linux分区 1 2 3 4 5 6 7 Device：分区序列 ​Boot：引导 ​Start：从X磁柱开始 ​End：到Y磁柱结束 ​Blocks：容量 ​Id：分区类型ID ​System：分区类型 1 2 - （2）windows分区 ![](image/f1_DJ7eqlCV4z.png) 实操案例\n（1）查看系统分区情况 1 2 3 4 5 6 7 8 9 10 11 12 13 [root@centos100 /]# fdisk -l Disk /dev/sda: 21.5 GB, 21474836480 bytes 255 heads, 63 sectors/track, 2610 cylinders Units = cylinders of 16065 * 512 = 8225280 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk identifier: 0x0005e654 Device Boot Start End Blocks Id System /dev/sda1 * 1 26 204800 83 Linux Partition 1 does not end on cylinder boundary. /dev/sda2 26 1332 10485760 83 Linux /dev/sda3 1332 1593 2097152 82 Linux swap / Solaris mount/umount 挂载/卸载\n什么是挂载卸载\n1 2 对于Linux用户来讲，不论有几个分区，分别分给哪一个目录使用，它总归就是一个根目录、一个独立且唯一的文件结构。 Linux中每个分区都是用来组成整个文件系统的一部分，它在用一种叫做“挂载”的处理方法，它整个文件系统中包含了一整套的文件和目录，并将一个分区和一个目录联系起来，要载入的那个分区将使它的存储空间在这个目录下获得。 (1)挂载前准备（必须要有光盘或者已经连接镜像文件） ![](../../BaiduNetdiskDownload/尚硅谷运维 linux shell/笔记/3第三章 常见Linux命令/image/g1_qpakRoM7Kj.png) 基本语法\n1 2 mount [-t vfstype] [-o options] device dir （功能描述：挂载设备） umount 设备文件名或挂载点 （功能描述：卸载设备） 参数说明\n参数 功能 -t vfstype 指定文件系统的类型，通常不必指定。mount 会自动选择正确的类型。常用类型有： 1)光盘或光盘镜像：iso9660 2)DOS fat16文件系统：msdos 3) Windows 9x fat32文件系统：vfat 4) Windows NT ntfs文件系统：ntfs 5)Mount Windows文件网络共享：smbfs 6) UNIX (LINUX) 文件网络共享：nfs -o options 主要用来描述设备或档案的挂接方式。常用的参数有： loop：用来把一个文件当成硬盘分区挂接上系统 ro：采用只读方式挂接设备 rw：采用读写方式挂接设备 iocharset：指定访问文件系统所用字符集 device 要挂接(mount)的设备 dir 设备在系统上的挂接点(mount point) 实操案例\n（1）挂载光盘镜像文件 1 2 3 [root@centos100 ~]# mkdir /mnt/cdrom/ (建立挂载点) [root@centos100 ~]# mount -t iso9660 /dev/cdrom /mnt/cdrom/ (设备/dev/cdrom挂载到/mnt/cdrom中) [root@centos100 ~]# ll /mnt/cdrom/ （2）卸载光盘镜像文件 1 [root@centos100 ~]# umount /mnt/cdrom （3）设置开机自动挂载 1 [root@centos100 ~]# vi /etc/fstab 添加红框中内容，保存退出\n![](../../BaiduNetdiskDownload/尚硅谷运维 linux shell/笔记/3第三章 常见Linux命令/image/g2_yrfo4OrykJ.png)\n4.12进程线程类命令 进程是正在执行的一个程序或命令，每一个进程都是一个运行的实体，都有自己的地址空间，并占用一定的系统资源。\nps (process status 进程状态)查看当前系统进程状态\n基本语法\n1 2 ps -aux | grep xxx （功能描述：查看系统中所有进程） ​ps -ef | grep xxx （功能描述：可以查看子父进程之间的关系） 选项说明\n选项 功能 -a 选择所有进程 -u 显示所有用户的所有进程 -x 显示没有终端的进程 功能说明\n（1）ps -aux显示信息说明 1 2 3 4 5 6 7 8 9 10 11 USER：该进程是由哪个用户产生的 PID：进程的ID号 ​%CPU：该进程占用CPU资源的百分比，占用越高，进程越耗费资源； ​%MEM：该进程占用物理内存的百分比，占用越高，进程越耗费资源； ​VSZ：该进程占用虚拟内存的大小，单位KB； ​RSS：该进程占用实际物理内存的大小，单位KB； ​TTY：该进程是在哪个终端中运行的。其中tty1-tty7代表本地控制台终端，tty1-tty6是本地的字符界面终端， tty7是图形终端。pts/0-255代表虚拟终端。 ​STAT：进程状态。常见的状态有：R：运行、S：睡眠、T：停止状态、s：包含子进程、+：位于后台 ​START：该进程的启动时间 ​TIME：该进程占用CPU的运算时间，注意不是系统时间 ​COMMAND：产生此进程的命令名 （2）ps -ef显示信息说明 1 2 3 4 5 6 7 8 UID：用户ID ​PID：进程ID ​PPID：父进程ID ​C：CPU用于计算执行优先级的因子。数值越大，表明进程是CPU密集型运算，执行优先级会降低；数值越小，表明进程是I/O密集型运算，执行优先级会提高 ​STIME：进程启动的时间 ​TTY：完整的终端名称 ​TIME：CPU时间 ​CMD：启动进程所用的命令和参数 经验技巧\n1 2 如果想查看进程的**CPU**占用率和内存占用率，可以使用aux; ​如果想查看**进程的父进程ID**可以使用ef; 实操案例\n1 [root@centos100 datas]# ps -aux ![](../../BaiduNetdiskDownload/尚硅谷运维 linux shell/笔记/3第三章 常见Linux命令/image/p1_GgAHP9zqWq.png)\n1 [root@centos100 datas]# ps -ef ![](../../BaiduNetdiskDownload/尚硅谷运维 linux shell/笔记/3第三章 常见Linux命令/image/p2_t1GuZfOJOf.png)\nkill终止进程\n基本语法\n1 2 kill [选项] 进程号 （功能描述：通过进程号杀死进程） ​ killall 进程名称 （功能描述：通过进程名称杀死进程，也支持通配符） 选项说明\n选项 功能 -9 表示强迫进程立即停止 实操案例\n（1）杀死浏览器进程 1 [root@centos100 桌面]# kill -9 5102 （2）通过进程名称杀死进程 1 [root@centos100 桌面]# killall firefox 4.13系统定时任务命令 crond服务管理\n重新启动crond服务\n1 [root@centos100 ~]# systemctl restart crond crontab 定时任务设置\n基本语法\n1 crontab [选项] 选项说明\n选项 功能 -e 编辑crontab定时任务 -l 查询crontab任务 -f 删除当前用户所有的crontab任务 参数说明\n（1）进入crontab编辑界面。会打开vim编辑你的工作,通过 \u0026ldquo;* \u0026quot; 定义任务周期。\n1 [root@centos100 ~]# crontab -e 项目 选项 范围 第一个“ *” 一小时当中的第几分钟 0-59 第二个“ *” 一天当中的第几小时 0-23 第三个“ *” 一个月当中的第几天 1-31 第四个“ *” 一年当中的第几月 1-12 第五个“ *” 一周当中的星期几 0-7（0和7都代表星期日） （2）每个星号上可以使用的特殊符号\n特殊符号 含义 * 代表任何时间。比如第一个“ *”就代表一小时中每分钟都执行一次的意思。 , 代表不连续的时间。比如“0 8,12,16 * * * 命令”，就代表在每天的8点0分，12点0分，16点0分都执行一次命令 - 代表连续的时间范围。比如“0 5 * * 1-6命令”，代表在周一到周六的凌晨5点0分执行命令 */n 代表每隔多久执行一次。比如“ */10 命令”，代表每隔10分钟就执行一遍命令 （3）特定时间执行命令\n时间 含义 45 22 * * * 命令 在22点45分执行命令 0 17 * * 1 命令 每周1 的17点0分执行命令 0 5 1,15 * * 命令 每月1号和15号的凌晨5点0分执行命令 40 4 * * 1-5 命令 每周一到周五的凌晨4点40分执行命令 */10 4 * * * 命令 每天的凌晨4点，每隔10分钟执行一次命令 0 0 1,15 * 1 命令(错误案例) 每月1号和15号，每周1的0点0分都会执行命令。 1 注意：星期几和几号最好不要同时出现，因为他们定义的都是天。非常容易让管理员混乱。 实参案例\n（1）每隔1分钟，向/root/bailongma.txt文件中添加一一些内容 1 */1 * * * * /bin/echo ”11” \u0026gt;\u0026gt; /root/bailongma.txt 第三章JAVA开发与大数据shell扩展篇 学习目标\n1 熟练使用RPM查询、安装、卸载软件\n2 熟练使用YUM安装程序\n1.RPM 1 什么是RPM\n1 RPM（RedHat Package Manager），RedHat软件包管理工具，类似windows里面的setup.exed.是Linux这系列操作系统里面的打包安装工具，它虽然是RedHat的标志，但理念是通用的。 2 RPM包的名称格式\n1 2 3 4 5 Apache-1.3.23-11.i386.rpm ​ - “apache” 软件名称 ​ - “1.3.23-11”软件的版本号，主版本和次版本 ​ - “i386”是软件所运行的硬件平台，Intel 32位微处理器的统称 ​ - “rpm”文件扩展名，代表RPM包 RPM查询命令\n基础语法\n1 2 rpm -qa （功能描述：查询所安装的所有rpm软件包） rpm -ql 服务名 (功能描述:查看安装位置) 经验技巧\n1 由于软件包比较多，一般都会采取过滤。rpm -qa | grep rpm软件包 实操案例\n（1）查询firefox软件安装情况 1 2 [root@hadoop101 Packages]# rpm -qa |grep firefox firefox-45.0.1-1.el6.centos.x86_64 RPM卸载命令\n基本语法\n1 2 （1）rpm -e 软件包 （2）rpm -e --nodeps 软件包 选项说明\n选项 功能 -e 卸载软件包 \u0026ndash;nodeps 卸载软件时，不检查依赖。这样的话，那些使用该软件包的软件在此之后可能就不能正常工作了。 实操案例\n（1）卸载firefox软件 1 [root@hadoop101 Packages]# rpm -e firefox RPM安装命令\n基本语法\n1 rpm -ivh RPM 包全名 选项说明\n选项 功能 -i -i=install，安装 -v -v=verbose，显示详细信息 -h -h=hash，进度条 \u0026ndash;nodeps \u0026ndash;nodeps，不检测依赖进度 实操案例\n（1）安装firefox软件 1 2 3 4 5 6 [root@hadoop101 Packages]# pwd /media/CentOS_6.8_Final/Packages [root@hadoop101 Packages]# rpm -ivh firefox-45.0.1-1.el6.centos.x86_64.rpm warning: firefox-45.0.1-1.el6.centos.x86_64.rpm: Header V3 RSA/SHA1 Signature, key ID c105b9de: NOKEY Preparing... ########################################### [100%] 1:firefox ########################################### [100%] 2.YUM 1 什么是YUM\n1 YUM（全称为 Yellow dog Updater, Modified）是一个在Fedora和RedHat以及CentOS中的Shell前端软件包管理器。基于RPM包管理，能够从指定的服务器自动下载RPM包并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软件包，无须繁琐地一次次下载、安装。该功能类似手机中的应用商店,通过网络下载程序包安装即可.功能类似在JAVA中使用MAVEN工具从远程仓库中下载依赖一样,可以自动处理依赖关系.YUM yum安装程序命令\n基本语法\n1 yum [选项] [参数] 选项说明\n选项 功能 -y 对所有提问都回答“yes” 参数说明\n参数 功能 install 安装rpm软件包 update 更新rpm软件包 check-update 检查是否有可用的更新rpm软件包 remove 删除指定的rpm软件包 list 显示软件包信息 clean 清理yum过期的缓存 deplist 显示yum软件包的所有依赖关系 实操案例\n（1）通过yum获取火狐浏览器软件包名称 1 [root@hadoop101 ~]#yum list | grep firefox （2）采用yum方式安装firefox 1 [root@hadoop101 ~]#yum -y install firefox.x86_64 3.实战演练 1 2 3 演练目标： （1）安装jdk （2）安装mysql8.0 3.1安装JDK 第一步 查询系统中自带的JDK\n1 rpm -qa | grep jdk 第二步 卸载系统中自带的JDK\n1 rpm -e --nodeps jdk的rpm软件包的名字 第三步 将jdk.tar.gz上传到/opt目录下\n第四步 解压jdk压缩包\n1 tar -zxvf jdk压缩包名称 第五步 在/etc/profile.d目录下创建my_env.sh文件(系统不建议直接修改/etc/profile)\n1 2 cd /etc/profile.d touch my_env.sh 第六步 在my_env.sh文件中配置JAVA_HOME环境变量\n1 2 3 4 #JAVA_HOME JAVA_HOME=/opt/jdk-1.8.0 PATH=$PATH:$JAVA_HOME/bin export PATH JAVA_HOME 第七步 执行source /etc/profile.d/my_env.sh使环境变量立即生效，如果不生效就重启XShell\n3.2安装 MySQL 第一步 卸载系统中自带的mysql\n1 2 3 4 检查mariadb rpm -qa | grep mariadb 卸载mariadb rpm -e --nodeps mariadb-libs 第二步 下载mysql8安装包\n下载地址https://downloads.mysql.com/archives/community/ 第三步 上传mysql压缩包到/opt 然后解压\n1 tar -xvf mysql-8.0.30-1.el7.x86_64.rpm-bundle.tar 第四步 解压后按照如下顺序进行安装\n1 2 3 4 5 6 rpm -ivh mysql-community-common-8.0.30-1.el7.x86_64.rpm rpm -ivh mysql-community-client-plugins-8.0.30-1.el7.x86_64.rpm rpm -ivh mysql-community-libs-8.0.30-1.el7.x86_64.rpm rpm -ivh mysql-community-client-8.0.30-1.el7.x86_64.rpm rpm -ivh mysql-community-icu-data-files-8.0.30-1.el7.x86_64.rpm rpm -ivh mysql-community-server-8.0.30-1.el7.x86_64.rpm 第五步 对MySQL进行初始化\n1 mysqld --initialize --console 第六步 修改mysql安装目录的所有用户和所属组\n1 chown -R mysql:mysql /var/lib/mysql/ 第七步 查看mysql的临时密码\n1 cat /var/log/mysqld.log | grep localhost 第八步 登录mysql,并修改密码\n1 2 3 4 登录 mysql -uroot -p 修改密码 alter user \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; identified by \u0026#39;root\u0026#39;; 4.大数据开发shell 学习目标\n1 熟悉shell脚本的原理和使用\n2 熟悉shell的编程语法\n1.Shell概述 1）Linux提供的Shell解析器有：\n1 2 3 4 5 6 7 8 9 10 11 12 13 [atguigu@hadoop101 ~]$ cat /etc/shells /bin/sh /bin/bash /sbin/nologin /bin/dash /bin/tcsh /bin/csh 2）bash和sh的关系\n1 2 3 4 5 [atguigu@hadoop101 bin]$ ll | grep bash -rwxr-xr-x. 1 root root 941880 5月 11 2016 bash lrwxrwxrwx. 1 root root 4 5月 27 2017 sh -\u0026gt; bash 3）Centos默认的解析器是bash\n1 2 3 [atguigu@hadoop101 bin]$ echo $SHELL /bin/bash 2.Shell脚本入门 （1）需求：创建一个Shell脚本，输出helloworld\n（2）案例实操：\n1 2 3 4 5 6 7 8 9 10 11 [atguigu@hadoop101 datas]$ touch helloworld.sh [atguigu@hadoop101 datas]$ vim helloworld.sh 在helloworld.sh中输入如下内容 #!/bin/bash echo \u0026#34;helloworld\u0026#34; （3）脚本的常用执行方式\n第一种：采用bash或sh+脚本的相对路径或绝对路径（不用赋予脚本+x权限）\n​ sh+脚本的相对路径\n1 2 3 [atguigu@hadoop101 datas]$ sh helloworld.sh Helloworld ​\tsh+脚本的绝对路径\n1 2 3 [atguigu@hadoop101 datas]$ sh /home/atguigu/datas/helloworld.sh helloworld ​\tbash+脚本的相对路径\n1 2 3 [atguigu@hadoop101 datas]$ bash helloworld.sh Helloworld ​\tbash+脚本的绝对路径\n1 2 3 [atguigu@hadoop101 datas]$ bash /home/atguigu/datas/helloworld.sh Helloworld 第二种：采用输入脚本的绝对路径或相对路径执行脚本（必须具有可执行权限+x）\n（a）首先要赋予helloworld.sh 脚本的+x权限\n1 [atguigu@hadoop101 datas]$ chmod +x helloworld.sh （b）执行脚本\n1 2 3 4 5 6 7 8 9 10 11 相对路径 [atguigu@hadoop101 datas]$ ./helloworld.sh Helloworld 绝对路径 [atguigu@hadoop101 datas]$ /home/atguigu/datas/helloworld.sh Helloworld 注意：第一种执行方法，本质是bash解析器帮你执行脚本，所以脚本本身不需要执行权限。第二种执行方法，本质是脚本需要自己执行，所以需要执行权限。\n【了解】第三种：在脚本的路径前加上“.”或者 source\n（a）有以下脚本\n1 2 3 4 5 6 7 [atguigu@hadoop101 datas]$ cat test.sh #!/bin/bash A=5 echo $A (b) 分别使用sh，bash，./ 和 . 的方式来执行，结果如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 [atguigu@hadoop101 datas]$ bash test.sh [atguigu@hadoop101 datas]$ echo $A [atguigu@hadoop101 datas]$ sh test.sh [atguigu@hadoop101 datas]$ echo $A [atguigu@hadoop101 datas]$ ./test.sh [atguigu@hadoop101 datas]$ echo $A [atguigu@hadoop101 datas]$ . test.sh [atguigu@hadoop101 datas]$ echo $A 5 原因：\n前三种方式都是在当前shell中打开一个子shell来执行脚本内容，当脚本内容结束，则子shell关闭，回到父shell中。\n第四种，也就是使用在脚本路径前加“.”或者 source的方式，可以使脚本内容在当前shell里执行，而无需打开子shell！这也是为什么我们每次要修改完/etc/profile文件以后，需要source一下的原因。\n开子shell与不开子shell的区别就在于，环境变量的继承关系，如在子shell中设置的当前变量，父shell是不可见的。\n3.变量 3.1 系统预定义变量 1）常用系统变量\n$HOME、$PWD、$SHELL、$USER等\n2）案例实操\n（1）查看系统变量的值\n1 2 3 [atguigu@hadoop101 datas]$ echo $HOME /home/atguigu （2）显示当前Shell中所有变量：set\n1 2 3 4 5 6 7 8 9 [atguigu@hadoop101 datas]$ set BASH=/bin/bash BASH_ALIASES=() BASH_ARGC=() BASH_ARGV=() 3**.2** 自定义变量 1）基本语法\n（1）定义变量：变量名=变量值，注意=号前后不能有空格\n（2）撤销变量：unset 变量名\n（3）声明静态变量：readonly变量，注意：不能unset\n2）变量定义规则\n（1）变量名称可以由字母、数字和下划线组成，但是不能以数字开头，环境变量名建议大写。\n（2）等号两侧不能有空格\n（3）在bash中，变量默认类型都是字符串类型，无法直接进行数值运算。\n（4）变量的值如果有空格，需要使用双引号或单引号括起来。\n3）案例实操\n（1）定义变量A\n1 2 3 4 5 [atguigu@hadoop101 datas]$ A=5 [atguigu@hadoop101 datas]$ echo $A 5 （2）给变量A重新赋值\n1 2 3 4 5 [atguigu@hadoop101 datas]$ A=8 [atguigu@hadoop101 datas]$ echo $A 8 （3）撤销变量A\n1 2 3 [atguigu@hadoop101 datas]$ unset A [atguigu@hadoop101 datas]$ echo $A （4）声明静态的变量B=2，不能unset\n1 2 3 4 5 6 7 8 9 [atguigu@hadoop101 datas]$ readonly B=2 [atguigu@hadoop101 datas]$ echo $B 2 [atguigu@hadoop101 datas]$ B=9 -bash: B: readonly variable （5）在bash中，变量默认类型都是字符串类型，无法直接进行数值运算\n1 2 3 4 5 [atguigu@hadoop102 ~]$ C=1+2 [atguigu@hadoop102 ~]$ echo $C 1+2 （6）变量的值如果有空格，需要使用双引号或单引号括起来\n1 2 3 4 5 6 7 8 9 [atguigu@hadoop102 ~]$ D=I love banzhang -bash: world: command not found [atguigu@hadoop102 ~]$ D=\u0026#34;I love banzhang\u0026#34; [atguigu@hadoop102 ~]$ echo $D I love banzhang （7）可把变量提升为全局环境变量，可供其他Shell程序使用\nexport 变量名\n1 [atguigu@hadoop101 datas]$ vim helloworld.sh 在helloworld.sh文件中增加echo $B\n1 2 3 4 5 6 7 8 9 10 11 12 13 #!/bin/bash echo \u0026#34;helloworld\u0026#34; echo $B [atguigu@hadoop101 datas]$ ./helloworld.sh Helloworld 发现并没有打印输出变量B的值。\n1 2 3 4 5 6 7 [atguigu@hadoop101 datas]$ export B [atguigu@hadoop101 datas]$ ./helloworld.sh helloworld 2 3**.3** 特殊变量 3.3.1 $n 1）基本语法\n$n\t（功能描述：n为数字，$0代表该脚本名称，$1-$9代表第一到第九个参数，十以上的参数，十以上的参数需要用大括号包含，如${10}）\n2）案例实操\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 [atguigu@hadoop101 datas]$ touch parameter.sh [atguigu@hadoop101 datas]$ vim parameter.sh #!/bin/bash echo \u0026#39;==========$n==========\u0026#39; echo $0 echo $1 echo $2 [atguigu@hadoop101 datas]$ chmod 777 parameter.sh [atguigu@hadoop101 datas]$ ./parameter.sh cls xz ==========$n========== ./parameter.sh cls xz 3.3.2 $# 1）基本语法\n$#\t（功能描述：获取所有输入参数个数，常用于循环）。\n2）案例实操\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 [atguigu@hadoop101 datas]$ vim parameter.sh #!/bin/bash echo \u0026#39;==========$n==========\u0026#39; echo $0 echo $1 echo $2 echo \u0026#39;==========$#==========\u0026#39; echo $# [atguigu@hadoop101 datas]$ chmod 777 parameter.sh [atguigu@hadoop101 datas]$ ./parameter.sh cls xz ==========$n========== ./parameter.sh cls xz ==========$#========== 2 3.3.3 $*、$@ 1）基本语法\n$*\t（功能描述：这个变量代表命令行中所有的参数，$*把所有的参数看成一个整体）\n$@\t（功能描述：这个变量也代表命令行中所有的参数，不过$@把每个参数区分对待）\n2）案例实操\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 [atguigu@hadoop101 datas]$ vim parameter.sh #!/bin/bash echo \u0026#39;==========$n==========\u0026#39; echo $0 echo $1 echo $2 echo \u0026#39;==========$#==========\u0026#39; echo $# echo \u0026#39;==========$*==========\u0026#39; echo $* echo \u0026#39;==========$@==========\u0026#39; echo $@ [atguigu@hadoop101 datas]$ ./parameter.sh a b c d e f g ==========$n========== ./parameter.sh a b ==========$#========== 7 ==========$*========== a b c d e f g ==========$@========== a b c d e f g 3.3.4 $？ 1）基本语法\n$？\t（功能描述：最后一次执行的命令的返回状态。如果这个变量的值为0，证明上一个命令正确执行；如果这个变量的值为非0（具体是哪个数，由命令自己来决定），则证明上一个命令执行不正确了。）\n2）案例实操\n判断helloworld.sh脚本是否正确执行\n1 2 3 4 5 6 7 [atguigu@hadoop101 datas]$ ./helloworld.sh hello world [atguigu@hadoop101 datas]$ echo $? 0 4.运算符 1）基本语法\n“$((运算式))”或“$[运算式]”\n2）案例实操：\n计算（2+3）* 4的值\n1 2 3 [atguigu@hadoop101 datas]# S=$[(2+3)*4] [atguigu@hadoop101 datas]# echo $S 5.条件判断 1）基本语法\n（1）test condition\n（2）[ condition ]（注意condition前后要有空格）\n注意：条件非空即为true，[ atguigu ]返回true，[ ] 返回false。\n2）常用判断条件\n（1）两个整数之间比较\n-eq 等于（equal）\t-ne 不等于（not equal）\n-lt 小于（less than）\t-le 小于等于（less equal）\n-gt 大于（greater than） -ge 大于等于（greater equal）\n（2）按照文件权限进行判断\n-r 有读的权限（read）\n-w 有写的权限（write）\n-x 有执行的权限（execute）\n（3）按照文件类型进行判断\n-e 文件存在（existence）\n-f 文件存在并且是一个常规的文件（file）\n-d 文件存在并且是一个目录（directory）\n3）案例实操\n（1）23是否大于等于22\n1 2 3 4 5 [atguigu@hadoop101 datas]$ [ 23 -ge 22 ] [atguigu@hadoop101 datas]$ echo $? 0 （2）helloworld.sh是否具有写权限\n1 2 3 4 5 [atguigu@hadoop101 datas]$ [ -w helloworld.sh ] [atguigu@hadoop101 datas]$ echo $? 0 （3）/home/atguigu/cls.txt目录中的文件是否存在\n1 2 3 4 5 [atguigu@hadoop101 datas]$ [ -e /home/atguigu/cls.txt ] [atguigu@hadoop101 datas]$ echo $? 1 （4）多条件判断（\u0026amp;\u0026amp; 表示前一条命令执行成功时，才执行后一条命令，|| 表示上一条命令执行失败后，才执行下一条命令）\n1 2 3 4 5 6 7 [atguigu@hadoop101 ~]$ [ atguigu ] \u0026amp;\u0026amp; echo OK || echo notOK OK [atguigu@hadoop101 datas]$ [ ] \u0026amp;\u0026amp; echo OK || echo notOK notOK 6.流程控制（重点） 6.1 if判断 1）基本语法\n（1）单分支\nif [ 条件判断式 ];then\n​ 程序\nfi\n或者\nif [ 条件判断式 ]\nthen\n​ 程序\nfi\n（2）多分支\nif [ 条件判断式 ]\nthen\n​ 程序\nelif [ 条件判断式 ]\nthen\n​\t程序\nelse\n​\t程序\nfi\n注意事项：\n（1）[ 条件判断式 ]，中括号和条件判断式之间必须有空格\n（2）if后要有空格\n2）案例实操\n输入一个数字，如果是1，则输出banzhang zhen shuai，如果是2，则输出cls zhen mei，如果是其它，什么也不输出。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 [atguigu@hadoop101 datas]$ touch if.sh [atguigu@hadoop101 datas]$ vim if.sh #!/bin/bash if [ $1 -eq 1 ] then echo \u0026#34;banzhang zhen shuai\u0026#34; elif [ $1 -eq 2 ] then echo \u0026#34;cls zhen mei\u0026#34; fi [atguigu@hadoop101 datas]$ chmod 777 if.sh [atguigu@hadoop101 datas]$ ./if.sh 1 banzhang zhen shuai 6.2 case语句 1）基本语法\ncase $变量名 in\n\u0026ldquo;值1\u0026rdquo;）\n​ 如果变量的值等于值1，则执行程序1\n;;\n\u0026ldquo;值2\u0026rdquo;）\n​ 如果变量的值等于值2，则执行程序2\n;;\n​ …省略其他分支…\n*）\n​ 如果变量的值都不是以上的值，则执行此程序\n;;\nesac\n注意事项：\n（1）case行尾必须为单词“in”，每一个模式匹配必须以右括号“）”结束。\n（2）双分号“;;”表示命令序列结束，相当于java中的break。\n（3）最后的“*）”表示默认模式，相当于java中的default。\n2）案例实操\n输入一个数字，如果是1，则输出banzhang，如果是2，则输出cls，如果是其它，输出renyao。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 [atguigu@hadoop101 datas]$ touch case.sh [atguigu@hadoop101 datas]$ vim case.sh !/bin/bash case $1 in \u0026#34;1\u0026#34;) echo \u0026#34;banzhang\u0026#34; ;; \u0026#34;2\u0026#34;) echo \u0026#34;cls\u0026#34; ;; *) echo \u0026#34;renyao\u0026#34; ;; esac [atguigu@hadoop101 datas]$ chmod 777 case.sh [atguigu@hadoop101 datas]$ ./case.sh 1 1 6.3 for循环 1）基本语法1\nfor (( 初始值;循环控制条件;变量变化 ))\ndo\n​ 程序\ndone\n2）案例实操\n从1加到100\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 [atguigu@hadoop101 datas]$ touch for1.sh [atguigu@hadoop101 datas]$ vim for1.sh #!/bin/bash sum=0 for((i=0;i\u0026lt;=100;i++)) do sum=$[$sum+$i] done echo $sum [atguigu@hadoop101 datas]$ chmod 777 for1.sh [atguigu@hadoop101 datas]$ ./for1.sh 5050 3）基本语法2\nfor 变量 in 值1 值2 值3…\ndo\n​ 程序\ndone\n4）案例实操\n（1）打印所有输入参数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 [atguigu@hadoop101 datas]$ touch for2.sh [atguigu@hadoop101 datas]$ vim for2.sh #!/bin/bash #打印数字 for i in cls mly wls do echo \u0026#34;ban zhang love $i\u0026#34; done [atguigu@hadoop101 datas]$ chmod 777 for2.sh [atguigu@hadoop101 datas]$ ./for2.sh ban zhang love cls ban zhang love mly ban zhang love wls （2）比较$*和$@区别\n$*和$@都表示传递给函数或脚本的所有参数，不被双引号“”包含时，都以$1 $2 …$n的形式输出所有参数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 [atguigu@hadoop101 datas]$ touch for3.sh [atguigu@hadoop101 datas]$ vim for3.sh #!/bin/bash echo \u0026#39;=============$*=============\u0026#39; for i in $* do echo \u0026#34;ban zhang love $i\u0026#34; done echo \u0026#39;=============$@=============\u0026#39; for j in $@ do echo \u0026#34;ban zhang love $j\u0026#34; done [atguigu@hadoop101 datas]$ chmod 777 for3.sh [atguigu@hadoop101 datas]$ ./for3.sh cls mly wls =============$*============= banzhang love cls banzhang love mly banzhang love wls =============$@============= banzhang love cls banzhang love mly banzhang love wls 当它们被双引号“”包含时，$*会将所有的参数作为一个整体，以“$1 $2 …$n”的形式输出所有参数；$@会将各个参数分开，以“$1” “$2”…“$n”的形式输出所有参数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 [atguigu@hadoop101 datas]$ vim for4.sh #!/bin/bash echo \u0026#39;=============$*=============\u0026#39; for i in \u0026#34;$*\u0026#34; #$*中的所有参数看成是一个整体，所以这个for循环只会循环一次 do echo \u0026#34;ban zhang love $i\u0026#34; done echo \u0026#39;=============$@=============\u0026#39; for j in \u0026#34;$@\u0026#34; #$@中的每个参数都看成是独立的，所以“$@”中有几个参数，就会循环几次 do echo \u0026#34;ban zhang love $j\u0026#34; done [atguigu@hadoop101 datas]$ chmod 777 for4.sh [atguigu@hadoop101 datas]$ ./for4.sh cls mly wls =============$*============= banzhang love cls mly wls =============$@============= banzhang love cls banzhang love mly banzhang love wls 6.4 while循环 1）基本语法\nwhile [ 条件判断式 ]\ndo\n​ 程序\ndone\n2**）案例实操**\n从1加到100\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 [atguigu@hadoop101 datas]$ touch while.sh [atguigu@hadoop101 datas]$ vim while.sh #!/bin/bash sum=0 i=1 while [ $i -le 100 ] do sum=$[$sum+$i] i=$[$i+1] done echo $sum [atguigu@hadoop101 datas]$ chmod 777 while.sh [atguigu@hadoop101 datas]$ ./while.sh 5050 7.read读取控制台输入 1）基本语法\nread (选项) (参数)\n选项：\n-p：指定读取值时的提示符；\n-t：指定读取值时等待的时间（秒）。\n参数\n​\t变量：指定读取值的变量名\n2）案例实操\n提示7秒内，读取控制台输入的名称\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 [atguigu@hadoop101 datas]$ touch read.sh [atguigu@hadoop101 datas]$ vim read.sh #!/bin/bash read -t 7 -p \u0026#34;Enter your name in 7 seconds :\u0026#34; NAME echo $NAME [atguigu@hadoop101 datas]$ ./read.sh Enter your name in 7 seconds : atguigu atguigu 8.函数 8.1 系统函数 8.1.1 basename 1）基本语法\nbasename [string / pathname] [suffix] （功能描述：basename命令会删掉所有的前缀包括最后一个（‘/’）字符，然后将字符串显示出来。\n选项：\nsuffix为后缀，如果suffix被指定了，basename会将pathname或string中的suffix去掉。\n2）案例实操\n截取该/home/atguigu/banzhang.txt路径的文件名称\n1 2 3 4 5 6 7 [atguigu@hadoop101 datas]$ basename /home/atguigu/banzhang.txt banzhang.txt [atguigu@hadoop101 datas]$ basename /home/atguigu/banzhang.txt .txt banzhang 8.1.2 dirname 1）基本语法\n​\tdirname 文件绝对路径\t（功能描述：从给定的包含绝对路径的文件名中去除文件名（非目录的部分），然后返回剩下的路径（目录的部分））\n2）案例实操\n获取banzhang.txt文件的路径\n1 2 3 [atguigu@hadoop101 ~]$ dirname /home/atguigu/banzhang.txt /home/atguigu 8.2 自定义函数 1）基本语法\n[ function ] funname[()]\n{\n​\tAction;\n​\t[return int;]\n}\n2）经验技巧\n（1）必须在调用函数地方之前，先声明函数，shell脚本是逐行运行。不会像其它语言一样先编译。\n（2）函数返回值，只能通过$?系统变量获得，可以显示加：return返回，如果不加，将以最后一条命令运行结果，作为返回值。return后跟数值n(0-255)\n3）案例实操\n计算两个输入参数的和\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 [atguigu@hadoop101 datas]$ touch fun.sh [atguigu@hadoop101 datas]$ vim fun.sh #!/bin/bash function sum() { s=0 s=$[$1+$2] echo \u0026#34;$s\u0026#34; } read -p \u0026#34;Please input the number1: \u0026#34; n1; read -p \u0026#34;Please input the number2: \u0026#34; n2; sum $n1 $n2; [atguigu@hadoop101 datas]$ chmod 777 fun.sh [atguigu@hadoop101 datas]$ ./fun.sh Please input the number1: 2 Please input the number2: 5 7 9.Shell工具（重点） 9.1 cut cut的工作就是“剪”，具体的说就是在文件中负责剪切数据用的。cut 命令从文件的每一行剪切字节、字符和字段并将这些字节、字符和字段输出。\n1）基本用法\ncut [选项参数] filename\n说明：默认分隔符是制表符\n2）选项参数说明\n选项参数 功能 -f 列号，提取第几列 -d 分隔符，按照指定分隔符分割列，默认是制表符“\\t” -c 指定具体的字符 3）案例实操\n（1）数据准备\n1 2 3 4 5 6 7 8 9 10 11 12 13 [atguigu@hadoop101 datas]$ touch cut.txt [atguigu@hadoop101 datas]$ vim cut.txt dong shen guan zhen wo wo lai lai le le （2）切割cut.txt第一列\n1 2 3 4 5 6 7 8 9 10 11 [atguigu@hadoop101 datas]$ cut -d \u0026#34; \u0026#34; -f 1 cut.txt dong guan wo lai le （3）切割cut.txt第二、三列\n1 2 3 4 5 6 7 8 9 10 11 [atguigu@hadoop101 datas]$ cut -d \u0026#34; \u0026#34; -f 2,3 cut.txt shen zhen wo lai le （4）在cut.txt文件中切割出guan\n1 2 3 [atguigu@hadoop101 datas]$ cat cut.txt | grep \u0026#34;guan\u0026#34; | cut -d \u0026#34; \u0026#34; -f 1 guan （5）选取系统PATH变量值，第2个“：”开始后的所有路径：\n1 2 3 4 5 6 7 [atguigu@hadoop101 datas]$ echo $PATH /usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/atguigu/.local/bin:/home/atguigu/bin [atguigu@hadoop101 datas]$ echo $PATH | cut -d \u0026#34;:\u0026#34; -f 3- /usr/local/sbin:/usr/sbin:/home/atguigu/.local/bin:/home/atguigu/bin （6）切割ifconfig 后打印的IP地址\n1 2 3 [atguigu@hadoop101 datas]$ ifconfig ens33 | grep netmask | cut -d \u0026#34;i\u0026#34; -f 2 | cut -d \u0026#34; \u0026#34; -f 2 192.168.6.101 9.2 awk 一个强大的文本分析工具，把文件逐行的读入，以空格为默认分隔符将每行切片，切开的部分再进行分析处理。\n1）基本用法\nawk [选项参数] ‘/pattern1/{action1} /pattern2/{action2}\u0026hellip;’ filename\npattern：表示awk在数据中查找的内容，就是匹配模式\naction：在找到匹配内容时所执行的一系列命令\n2）选项参数说明\n选项参数 功能 -F 指定输入文件折分隔符 -v 赋值一个用户定义变量 3）案例实操\n（1）数据准备\n1 [atguigu@hadoop101 datas]$ sudo cp /etc/passwd ./ （2）搜索passwd文件以root关键字开头的所有行，并输出该行的第7列。\n1 2 3 [atguigu@hadoop101 datas]$ awk -F : \u0026#39;/^root/{print $7}\u0026#39; passwd /bin/bash （3）搜索passwd文件以root关键字开头的所有行，并输出该行的第1列和第7列，中间以“，”号分割。\n1 2 3 [atguigu@hadoop101 datas]$ awk -F : \u0026#39;/^root/{print $1\u0026#34;,\u0026#34;$7}\u0026#39; passwd root,/bin/bash 注意：只有匹配了pattern的行才会执行action\n（4）只显示/etc/passwd的第一列和第七列，以逗号分割，且在所有行前面添加列名user，shell在最后一行添加\u0026quot;dahaige，/bin/zuishuai\u0026rdquo;。\n1 2 3 4 5 6 7 8 9 10 11 12 13 [atguigu@hadoop101 datas]$ awk -F : \u0026#39;BEGIN{print \u0026#34;user, shell\u0026#34;} {print $1\u0026#34;,\u0026#34;$7} END{print \u0026#34;dahaige,/bin/zuishuai\u0026#34;}\u0026#39; passwd user, shell root,/bin/bash bin,/sbin/nologin 。。。 atguigu,/bin/bash dahaige,/bin/zuishuai 注意：BEGIN 在所有数据读取行之前执行；END 在所有数据执行之后执行。\n（5）将passwd文件中的用户id增加数值1并输出\n1 2 3 4 5 6 7 8 9 [atguigu@hadoop101 datas]$ awk -v i=1 -F : \u0026#39;{print $3+i}\u0026#39; passwd 1 2 3 4 4**）awk的内置变量**\n变量 说明 FILENAME 文件名 NR 已读的记录数（行号） NF 浏览记录的域的个数（切割后，列的个数） 5）案例实操\n（1）统计passwd文件名，每行的行号，每行的列数\n1 2 3 4 5 6 7 8 9 [atguigu@hadoop101 datas]$ awk -F : \u0026#39;{print \u0026#34;filename:\u0026#34; FILENAME \u0026#34;,linenum:\u0026#34; NR \u0026#34;,col:\u0026#34;NF}\u0026#39; passwd filename:passwd,linenum:1,col:7 filename:passwd,linenum:2,col:7 filename:passwd,linenum:3,col:7 。。。 （2）查询ifconfig命令输出结果中的空行所在的行号\n1 2 3 4 5 6 7 [atguigu@hadoop101 datas]$ ifconfig | awk \u0026#39;/^$/{print NR}\u0026#39; 9 18 26 （3）切割IP\n1 2 3 [atguigu@hadoop101 datas]$ ifconfig ens33 | grep netmask | awk -F \u0026#34;inet\u0026#34; \u0026#39;{print $2}\u0026#39; | awk -F \u0026#34; \u0026#34; \u0026#39;{print $1}\u0026#39; 192.168.6.101 9.3 sort sort命令是在Linux里非常有用，它将文件进行排序，并将排序结果标准输出。\n1）基本语法\nSort (选项) (参数)\n选项 说明 -n 依照数值的大小排序 -r 以相反的顺序来排序 -t 设置排序时所用的分隔字符 -k 指定需要排序的列 参数：指定待排序的文件列表\n2）案例实操\n（1）数据准备\n1 2 3 4 5 6 7 8 9 10 11 12 13 [atguigu@hadoop101 datas]$ touch sort.txt [atguigu@hadoop101 datas]$ vim sort.txt bb:40:5.4 bd:20:4.2 xz:50:2.3 cls:10:3.5 ss:30:1.6 （2）按照“：”分割后的第三列倒序排序。\n1 2 3 4 5 6 7 8 9 10 11 [atguigu@hadoop101 datas]$ sort -t : -nrk 3 sort.txt bb:40:5.4 bd:20:4.2 cls:10:3.5 xz:50:2.3 ss:30:1.6 9.4 wc wc命令用来统计文件信息。利用wc指令我们可以计算文件的行数，字节数、字符数等。\n1）基本语法\nwc [选项参数] filename\n选项参数 功能 -l 统计文件行数 -w 统计文件的单词数 -m 统计文件的字符数 -c 统计文件的字节数 2）案例实操\n统计/etc/profile文件的行数、单词数、字节数！\n1 2 3 4 5 [atguigu@hadoop101 datas]$ wc -l /etc/profile [atguigu@hadoop101 datas]$ wc -w /etc/profile [atguigu@hadoop101 datas]$ wc -m /etc/profile 10.正则表达式入门 正则表达式使用单个字符串来描述、匹配一系列符合某个语法规则的字符串。在很多文本编辑器里，正则表达式通常被用来检索、替换那些符合某个模式的文本。在Linux中，grep，sed，awk等命令都支持通过正则表达式进行模式匹配。\n10.1 常规匹配 一串不包含特殊字符的正则表达式匹配它自己，例如：\n1 [atguigu@hadoop101 datas]$ cat /etc/passwd | grep atguigu 就会匹配所有包含atguigu的行\n10.2 常用特殊字符 1）特殊字符：^\n^ 匹配一行的开头，例如：\n1 [atguigu@hadoop101 datas]$ cat /etc/passwd | grep ^a 会匹配出所有以a开头的行\n2）特殊字符：$\n$ 匹配一行的结束，例如\n1 [atguigu@hadoop101 datas]$ cat /etc/passwd | grep t$ 会匹配出所有以t结尾的行\n思考：^$ 匹配什么？\n3）特殊字符：.\n. 匹配一个任意的字符，例如\n1 [atguigu@hadoop101 datas]$ cat /etc/passwd | grep r..t 会匹配包含rabt,rbbt,rxdt,root等的所有行\n4）特殊字符：*\n不单独使用，他和上一个字符连用，表示匹配上一个字符0次或多次，例如 1 [atguigu@hadoop101 datas]$ cat /etc/passwd | grep ro*t 会匹配rt, rot, root, rooot, roooot等所有行\n思考：.* 匹配什么？\n5）特殊字符：[ ]\n[ ] 表示匹配某个范围内的一个字符，例如\n[6,8]\u0026mdash;\u0026mdash;匹配6或者8\n[0-9]\u0026mdash;\u0026mdash;匹配一个0-9的数字\n[0-9]*\u0026mdash;\u0026mdash;匹配任意长度的数字字符串\n[a-z]\u0026mdash;\u0026mdash;匹配一个a-z之间的字符\n[a-z]* \u0026mdash;\u0026mdash;匹配任意长度的字母字符串\n[a-c, e-f]-匹配a-c或者e-f之间的任意字符\n1 [atguigu@hadoop101 datas]$ cat /etc/passwd | grep r[a,b,c]*t 会匹配rt,rat, rbt, rabt, rbact,rabccbaaacbt等等所有行\n6）特殊字符：\\\n\\ 表示转义，并不会单独使用。由于所有特殊字符都有其特定匹配模式，当我们想匹配某一特殊字符本身时（例如，我想找出所有包含 \u0026lsquo;$\u0026rsquo; 的行），就会碰到困难。此时我们就要将转义字符和特殊字符连用，来表示特殊字符本身，例如\n1 [atguigu@hadoop101 datas]$ cat /etc/passwd | grep a\\$b 就会匹配所有包含 a$b 的行。\n","date":"2023-11-25T00:00:00Z","image":"https://gkxgithub.github.io/p/linux/6617e27df1b05f6ef02743afbb36d6a_hu9039010403693100886.jpg","permalink":"https://gkxgithub.github.io/p/linux/","title":"linux"},{"content":"正文测试 而这些并不是完全重要，更加重要的问题是， 带着这些问题，我们来审视一下学生会退会。 既然如何， 对我个人而言，学生会退会不仅仅是一个重大的事件，还可能会改变我的人生。 我们不得不面对一个非常尴尬的事实，那就是， 可是，即使是这样，学生会退会的出现仍然代表了一定的意义。 学生会退会，发生了会如何，不发生又会如何。 经过上述讨论， 生活中，若学生会退会出现了，我们就不得不考虑它出现了的事实。 学生会退会，到底应该如何实现。 这样看来， 在这种困难的抉择下，本人思来想去，寝食难安。 对我个人而言，学生会退会不仅仅是一个重大的事件，还可能会改变我的人生。 就我个人来说，学生会退会对我的意义，不能不说非常重大。 莎士比亚曾经提到过，人的一生是短的，但如果卑劣地过这一生，就太长了。这似乎解答了我的疑惑。 莫扎特说过一句富有哲理的话，谁和我一样用功，谁就会和我一样成功。这启发了我， 对我个人而言，学生会退会不仅仅是一个重大的事件，还可能会改变我的人生。 学生会退会，到底应该如何实现。 一般来说， 从这个角度来看， 这种事实对本人来说意义重大，相信对这个世界也是有一定意义的。 在这种困难的抉择下，本人思来想去，寝食难安。 了解清楚学生会退会到底是一种怎么样的存在，是解决一切问题的关键。 一般来说， 生活中，若学生会退会出现了，我们就不得不考虑它出现了的事实。 问题的关键究竟为何？ 而这些并不是完全重要，更加重要的问题是。\n奥斯特洛夫斯基曾经说过，共同的事业，共同的斗争，可以使人们产生忍受一切的力量。　带着这句话，我们还要更加慎重的审视这个问题： 一般来讲，我们都必须务必慎重的考虑考虑。 既然如此， 这种事实对本人来说意义重大，相信对这个世界也是有一定意义的。 带着这些问题，我们来审视一下学生会退会。 我认为， 我认为， 在这种困难的抉择下，本人思来想去，寝食难安。 问题的关键究竟为何？ 每个人都不得不面对这些问题。 在面对这种问题时， 要想清楚，学生会退会，到底是一种怎么样的存在。 我认为， 既然如此， 每个人都不得不面对这些问题。 在面对这种问题时， 那么， 我认为， 学生会退会因何而发生。\n引用 思念是最暖的忧伤像一双翅膀\n让我停不了飞不远在过往游荡\n不告而别的你 就算为了我着想\n这么沉痛的呵护 我怎么能翱翔\n最暖的憂傷 - 田馥甄\n图片 1 2 3 ![Photo by Florian Klauer on Unsplash](florian-klauer-nptLmg6jqDo-unsplash.jpg) ![Photo by Luca Bravo on Unsplash](luca-bravo-alS7ewQ41M8-unsplash.jpg) ![Photo by Helena Hertz on Unsplash](helena-hertz-wWZzXlDpMog-unsplash.jpg) ![Photo by Hudai Gayiran on Unsplash](hudai-gayiran-3Od_VKcDEAA-unsplash.jpg) 相册语法来自 Typlog\n","date":"2020-09-09T00:00:00Z","image":"https://gkxgithub.github.io/p/test-chinese/helena-hertz-wWZzXlDpMog-unsplash_hu4699868770670889127.jpg","permalink":"https://gkxgithub.github.io/p/test-chinese/","title":"Chinese Test"},{"content":"This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\nHeadings The following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1 H2 H3 H4 H5 H6 Paragraph Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\nBlockquotes The blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\nBlockquote without attribution Tiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote.\nBlockquote with attribution Don\u0026rsquo;t communicate by sharing memory, share memory by communicating.\n— Rob Pike1\nTables Tables aren\u0026rsquo;t part of the core Markdown spec, but Hugo supports supports them out-of-the-box.\nName Age Bob 27 Alice 23 Inline Markdown within tables Italics Bold Code italics bold code A B C D E F Lorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus ultricies, sapien non euismod aliquam, dui ligula tincidunt odio, at accumsan nulla sapien eget ex. Proin eleifend dictum ipsum, non euismod ipsum pulvinar et. Vivamus sollicitudin, quam in pulvinar aliquam, metus elit pretium purus Proin sit amet velit nec enim imperdiet vehicula. Ut bibendum vestibulum quam, eu egestas turpis gravida nec Sed scelerisque nec turpis vel viverra. Vivamus vitae pretium sapien Code Blocks Code block with backticks 1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block indented with four spaces \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block with Hugo\u0026rsquo;s internal highlight shortcode 1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Diff code block 1 2 3 4 5 [dependencies.bevy] git = \u0026#34;https://github.com/bevyengine/bevy\u0026#34; rev = \u0026#34;11f52b8c72fc3a568e8bb4a4cd1f3eb025ac2e13\u0026#34; - features = [\u0026#34;dynamic\u0026#34;] + features = [\u0026#34;jpeg\u0026#34;, \u0026#34;dynamic\u0026#34;] List Types Ordered List First item Second item Third item Unordered List List item Another item And another item Nested list Fruit Apple Orange Banana Dairy Milk Cheese Other Elements — abbr, sub, sup, kbd, mark GIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL + ALT + Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\nHyperlinked image The above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2019-03-11T00:00:00Z","image":"https://gkxgithub.github.io/p/markdown-syntax-guide/pawel-czerwinski-8uZPynIu-rQ-unsplash_hu6307248181568134095.jpg","permalink":"https://gkxgithub.github.io/p/markdown-syntax-guide/","title":"Markdown Syntax Guide"},{"content":"Lorem est tota propiore conpellat pectoribus de pectora summo.\nRedit teque digerit hominumque toris verebor lumina non cervice subde tollit usus habet Arctonque, furores quas nec ferunt. Quoque montibus nunc caluere tempus inhospita parcite confusaque translucet patri vestro qui optatis lumine cognoscere flos nubis! Fronde ipsamque patulos Dryopen deorum.\nExierant elisi ambit vivere dedere Duce pollice Eris modo Spargitque ferrea quos palude Rursus nulli murmur; hastile inridet ut ab gravi sententia! Nomine potitus silentia flumen, sustinet placuit petis in dilapsa erat sunt. Atria tractus malis.\nComas hunc haec pietate fetum procerum dixit Post torum vates letum Tiresia Flumen querellas Arcanaque montibus omnes Quidem et Vagus elidunt The Van de Graaf Canon\nMane refeci capiebant unda mulcebat Victa caducifer, malo vulnere contra dicere aurato, ludit regale, voca! Retorsit colit est profanae esse virescere furit nec; iaculi matertera et visa est, viribus. Divesque creatis, tecta novat collumque vulnus est, parvas. Faces illo pepulere tempus adest. Tendit flamma, ab opes virum sustinet, sidus sequendo urbis.\nIubar proles corpore raptos vero auctor imperium; sed et huic: manus caeli Lelegas tu lux. Verbis obstitit intus oblectamina fixis linguisque ausus sperare Echionides cornuaque tenent clausit possit. Omnia putatur. Praeteritae refert ausus; ferebant e primus lora nutat, vici quae mea ipse. Et iter nil spectatae vulnus haerentia iuste et exercebat, sui et.\nEurytus Hector, materna ipsumque ut Politen, nec, nate, ignari, vernum cohaesit sequitur. Vel mitis temploque vocatus, inque alis, oculos nomen non silvis corpore coniunx ne displicet illa. Crescunt non unus, vidit visa quantum inmiti flumina mortis facto sic: undique a alios vincula sunt iactata abdita! Suspenderat ego fuit tendit: luna, ante urbem Propoetides parte.\n","date":"2019-03-09T00:00:00Z","image":"https://gkxgithub.github.io/p/placeholder-text/matt-le-SJSpo9hQf7s-unsplash_hu10664154974910995856.jpg","permalink":"https://gkxgithub.github.io/p/placeholder-text/","title":"Placeholder Text"},{"content":"Mathematical notation in a Hugo project can be enabled by using third party JavaScript libraries.\nIn this example we will be using KaTeX\nCreate a partial under /layouts/partials/math.html Within this partial reference the Auto-render Extension or host these scripts locally. Include the partial in your templates like so: 1 2 3 {{ if or .Params.math .Site.Params.math }} {{ partial \u0026#34;math.html\u0026#34; . }} {{ end }} To enable KaTeX globally set the parameter math to true in a project\u0026rsquo;s configuration To enable KaTeX on a per page basis include the parameter math: true in content files Note: Use the online reference of Supported TeX Functions\nExamples Inline math: $\\varphi = \\dfrac{1+\\sqrt5}{2}= 1.6180339887…$\nBlock math: $$ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$\n","date":"2019-03-08T00:00:00Z","permalink":"https://gkxgithub.github.io/p/math-typesetting/","title":"Math Typesetting"},{"content":"Emoji can be enabled in a Hugo project in a number of ways.\nThe emojify function can be called directly in templates or Inline Shortcodes.\nTo enable emoji globally, set enableEmoji to true in your site\u0026rsquo;s configuration and then you can type emoji shorthand codes directly in content files; e.g.\n🙈 :see_no_evil: 🙉 :hear_no_evil: 🙊 :speak_no_evil:\nThe Emoji cheat sheet is a useful reference for emoji shorthand codes.\nN.B. The above steps enable Unicode Standard emoji characters and sequences in Hugo, however the rendering of these glyphs depends on the browser and the platform. To style the emoji you can either use a third party emoji font or a font stack; e.g.\n1 2 3 .emoji { font-family: Apple Color Emoji, Segoe UI Emoji, NotoColorEmoji, Segoe UI Symbol, Android Emoji, EmojiSymbols; } ","date":"2019-03-05T00:00:00Z","image":"https://gkxgithub.github.io/p/emoji-support/the-creative-exchange-d2zvqp3fpro-unsplash_hu5876398126655421130.jpg","permalink":"https://gkxgithub.github.io/p/emoji-support/","title":"Emoji Support"}]